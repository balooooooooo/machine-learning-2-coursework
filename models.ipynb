{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:46.756697300Z",
     "start_time": "2024-01-06T18:22:46.692239900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6491863b8ff047b2"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "dfs_train = {}\n",
    "dfs_test = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:46.934242500Z",
     "start_time": "2024-01-06T18:22:46.707275100Z"
    }
   },
   "id": "67e99dc3b60e9c20"
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "for root, directory, files in os.walk(\"data/train_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_train[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            try:\n",
    "                dfs_train[file[:-4]] = pd.get_dummies(dfs_train[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "lens_test = 0\n",
    "for root, directory, files in os.walk(\"data/test_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_test[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            try:\n",
    "                dfs_test[file[:-4]] = pd.get_dummies(dfs_test[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "            lens_test += dfs_test[file[:-4]].shape[0]\n",
    "print(\"---\")\n",
    "lens_orig = 0\n",
    "df_test_y = pd.DataFrame()\n",
    "for root, directory, files in os.walk(\"data/orig_data\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            # print(pd.read_csv(f\"{root}/{file}\").shape)\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            lens_orig += tmp.shape[0]\n",
    "            tmp[\"country\"] = file[:-5]\n",
    "            df_test_y = pd.concat([df_test_y, tmp], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:50.677534200Z",
     "start_time": "2024-01-06T18:22:46.718364600Z"
    }
   },
   "id": "c7af8ff6f8ea0ba"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "df_test_y[\"Date\"] = pd.to_datetime(df_test_y[\"Date\"], format = '%d/%m/%Y', dayfirst=True)\n",
    "\n",
    "df_test_y.sort_values(by=\"Date\", inplace=True, ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:50.696593900Z",
     "start_time": "2024-01-06T18:22:50.679544300Z"
    }
   },
   "id": "ff5e531d024f1fd8"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "    Div       Date   Time       HomeTeam     AwayTeam  FTHG  FTAG FTR  HTHG  \\\n0    E1 2022-07-29  20:00   Huddersfield      Burnley     0     1   A   0.0   \n6    E3 2022-07-30  15:00       Rochdale        Crewe     1     2   A   0.0   \n5    E3 2022-07-30  15:00    Northampton   Colchester     3     2   H   1.0   \n4    E3 2022-07-30  15:00  Leyton Orient      Grimsby     2     0   H   0.0   \n11   E2 2022-07-30  15:00        Wycombe       Burton     3     0   H   3.0   \n..   ..        ...    ...            ...          ...   ...   ...  ..   ...   \n375  E0 2023-05-28  16:30        Everton  Bournemouth     1     0   H   0.0   \n372  E0 2023-05-28  16:30      Brentford     Man City     1     0   H   0.0   \n377  E0 2023-05-28  16:30      Leicester     West Ham     2     1   H   1.0   \n378  E0 2023-05-28  16:30     Man United       Fulham     2     1   H   1.0   \n379  E0 2023-05-28  16:30    Southampton    Liverpool     4     4   D   2.0   \n\n     HTAG  ... B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  AvgCAHH  \\\n0     1.0  ...     2.09      1.81   2.10   1.82     2.14     1.83     2.09   \n6     2.0  ...     1.70      2.10   1.78   2.12     1.85     2.17     1.75   \n5     1.0  ...     2.00      1.85   2.02   1.87     2.02     1.92     1.96   \n4     0.0  ...     1.80      2.05   1.79   2.10     1.86     2.10     1.80   \n11    0.0  ...     2.00      1.85   2.00   1.88     2.03     1.92     1.96   \n..    ...  ...      ...       ...    ...    ...      ...      ...      ...   \n375   0.0  ...     2.02      1.77   2.10   1.81     2.17     1.92     2.03   \n372   0.0  ...     1.93      1.97   2.05   1.86     2.28     1.97     2.01   \n377   0.0  ...     1.75      2.05   1.85   2.06     1.90     2.16     1.82   \n378   1.0  ...     1.98      1.92   1.98   1.93     2.07     1.98     1.97   \n379   2.0  ...     1.82      2.08   1.85   2.07     1.96     2.12     1.88   \n\n     AvgCAHA  country      Referee  \n0       1.78  england  J Linington  \n6       2.07  england    A Kitchen  \n5       1.85  england      M Woods  \n4       2.02  england    C Pollard  \n11      1.85  england       G Ward  \n..       ...      ...          ...  \n375     1.83  england    S Attwell  \n372     1.85  england     J Brooks  \n377     2.04  england     S Hooper  \n378     1.89  england      R Jones  \n379     1.98  england    D England  \n\n[2036 rows x 107 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>...</th>\n      <th>B365CAHH</th>\n      <th>B365CAHA</th>\n      <th>PCAHH</th>\n      <th>PCAHA</th>\n      <th>MaxCAHH</th>\n      <th>MaxCAHA</th>\n      <th>AvgCAHH</th>\n      <th>AvgCAHA</th>\n      <th>country</th>\n      <th>Referee</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E1</td>\n      <td>2022-07-29</td>\n      <td>20:00</td>\n      <td>Huddersfield</td>\n      <td>Burnley</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.09</td>\n      <td>1.81</td>\n      <td>2.10</td>\n      <td>1.82</td>\n      <td>2.14</td>\n      <td>1.83</td>\n      <td>2.09</td>\n      <td>1.78</td>\n      <td>england</td>\n      <td>J Linington</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Rochdale</td>\n      <td>Crewe</td>\n      <td>1</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.70</td>\n      <td>2.10</td>\n      <td>1.78</td>\n      <td>2.12</td>\n      <td>1.85</td>\n      <td>2.17</td>\n      <td>1.75</td>\n      <td>2.07</td>\n      <td>england</td>\n      <td>A Kitchen</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Northampton</td>\n      <td>Colchester</td>\n      <td>3</td>\n      <td>2</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.00</td>\n      <td>1.85</td>\n      <td>2.02</td>\n      <td>1.87</td>\n      <td>2.02</td>\n      <td>1.92</td>\n      <td>1.96</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>M Woods</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Leyton Orient</td>\n      <td>Grimsby</td>\n      <td>2</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.80</td>\n      <td>2.05</td>\n      <td>1.79</td>\n      <td>2.10</td>\n      <td>1.86</td>\n      <td>2.10</td>\n      <td>1.80</td>\n      <td>2.02</td>\n      <td>england</td>\n      <td>C Pollard</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>E2</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Wycombe</td>\n      <td>Burton</td>\n      <td>3</td>\n      <td>0</td>\n      <td>H</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.00</td>\n      <td>1.85</td>\n      <td>2.00</td>\n      <td>1.88</td>\n      <td>2.03</td>\n      <td>1.92</td>\n      <td>1.96</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>G Ward</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Everton</td>\n      <td>Bournemouth</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.02</td>\n      <td>1.77</td>\n      <td>2.10</td>\n      <td>1.81</td>\n      <td>2.17</td>\n      <td>1.92</td>\n      <td>2.03</td>\n      <td>1.83</td>\n      <td>england</td>\n      <td>S Attwell</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Brentford</td>\n      <td>Man City</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.93</td>\n      <td>1.97</td>\n      <td>2.05</td>\n      <td>1.86</td>\n      <td>2.28</td>\n      <td>1.97</td>\n      <td>2.01</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>J Brooks</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Leicester</td>\n      <td>West Ham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.75</td>\n      <td>2.05</td>\n      <td>1.85</td>\n      <td>2.06</td>\n      <td>1.90</td>\n      <td>2.16</td>\n      <td>1.82</td>\n      <td>2.04</td>\n      <td>england</td>\n      <td>S Hooper</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Man United</td>\n      <td>Fulham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.98</td>\n      <td>1.92</td>\n      <td>1.98</td>\n      <td>1.93</td>\n      <td>2.07</td>\n      <td>1.98</td>\n      <td>1.97</td>\n      <td>1.89</td>\n      <td>england</td>\n      <td>R Jones</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Southampton</td>\n      <td>Liverpool</td>\n      <td>4</td>\n      <td>4</td>\n      <td>D</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.82</td>\n      <td>2.08</td>\n      <td>1.85</td>\n      <td>2.07</td>\n      <td>1.96</td>\n      <td>2.12</td>\n      <td>1.88</td>\n      <td>1.98</td>\n      <td>england</td>\n      <td>D England</td>\n    </tr>\n  </tbody>\n</table>\n<p>2036 rows × 107 columns</p>\n</div>"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_y[df_test_y[\"country\"]==\"england\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:50.747605Z",
     "start_time": "2024-01-06T18:22:50.692590800Z"
    }
   },
   "id": "afbab6d2afef5660"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "for country in df_test_y[\"country\"].unique():\n",
    "    col1 = df_test_y[df_test_y[\"country\"] == country][\"FTHG\"].reset_index()\n",
    "    col2 = df_test_y[df_test_y[\"country\"] == country][\"FTAG\"].reset_index()\n",
    "\n",
    "    target_values = col1[\"FTHG\"] + col2[\"FTAG\"]\n",
    "\n",
    "    dfs_test[f\"df_{country}\"][\"Target_regr\"] = target_values\n",
    "    dfs_test[f\"df_{country}\"][\"FTHG\"] = col1[\"FTHG\"]\n",
    "    dfs_test[f\"df_{country}\"][\"FTAG\"] = col2[\"FTAG\"]\n",
    "    dfs_test[f\"df_{country}\"]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_test[f\"df_{country}\"]['FTAG'], dfs_test[f\"df_{country}\"]['FTHG'])]\n",
    "    dfs_test[f\"df_{country}\"].drop(columns=[\"FTHG\", \"FTAG\", \"Unnamed: 0\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:50.783086900Z",
     "start_time": "2024-01-06T18:22:50.726650400Z"
    }
   },
   "id": "85233e29ca135574"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  FTHG  FTAG  season  Avg_away_odds  Avg_home_odds  \\\n0            300   5.0   1.0     1.0       4.666667       1.556667   \n1            301   3.0   0.0     1.0       8.600000       1.233333   \n2            302   1.0   1.0     1.0       2.966667       2.050000   \n3            303   4.0   2.0     1.0       5.733333       1.416667   \n4            304   1.0   0.0     1.0       3.916667       1.706667   \n...          ...   ...   ...     ...            ...            ...   \n5487        5787   3.0   0.0    21.0       3.914000       1.870000   \n5488        5788   2.0   0.0    21.0       7.970000       1.330000   \n5489        5789   2.0   3.0    21.0       1.392000       7.320000   \n5490        5790   5.0   0.0    21.0      11.128000       1.228000   \n5491        5791   0.0   2.0    21.0       1.482000       6.234000   \n\n      Avg_draw_odds  Var_away_odds  Var_home_odds  Var_draw_odds  ...  \\\n0          3.533333       0.083333       0.000133       0.043333  ...   \n1          4.900000       2.680000       0.003333       0.280000  ...   \n2          3.166667       0.043333       0.032500       0.063333  ...   \n3          3.833333       0.463333       0.000833       0.043333  ...   \n4          3.383333       0.270833       0.008133       0.110833  ...   \n...             ...            ...            ...            ...  ...   \n5487       3.574000       0.010480       0.001150       0.013380  ...   \n5488       5.290000       0.092000       0.000350       0.045500  ...   \n5489       4.752000       0.001270       0.130750       0.026770  ...   \n5490       6.252000       2.046920       0.000370       0.062520  ...   \n5491       4.430000       0.000470       0.137530       0.019500  ...   \n\n     AwayLossRatio  AwayDrawRatio  HomeTeamAvgShotsOnTarget  \\\n0         0.500000       0.235294                  4.756882   \n1         0.470588       0.205882                  6.264428   \n2         0.250000       0.281250                  4.734209   \n3         0.500000       0.235294                  5.121079   \n4         0.500000       0.235294                       NaN   \n...            ...            ...                       ...   \n5487      0.249637       0.258345                  4.455075   \n5488      0.426195       0.237006                  5.613602   \n5489      0.156342       0.227139                  4.648310   \n5490      0.424581       0.312849                  5.128811   \n5491      0.280415       0.240356                  3.272727   \n\n      AwayTeamAvgShotsOnTarget  HomeTeamScoredRatio  AwayTeamScoredRatio  \\\n0                     4.309364             0.478261             0.319149   \n1                     4.510234             0.778761             0.457831   \n2                     5.034806             0.472527             0.571429   \n3                     4.826950             0.552381             0.448980   \n4                          NaN                  NaN                  NaN   \n...                        ...                  ...                  ...   \n5487                  5.083699             0.436352             0.600632   \n5488                  4.621183             0.673558             0.445467   \n5489                  5.431673             0.486462             0.683400   \n5490                  4.660707             0.574391             0.441392   \n5491                  5.192850             0.312500             0.577734   \n\n      Target_regr  Target_clas  Bookie_Prediction_A  Bookie_Prediction_H  \n0             6.0            1                False                 True  \n1             3.0            1                False                 True  \n2             2.0           -1                False                 True  \n3             6.0            1                False                 True  \n4             1.0            1                False                 True  \n...           ...          ...                  ...                  ...  \n5487          3.0            1                False                 True  \n5488          2.0            1                False                 True  \n5489          5.0            0                 True                False  \n5490          5.0            1                False                 True  \n5491          2.0            0                 True                False  \n\n[5492 rows x 111 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>season</th>\n      <th>Avg_away_odds</th>\n      <th>Avg_home_odds</th>\n      <th>Avg_draw_odds</th>\n      <th>Var_away_odds</th>\n      <th>Var_home_odds</th>\n      <th>Var_draw_odds</th>\n      <th>...</th>\n      <th>AwayLossRatio</th>\n      <th>AwayDrawRatio</th>\n      <th>HomeTeamAvgShotsOnTarget</th>\n      <th>AwayTeamAvgShotsOnTarget</th>\n      <th>HomeTeamScoredRatio</th>\n      <th>AwayTeamScoredRatio</th>\n      <th>Target_regr</th>\n      <th>Target_clas</th>\n      <th>Bookie_Prediction_A</th>\n      <th>Bookie_Prediction_H</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.666667</td>\n      <td>1.556667</td>\n      <td>3.533333</td>\n      <td>0.083333</td>\n      <td>0.000133</td>\n      <td>0.043333</td>\n      <td>...</td>\n      <td>0.500000</td>\n      <td>0.235294</td>\n      <td>4.756882</td>\n      <td>4.309364</td>\n      <td>0.478261</td>\n      <td>0.319149</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>301</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>8.600000</td>\n      <td>1.233333</td>\n      <td>4.900000</td>\n      <td>2.680000</td>\n      <td>0.003333</td>\n      <td>0.280000</td>\n      <td>...</td>\n      <td>0.470588</td>\n      <td>0.205882</td>\n      <td>6.264428</td>\n      <td>4.510234</td>\n      <td>0.778761</td>\n      <td>0.457831</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>302</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.966667</td>\n      <td>2.050000</td>\n      <td>3.166667</td>\n      <td>0.043333</td>\n      <td>0.032500</td>\n      <td>0.063333</td>\n      <td>...</td>\n      <td>0.250000</td>\n      <td>0.281250</td>\n      <td>4.734209</td>\n      <td>5.034806</td>\n      <td>0.472527</td>\n      <td>0.571429</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>303</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>5.733333</td>\n      <td>1.416667</td>\n      <td>3.833333</td>\n      <td>0.463333</td>\n      <td>0.000833</td>\n      <td>0.043333</td>\n      <td>...</td>\n      <td>0.500000</td>\n      <td>0.235294</td>\n      <td>5.121079</td>\n      <td>4.826950</td>\n      <td>0.552381</td>\n      <td>0.448980</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>304</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.916667</td>\n      <td>1.706667</td>\n      <td>3.383333</td>\n      <td>0.270833</td>\n      <td>0.008133</td>\n      <td>0.110833</td>\n      <td>...</td>\n      <td>0.500000</td>\n      <td>0.235294</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5487</th>\n      <td>5787</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>3.914000</td>\n      <td>1.870000</td>\n      <td>3.574000</td>\n      <td>0.010480</td>\n      <td>0.001150</td>\n      <td>0.013380</td>\n      <td>...</td>\n      <td>0.249637</td>\n      <td>0.258345</td>\n      <td>4.455075</td>\n      <td>5.083699</td>\n      <td>0.436352</td>\n      <td>0.600632</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5488</th>\n      <td>5788</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>7.970000</td>\n      <td>1.330000</td>\n      <td>5.290000</td>\n      <td>0.092000</td>\n      <td>0.000350</td>\n      <td>0.045500</td>\n      <td>...</td>\n      <td>0.426195</td>\n      <td>0.237006</td>\n      <td>5.613602</td>\n      <td>4.621183</td>\n      <td>0.673558</td>\n      <td>0.445467</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5489</th>\n      <td>5789</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>1.392000</td>\n      <td>7.320000</td>\n      <td>4.752000</td>\n      <td>0.001270</td>\n      <td>0.130750</td>\n      <td>0.026770</td>\n      <td>...</td>\n      <td>0.156342</td>\n      <td>0.227139</td>\n      <td>4.648310</td>\n      <td>5.431673</td>\n      <td>0.486462</td>\n      <td>0.683400</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5490</th>\n      <td>5790</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>11.128000</td>\n      <td>1.228000</td>\n      <td>6.252000</td>\n      <td>2.046920</td>\n      <td>0.000370</td>\n      <td>0.062520</td>\n      <td>...</td>\n      <td>0.424581</td>\n      <td>0.312849</td>\n      <td>5.128811</td>\n      <td>4.660707</td>\n      <td>0.574391</td>\n      <td>0.441392</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5491</th>\n      <td>5791</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>1.482000</td>\n      <td>6.234000</td>\n      <td>4.430000</td>\n      <td>0.000470</td>\n      <td>0.137530</td>\n      <td>0.019500</td>\n      <td>...</td>\n      <td>0.280415</td>\n      <td>0.240356</td>\n      <td>3.272727</td>\n      <td>5.192850</td>\n      <td>0.312500</td>\n      <td>0.577734</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5492 rows × 111 columns</p>\n</div>"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train[\"df_belgium\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:50.854235100Z",
     "start_time": "2024-01-06T18:22:50.769145600Z"
    }
   },
   "id": "309339a0458df882"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "def impute_nan_values(dfs):\n",
    "    for df in dfs.values():\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "                df[col] = df.groupby(\"season\")[col].transform(lambda x: x.fillna(x.mean()))\n",
    "        df.dropna(inplace=True)\n",
    "impute_nan_values(dfs_train)\n",
    "impute_nan_values(dfs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.424117500Z",
     "start_time": "2024-01-06T18:22:50.802655600Z"
    }
   },
   "id": "6a00c509f5e49cb3"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vojta\\AppData\\Local\\Temp\\ipykernel_29240\\27335406.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_train[country]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_train[country]['FTAG'], dfs_train[country]['FTHG'])]\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "dfs_valid_reg_X = {}\n",
    "dfs_valid_reg_y = {}\n",
    "dfs_train_reg_X = {}\n",
    "dfs_train_reg_y = {}\n",
    "dfs_valid_clas_X = {}\n",
    "dfs_valid_clas_y = {}\n",
    "dfs_train_clas_X = {}\n",
    "dfs_train_clas_y = {}\n",
    "dfs_test_clas_X = {}\n",
    "dfs_test_clas_y = {}\n",
    "dfs_test_reg_X = {}\n",
    "dfs_test_reg_y = {}\n",
    "\n",
    "cols_to_drop = ['FTHG', 'FTAG', 'MatchTeams', 'SameHomeTeam', 'Target', 'Target_regr', 'Target_clas', \"Unnamed: 0\", \"index\", \"season\"]\n",
    "\n",
    "for country in dfs_train:\n",
    "    dfs_train[country] =   dfs_train[country][dfs_train[country][\"season\"] > 17]\n",
    "    dfs_train[country]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_train[country]['FTAG'], dfs_train[country]['FTHG'])]\n",
    "\n",
    "    dfs_valid_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_regr\"]\n",
    "    dfs_valid_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_train_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_train_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_valid_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_clas\"]\n",
    "    dfs_valid_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "for country in dfs_test:\n",
    "    dfs_test_reg_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_test_reg_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_test_clas_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_test_clas_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.569412800Z",
     "start_time": "2024-01-06T18:22:52.433637200Z"
    }
   },
   "id": "bc85102fe8888b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns=[\"country\"])\n",
    "test_results = pd.DataFrame(columns=[\"country\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.611977100Z",
     "start_time": "2024-01-06T18:22:52.566901200Z"
    }
   },
   "id": "adc91403dbf185be"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "train_results[\"country\"] = dfs_train_clas_X.keys()\n",
    "test_results[\"country\"] = dfs_train_clas_X.keys()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.620495300Z",
     "start_time": "2024-01-06T18:22:52.582928600Z"
    }
   },
   "id": "4fbe116bc1af055e"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "        country\n0       belgium\n1       england\n2        france\n3       germany\n4        greece\n5         italy\n6   netherlands\n7      portugal\n8      scotland\n9         spain\n10       turkey",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.622496900Z",
     "start_time": "2024-01-06T18:22:52.600959500Z"
    }
   },
   "id": "9d6866e75a8203e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification task\n",
    "We decided to go with Voting Classifier consisting of 3 classification algorithms -  Gaussian Naive Bayes, RandomForestClassifier & Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382011daf10761e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71023eb496babff"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, multi_class='multinomial', max_iter=10000) ### Cesta je snizit hloubku stromu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:22:52.635013200Z",
     "start_time": "2024-01-06T18:22:52.613978900Z"
    }
   },
   "id": "849fa728bd3dfd6d"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for baseline model on validation data for belgium: 0.5250836120401338\n",
      "F1-score for baseline model on train data for belgium: 0.4727805105667286\n",
      "F1-score for baseline model on validation data for belgium: 0.4300656102874103\n",
      "F1-score for baseline model on test data for belgium: 0.32740886607856273\n",
      " --------\n",
      "Accuracy for baseline model on validation data for england: 0.4506265664160401\n",
      "F1-score for baseline model on train data for england: 0.49817595686333976\n",
      "F1-score for baseline model on validation data for england: 0.4009770162096624\n",
      "F1-score for baseline model on test data for england: 0.3379346465524318\n",
      " --------\n",
      "Accuracy for baseline model on validation data for france: 0.44519621109607577\n",
      "F1-score for baseline model on train data for france: 0.4931800029005838\n",
      "F1-score for baseline model on validation data for france: 0.39574803157157595\n",
      "F1-score for baseline model on test data for france: 0.3803300321503376\n",
      " --------\n",
      "Accuracy for baseline model on validation data for germany: 0.46166666666666667\n",
      "F1-score for baseline model on train data for germany: 0.4832071970653035\n",
      "F1-score for baseline model on validation data for germany: 0.39031516166127184\n",
      "F1-score for baseline model on test data for germany: 0.35923050379572125\n",
      " --------\n",
      "Accuracy for baseline model on validation data for greece: 0.43829787234042555\n",
      "F1-score for baseline model on train data for greece: 0.5753586016680604\n",
      "F1-score for baseline model on validation data for greece: 0.4065590531944734\n",
      "F1-score for baseline model on test data for greece: 0.40270440582762856\n",
      " --------\n",
      "Accuracy for baseline model on validation data for italy: 0.4733969986357435\n",
      "F1-score for baseline model on train data for italy: 0.5115388775374964\n",
      "F1-score for baseline model on validation data for italy: 0.42880773680831624\n",
      "F1-score for baseline model on test data for italy: 0.32459086670232157\n",
      " --------\n",
      "Accuracy for baseline model on validation data for netherlands: 0.5\n",
      "F1-score for baseline model on train data for netherlands: 0.48307040604601764\n",
      "F1-score for baseline model on validation data for netherlands: 0.41300479805639884\n",
      "F1-score for baseline model on test data for netherlands: 0.382110737985891\n",
      " --------\n",
      "Accuracy for baseline model on validation data for portugal: 0.5166666666666667\n",
      "F1-score for baseline model on train data for portugal: 0.5342436399130329\n",
      "F1-score for baseline model on validation data for portugal: 0.46989891831082664\n",
      "F1-score for baseline model on test data for portugal: 0.3894030342172581\n",
      " --------\n",
      "Accuracy for baseline model on validation data for scotland: 0.458950201884253\n",
      "F1-score for baseline model on train data for scotland: 0.523232984018048\n",
      "F1-score for baseline model on validation data for scotland: 0.4209930353919762\n",
      "F1-score for baseline model on test data for scotland: 0.3622946126948024\n",
      " --------\n",
      "Accuracy for baseline model on validation data for spain: 0.45696969696969697\n",
      "F1-score for baseline model on train data for spain: 0.5021771920096386\n",
      "F1-score for baseline model on validation data for spain: 0.4072036289530059\n",
      "F1-score for baseline model on test data for spain: 0.30761124518787697\n",
      " --------\n",
      "Accuracy for baseline model on validation data for turkey: 0.453804347826087\n",
      "F1-score for baseline model on train data for turkey: 0.5145199916711124\n",
      "F1-score for baseline model on validation data for turkey: 0.3809213838115572\n",
      "F1-score for baseline model on test data for turkey: 0.35126060234455975\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_test_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    lr.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = lr.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = lr.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = lr.predict(dfs_test_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"lr\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    test_results.loc[test_results[\"country\"] == country, \"lr\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    \n",
    "    print(f\"Accuracy for baseline model on validation data for {country}: {accuracy_score(dfs_valid_clas_y[country], dfs_valid_predict[country])}\")\n",
    "    print(f\"F1-score for baseline model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:01.062646800Z",
     "start_time": "2024-01-06T18:22:52.629006100Z"
    }
   },
   "id": "e9ec9754db98e2da"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "        country        lr\n0       belgium  0.430066\n1       england  0.400977\n2        france  0.395748\n3       germany  0.390315\n4        greece  0.406559\n5         italy  0.428808\n6   netherlands  0.413005\n7      portugal  0.469899\n8      scotland  0.420993\n9         spain  0.407204\n10       turkey  0.380921",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n      <td>0.430066</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n      <td>0.400977</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n      <td>0.395748</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n      <td>0.390315</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n      <td>0.406559</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n      <td>0.428808</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n      <td>0.413005</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n      <td>0.469899</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n      <td>0.420993</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n      <td>0.407204</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n      <td>0.380921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        country        lr\n0       belgium  0.327409\n1       england  0.337935\n2        france  0.380330\n3       germany  0.359231\n4        greece  0.402704\n5         italy  0.324591\n6   netherlands  0.382111\n7      portugal  0.389403\n8      scotland  0.362295\n9         spain  0.307611\n10       turkey  0.351261",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n      <td>0.327409</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n      <td>0.337935</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n      <td>0.380330</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n      <td>0.359231</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n      <td>0.402704</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n      <td>0.324591</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n      <td>0.382111</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n      <td>0.389403</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n      <td>0.362295</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n      <td>0.307611</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n      <td>0.351261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_results[[\"country\", \"lr\"]])\n",
    "display(test_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:01.097406100Z",
     "start_time": "2024-01-06T18:23:01.063647500Z"
    }
   },
   "id": "9d17b1c40657c011"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Baseline Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594858abcbcb887e"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "rfm = RandomForestClassifier(random_state=42, max_depth=4) ### Cesta je snizit hloubku stromu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:01.138789300Z",
     "start_time": "2024-01-06T18:23:01.077685700Z"
    }
   },
   "id": "f34af3475c665b37"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Random Forest model on train data for belgium: 0.4378488347502432\n",
      "F1-score for baseline Random Forest model on validation data for belgium: 0.40367993153615744\n",
      "F1-score for baseline Random Forest model on test data for belgium: 0.3310089877775468\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for england: 0.32743610288464803\n",
      "F1-score for baseline Random Forest model on validation data for england: 0.32822042822042824\n",
      "F1-score for baseline Random Forest model on test data for england: 0.25990710678210677\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for france: 0.399439097532346\n",
      "F1-score for baseline Random Forest model on validation data for france: 0.35889580164665885\n",
      "F1-score for baseline Random Forest model on test data for france: 0.31746807433157204\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for germany: 0.372131441854511\n",
      "F1-score for baseline Random Forest model on validation data for germany: 0.34824821401428796\n",
      "F1-score for baseline Random Forest model on test data for germany: 0.29252300714059926\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for greece: 0.5556538509862783\n",
      "F1-score for baseline Random Forest model on validation data for greece: 0.4267068695843517\n",
      "F1-score for baseline Random Forest model on test data for greece: 0.35776457669169853\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for italy: 0.41327415680743157\n",
      "F1-score for baseline Random Forest model on validation data for italy: 0.38659834092743434\n",
      "F1-score for baseline Random Forest model on test data for italy: 0.28236000706588943\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for netherlands: 0.4477808145223876\n",
      "F1-score for baseline Random Forest model on validation data for netherlands: 0.41256101842853665\n",
      "F1-score for baseline Random Forest model on test data for netherlands: 0.3476270273505296\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for portugal: 0.4341647661038512\n",
      "F1-score for baseline Random Forest model on validation data for portugal: 0.4064798579636307\n",
      "F1-score for baseline Random Forest model on test data for portugal: 0.3702119172276241\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for scotland: 0.3853766658644708\n",
      "F1-score for baseline Random Forest model on validation data for scotland: 0.362062523352846\n",
      "F1-score for baseline Random Forest model on test data for scotland: 0.31145942732904425\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for spain: 0.4351401456259328\n",
      "F1-score for baseline Random Forest model on validation data for spain: 0.3799301553106476\n",
      "F1-score for baseline Random Forest model on test data for spain: 0.32024608673206867\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for turkey: 0.4750242919611057\n",
      "F1-score for baseline Random Forest model on validation data for turkey: 0.37455521430839306\n",
      "F1-score for baseline Random Forest model on test data for turkey: 0.32067257492968665\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    rfm.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = rfm.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = rfm.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = rfm.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    # Calculate the average depth of all decision trees\n",
    "    average_depth = sum(tree.get_depth() for tree in rfm.estimators_) / len(rfm.estimators_)\n",
    "\n",
    "    # print(f\"Average Depth of Decision Trees for {country}: {average_depth}\")\n",
    "    train_results.loc[train_results[\"country\"] == country, \"rfm\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    # print(f\"Accuracy for baseline model on validation data for {country}: {round(accuracy_score(dfs_valid_clas_y[country], dfs_train_predict[country])*100, ndigits=4)}%\")\n",
    "    print(f\"F1-score for baseline Random Forest model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Random Forest model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Random Forest model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:03.810216900Z",
     "start_time": "2024-01-06T18:23:01.095403900Z"
    }
   },
   "id": "57ec67f0a3906196"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MultinomialNaive Bayes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab31cc39a53d29b"
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:03.824321Z",
     "start_time": "2024-01-06T18:23:03.808906600Z"
    }
   },
   "id": "561c2f796f6b828a"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Multinomial Naive Bayes model on train data for belgium: 0.4255711292491478\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for belgium: 0.40595500070221185\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for belgium: 0.3616061357996842\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for england: 0.47621455325225986\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for england: 0.44302221161866573\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for england: 0.3425640810954196\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for france: 0.48709385058962384\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for france: 0.44166874510691706\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for france: 0.38679821408619536\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for germany: 0.46336642551790447\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for germany: 0.413038350868521\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for germany: 0.3887743081341389\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for greece: 0.5469379241427905\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for greece: 0.4771362271362271\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for greece: 0.4371217243428196\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for italy: 0.5090069527518928\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for italy: 0.45200712455026654\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for italy: 0.3290309760897996\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for netherlands: 0.46890382580073275\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for netherlands: 0.45944954874502475\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for netherlands: 0.37420909062073776\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for portugal: 0.508725820834707\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for portugal: 0.5501816191471364\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for portugal: 0.39751005515271937\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for scotland: 0.4889821013453819\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for scotland: 0.4592283837507023\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for scotland: 0.37222841983952354\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for spain: 0.4831325349594879\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for spain: 0.4409106395416836\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for spain: 0.323316985113257\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for turkey: 0.4566879351403201\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for turkey: 0.4162249678901572\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for turkey: 0.3517916547856667\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    nb.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = nb.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = nb.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = nb.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    train_results.loc[train_results[\"country\"] == country, \"nb\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:04.063260400Z",
     "start_time": "2024-01-06T18:23:03.827323300Z"
    }
   },
   "id": "35ee17d02a2f0cc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3b120342bd53c8"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:04.064260900Z",
     "start_time": "2024-01-06T18:23:04.043412Z"
    }
   },
   "id": "21b749850dc349dc"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline KNeighbors model on train data for belgium: 0.5710600107944851\n",
      "F1-score for baseline KNeighbors model on validation data for belgium: 0.46310744352754857\n",
      "F1-score for baseline KNeighbors model on test data for belgium: 0.3701209330737993\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for england: 0.5827749869996115\n",
      "F1-score for baseline KNeighbors model on validation data for england: 0.3933019717107375\n",
      "F1-score for baseline KNeighbors model on test data for england: 0.31704960062302684\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for france: 0.6045559302159741\n",
      "F1-score for baseline KNeighbors model on validation data for france: 0.4070633684926858\n",
      "F1-score for baseline KNeighbors model on test data for france: 0.3567566253218599\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for germany: 0.5979028682142488\n",
      "F1-score for baseline KNeighbors model on validation data for germany: 0.43189945723011075\n",
      "F1-score for baseline KNeighbors model on test data for germany: 0.384369081377897\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for greece: 0.6100450968042084\n",
      "F1-score for baseline KNeighbors model on validation data for greece: 0.43349309420737986\n",
      "F1-score for baseline KNeighbors model on test data for greece: 0.4091988858064483\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for italy: 0.6109617314835425\n",
      "F1-score for baseline KNeighbors model on validation data for italy: 0.4406765197891998\n",
      "F1-score for baseline KNeighbors model on test data for italy: 0.34909135283549286\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for netherlands: 0.6043986490010157\n",
      "F1-score for baseline KNeighbors model on validation data for netherlands: 0.4385340755913578\n",
      "F1-score for baseline KNeighbors model on test data for netherlands: 0.36545163818899234\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for portugal: 0.6177226470120095\n",
      "F1-score for baseline KNeighbors model on validation data for portugal: 0.5287392482274752\n",
      "F1-score for baseline KNeighbors model on test data for portugal: 0.36460628684321233\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for scotland: 0.6279892871096441\n",
      "F1-score for baseline KNeighbors model on validation data for scotland: 0.4144833697072503\n",
      "F1-score for baseline KNeighbors model on test data for scotland: 0.33775808208797903\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for spain: 0.5783881318696844\n",
      "F1-score for baseline KNeighbors model on validation data for spain: 0.4248594670050399\n",
      "F1-score for baseline KNeighbors model on test data for spain: 0.3431502479472022\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for turkey: 0.5909003584385879\n",
      "F1-score for baseline KNeighbors model on validation data for turkey: 0.3890698194260256\n",
      "F1-score for baseline KNeighbors model on test data for turkey: 0.3555659155659156\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    kn.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = kn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = kn.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = kn.predict(dfs_test_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"kn\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline KNeighbors model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:06.213230600Z",
     "start_time": "2024-01-06T18:23:04.062258400Z"
    }
   },
   "id": "cfd82a05eab38d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1155353c873345e8"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:06.232293500Z",
     "start_time": "2024-01-06T18:23:06.214231900Z"
    }
   },
   "id": "ca95c293c0f6ad91"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline GradientBoostingClassifier model on train data for belgium: 0.8814600471442763\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for belgium: 0.4155311657373229\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for belgium: 0.35122323033677416\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for england: 0.5295075625406082\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for england: 0.3946094169515673\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for england: 0.3031707783141805\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for france: 0.7090153120670831\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for france: 0.3685820972938547\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for france: 0.3360432708936869\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for germany: 0.7031926030103174\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for germany: 0.3778545194744722\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for germany: 0.36830205257602405\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for greece: 0.9205465717660841\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for greece: 0.399046159087038\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for greece: 0.42539089525390894\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for italy: 0.7028600221700362\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for italy: 0.4630471779099632\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for italy: 0.3242430141677597\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for netherlands: 0.8724304216941307\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for netherlands: 0.4118074118074118\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for netherlands: 0.3908338858892993\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for portugal: 0.8830037033701955\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for portugal: 0.4434422785370756\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for portugal: 0.36061631554824114\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for scotland: 0.7188447164686919\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for scotland: 0.4112341441420309\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for scotland: 0.33094553833181656\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for spain: 0.6653139439566722\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for spain: 0.4229057270483012\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for spain: 0.3277078609559428\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for turkey: 0.8624303041639685\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for turkey: 0.3659527245692294\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for turkey: 0.3408994474568245\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    gbc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = gbc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = gbc.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = gbc.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    train_results.loc[train_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:36:37.045509300Z",
     "start_time": "2024-01-06T18:35:35.123886500Z"
    }
   },
   "id": "4cc3cc37f905e8df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Search\n",
    "Use random search to get best parameters for each country"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7270aca6b067226"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forrest "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2464b62827b657ce"
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for best Random Forest model on train data for belgium: 0.40116661703963286\n",
      "F1-score for best Random Forest model on validation data for belgium: 0.40099324419354687\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for belgium: 0.32663673774784885\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for england: 0.35904938284710397\n",
      "F1-score for best Random Forest model on validation data for england: 0.3712762598664237\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for england: 0.28339852727358006\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for france: 0.36262657049763297\n",
      "F1-score for best Random Forest model on validation data for france: 0.3540200681211452\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for france: 0.32003788008727807\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for germany: 0.37735064070560825\n",
      "F1-score for best Random Forest model on validation data for germany: 0.3587058665592697\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for germany: 0.3020702032855594\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for greece: 0.4187132891155036\n",
      "F1-score for best Random Forest model on validation data for greece: 0.35967785967785965\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for greece: 0.3193879990437485\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for italy: 0.3819595521017591\n",
      "F1-score for best Random Forest model on validation data for italy: 0.3831786171574904\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for italy: 0.2856146685073095\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for netherlands: 0.4206435944140862\n",
      "F1-score for best Random Forest model on validation data for netherlands: 0.39863895977640057\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for netherlands: 0.3527145531579466\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for portugal: 0.40996009023078256\n",
      "F1-score for best Random Forest model on validation data for portugal: 0.40760216833836466\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for portugal: 0.36975528697987614\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for scotland: 0.41366288663462214\n",
      "F1-score for best Random Forest model on validation data for scotland: 0.36068562164985335\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for scotland: 0.3144059276911047\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for spain: 0.4906362822053269\n",
      "F1-score for best Random Forest model on validation data for spain: 0.4154167770252582\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for spain: 0.3296001730874527\n",
      " --------\n",
      "F1-score for best Random Forest model on train data for turkey: 0.36259824153274617\n",
      "F1-score for best Random Forest model on validation data for turkey: 0.37159613956941345\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for turkey: 0.3032525483229708\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [i for i in range(1, 30)],\n",
    "    'min_samples_split': [i for i in range(1, 300)],\n",
    "    'min_samples_leaf': [i for i in range(1, 200)]\n",
    "}\n",
    "rfm = RandomForestClassifier(random_state=42)\n",
    "dfs_train_predict_random = {}\n",
    "dfs_valid_predict_random = {}\n",
    "dfs_best_params_rfm = {}\n",
    "random_search = RandomizedSearchCV(estimator=rfm, param_distributions=param_grid, n_iter=40,\n",
    "                                   cv=5, random_state=42, n_jobs=-1)\n",
    "dfs_train_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    \n",
    "    random_search.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    \n",
    "    best_params = random_search.best_params_\n",
    "    best_random_forest = random_search.best_estimator_\n",
    "    \n",
    "    dfs_best_params_rfm[country] = best_params\n",
    "    dfs_train_predict_random[country] = best_random_forest.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict_random[country] = best_random_forest.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = best_random_forest.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    train_results.loc[train_results[\"country\"] == country, \"rfm_rs\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    train_results.loc[train_results[\"country\"] == country, \"best_params\"] = best_params\n",
    "    print(f\"F1-score for best Random Forest model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict_random[country], average='macro')}\")\n",
    "    print(f\"F1-score for best Random Forest model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict_random[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:37:27.272625400Z",
     "start_time": "2024-01-06T18:36:37.051028700Z"
    }
   },
   "id": "bd22878a7300438b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LogReg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9aa65dcc10ce4f8"
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for best LogReg model on train data for belgium: 0.39246176906886615\n",
      "F1-score for best LogReg model on validation data for belgium: 0.39807389937106924\n",
      "F1-score for best LogReg model on test data for belgium: 0.34056982647571415\n",
      " --------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[211], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m dfs_valid_predict \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m country \u001B[38;5;129;01min\u001B[39;00m dfs_train_clas_X\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdfs_train_clas_X\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcountry\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdfs_train_clas_y\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcountry\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     best_params \u001B[38;5;241m=\u001B[39m random_search\u001B[38;5;241m.\u001B[39mbest_params_\n\u001B[0;32m     24\u001B[0m     dfs_best_params_lr[country] \u001B[38;5;241m=\u001B[39m best_params\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1807\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1808\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1809\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1810\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1811\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1812\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1813\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    842\u001B[0m         )\n\u001B[0;32m    843\u001B[0m     )\n\u001B[1;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    867\u001B[0m     )\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\SDKs\\ml_venv\\lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                 # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],     # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga'],        # Algorithm to use in the optimization problem\n",
    "    'max_iter': [8000]               # Maximum number of iterations for optimization\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "dfs_train_predict_random = {}\n",
    "dfs_valid_predict_random = {}\n",
    "dfs_best_params_lr = {}\n",
    "random_search = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, n_iter=10,\n",
    "                                   cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "fs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    random_search.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    dfs_best_params_lr[country] = best_params\n",
    "\n",
    "    best_knn = random_search.best_estimator_\n",
    "    dfs_train_predict[country] = best_knn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = best_knn.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = best_knn.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    train_results.loc[train_results[\"country\"] == country, \"lr_rc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for best LogReg model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for best LogReg model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for best LogReg model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:39:16.833068Z",
     "start_time": "2024-01-06T18:37:27.274626300Z"
    }
   },
   "id": "cdccfd1037befcb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90bfbc58b135c34e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:23:08.552822600Z",
     "start_time": "2024-01-06T18:23:08.550820900Z"
    }
   },
   "id": "e38e9ecb0fa5fd39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed85c4ceff50c438"
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for i, row in train_results.iterrows():\n",
    "    # display(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"rfm_rs\"]])\n",
    "    best_models.append(pd.to_numeric(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"rfm_rs\"]]).nlargest(3).index.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:39:20.596915Z",
     "start_time": "2024-01-06T18:39:20.574021600Z"
    }
   },
   "id": "1143fe15b8757fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def voting_classifier(best_models_country, X_train, y_train, X_val, y_val, country: str, X_test, y_test):\n",
    "    \"\"\"\"\"\"\n",
    "    models = {\n",
    "        \"lr\": LogisticRegression(random_state=42, multi_class='multinomial', max_iter=10000),\n",
    "        \"rfm\": rfm,\n",
    "        \"nb\": nb,\n",
    "        \"kn\": kn,\n",
    "        \"gbc\": gbc,\n",
    "        \"rfm_rs\": RandomForestClassifier(random_state=42),\n",
    "        \"lr_rc\": LogisticRegression(random_state=42)\n",
    "        \n",
    "    }\n",
    "    print(best_models_country)\n",
    "    clf1 = models[best_models_country[0]] if best_models_country[0] != \"rfm_rs\" else models[best_models_country[0]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf2 = models[best_models_country[1]] if best_models_country[1] != \"rfm_rs\" else models[best_models_country[1]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf3 = models[best_models_country[2]] if best_models_country[2] != \"rfm_rs\" else models[best_models_country[2]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    \n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[(best_models_country[0], clf1 ), (best_models_country[1], clf2 ),(best_models_country[2], clf3 )],\n",
    "        voting='hard'\n",
    "    ) \n",
    "    eclf.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_predict = eclf.predict(X_train)\n",
    "    y_val_predict = eclf.predict(X_val)\n",
    "    \n",
    "    y_test_predict = eclf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(f\"F1-score for voting classifier model on train data for {country}: {f1_score(y_train, y_train_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on validation data for {country}: {f1_score(y_val, y_val_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on test data for {country}: {f1_score(y_test, y_test_predict, average='macro')}\\n --------\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:39:21.699950400Z",
     "start_time": "2024-01-06T18:39:21.678665700Z"
    }
   },
   "id": "fdb58c1352b112f8"
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kn', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for belgium: 0.6952013209310076\n",
      "F1-score for voting classifier model on validation data for belgium: 0.46049255036491443\n",
      "F1-score for voting classifier model on test data for belgium: 0.3560412816336987\n",
      " --------\n",
      "['nb', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for england: 0.512238975196527\n",
      "F1-score for voting classifier model on validation data for england: 0.42991395307775315\n",
      "F1-score for voting classifier model on test data for england: 0.335940104983608\n",
      " --------\n",
      "['nb', 'kn', 'lr']\n",
      "F1-score for voting classifier model on train data for france: 0.5333761722346051\n",
      "F1-score for voting classifier model on validation data for france: 0.4248510662873288\n",
      "F1-score for voting classifier model on test data for france: 0.37622863055785283\n",
      " --------\n",
      "['kn', 'nb', 'lr']\n",
      "F1-score for voting classifier model on train data for germany: 0.5225956197823206\n",
      "F1-score for voting classifier model on validation data for germany: 0.4328601733823952\n",
      "F1-score for voting classifier model on test data for germany: 0.39121847626219464\n",
      " --------\n",
      "['nb', 'kn', 'rfm']\n",
      "F1-score for voting classifier model on train data for greece: 0.7297264037880372\n",
      "F1-score for voting classifier model on validation data for greece: 0.4402827429314267\n",
      "F1-score for voting classifier model on test data for greece: 0.44711152289229444\n",
      " --------\n",
      "['gbc', 'rfm_rs', 'nb']\n",
      "F1-score for voting classifier model on train data for italy: 0.5513476604063134\n",
      "F1-score for voting classifier model on validation data for italy: 0.43785769785769785\n",
      "F1-score for voting classifier model on test data for italy: 0.324006129877022\n",
      " --------\n",
      "['nb', 'kn', 'lr']\n",
      "F1-score for voting classifier model on train data for netherlands: 0.5486225685952087\n",
      "F1-score for voting classifier model on validation data for netherlands: 0.4661365866845319\n",
      "F1-score for voting classifier model on test data for netherlands: 0.37458363356586505\n",
      " --------\n",
      "['nb', 'kn', 'lr']\n",
      "F1-score for voting classifier model on train data for portugal: 0.5689923626508993\n",
      "F1-score for voting classifier model on validation data for portugal: 0.5470397703129718\n",
      "F1-score for voting classifier model on test data for portugal: 0.4202906090254528\n",
      " --------\n",
      "['nb', 'lr', 'kn']\n",
      "F1-score for voting classifier model on train data for scotland: 0.5518538744412751\n",
      "F1-score for voting classifier model on validation data for scotland: 0.47759038953627114\n",
      "F1-score for voting classifier model on test data for scotland: 0.3669726945089264\n",
      " --------\n",
      "['nb', 'kn', 'gbc']\n",
      "F1-score for voting classifier model on train data for spain: 0.5923921940039478\n",
      "F1-score for voting classifier model on validation data for spain: 0.45050298448158127\n",
      "F1-score for voting classifier model on test data for spain: 0.3323096595555104\n",
      " --------\n",
      "['nb', 'kn', 'lr']\n",
      "F1-score for voting classifier model on train data for turkey: 0.5480557611070624\n",
      "F1-score for voting classifier model on validation data for turkey: 0.38964785970230614\n",
      "F1-score for voting classifier model on test data for turkey: 0.36162116898657204\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "for i, country in enumerate(dfs_train_clas_X.keys()):\n",
    "    voting_classifier(best_models[i], dfs_train_clas_X[country], dfs_train_clas_y[country], dfs_valid_clas_X[country], dfs_valid_clas_y[country],country, dfs_test_clas_X[country], dfs_test_clas_y[country])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:40:14.152906900Z",
     "start_time": "2024-01-06T18:39:29.239881100Z"
    }
   },
   "id": "876472e32da6e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
