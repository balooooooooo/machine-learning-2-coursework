{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:52.155178200Z",
     "start_time": "2024-01-07T20:52:52.022463600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6491863b8ff047b2"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "dfs_train = {}\n",
    "dfs_test = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:52.269214700Z",
     "start_time": "2024-01-07T20:52:52.036816100Z"
    }
   },
   "id": "67e99dc3b60e9c20"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def drop_columns_with_div(df):\n",
    "    # Get a list of columns containing \"Div\" in their name\n",
    "    div_cols = [col for col in df.columns if 'Div' in col]\n",
    "\n",
    "    # Drop the identified columns\n",
    "    df.drop(columns=div_cols, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:52.304222500Z",
     "start_time": "2024-01-07T20:52:52.052385400Z"
    }
   },
   "id": "b6801d4967639f7"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "for root, directory, files in os.walk(\"data/train_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_train[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            dfs_train[file[:-4]] = drop_columns_with_div(dfs_train[file[:-4]])\n",
    "            try:\n",
    "                dfs_train[file[:-4]] = pd.get_dummies(dfs_train[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "lens_test = 0\n",
    "for root, directory, files in os.walk(\"data/test_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_test[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            dfs_test[file[:-4]] = drop_columns_with_div(dfs_test[file[:-4]])\n",
    "    try:\n",
    "        dfs_test[file[:-4]] = pd.get_dummies(dfs_test[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "    except KeyError:\n",
    "        pass\n",
    "            # lens_test += dfs_test[file[:-4]].shape[0]\n",
    "print(\"---\")\n",
    "lens_orig = 0\n",
    "df_test_y = pd.DataFrame()\n",
    "for root, directory, files in os.walk(\"data/orig_data\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            # print(pd.read_csv(f\"{root}/{file}\").shape)\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            lens_orig += tmp.shape[0]\n",
    "            tmp[\"country\"] = file[:-5]\n",
    "            \n",
    "            df_test_y = pd.concat([df_test_y, tmp], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:16.647186Z",
     "start_time": "2024-01-07T21:07:12.361419700Z"
    }
   },
   "id": "c7af8ff6f8ea0ba"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "dfs_test_copy = dfs_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:56.093860400Z",
     "start_time": "2024-01-07T20:52:56.064106500Z"
    }
   },
   "id": "7482cfca1a53487a"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "for country in df_test_y[\"country\"].unique():\n",
    "    col1 = df_test_y[df_test_y[\"country\"] == country][\"FTHG\"].reset_index()\n",
    "    col2 = df_test_y[df_test_y[\"country\"] == country][\"FTAG\"].reset_index()\n",
    "\n",
    "    target_values = col1[\"FTHG\"] + col2[\"FTAG\"]\n",
    "\n",
    "    dfs_test[f\"df_{country}\"][\"Target_regr\"] = target_values\n",
    "    dfs_test[f\"df_{country}\"][\"FTHG\"] = col1[\"FTHG\"]\n",
    "    dfs_test[f\"df_{country}\"][\"FTAG\"] = col2[\"FTAG\"]\n",
    "    dfs_test[f\"df_{country}\"]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_test[f\"df_{country}\"]['FTAG'], dfs_test[f\"df_{country}\"]['FTHG'])]\n",
    "    dfs_test[f\"df_{country}\"].drop(columns=[\"FTHG\", \"FTAG\", \"Unnamed: 0\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:16.718334600Z",
     "start_time": "2024-01-07T21:07:16.644802500Z"
    }
   },
   "id": "85233e29ca135574"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0        Date  FTHG  FTAG  league  season Time  Avg_away_odds  \\\n0              30  2002-01-01   2.0   0.0     2.0     1.0  NaN       5.775000   \n1              31  2002-01-01   1.0   1.0     0.0     1.0  NaN       3.150000   \n2              32  2002-01-01   1.0   1.0     0.0     1.0  NaN       8.250000   \n3              33  2002-01-01   2.0   4.0     0.0     1.0  NaN       7.666667   \n4              34  2002-01-01   0.0   0.0     1.0     1.0  NaN       4.733333   \n...           ...         ...   ...   ...     ...     ...  ...            ...   \n41324       43301  2016-12-31   0.0   1.0     3.0    16.0  NaN       2.227143   \n41325       43302  2016-12-31   1.0   1.0     3.0    16.0  NaN       2.364286   \n41326       43303  2016-12-31   2.0   4.0     3.0    16.0  NaN       2.814286   \n41327       43304  2016-12-31   4.0   1.0     0.0    16.0  NaN       3.230000   \n41328       43305  2017-12-31   0.0   0.0     0.0    17.0  NaN       1.262857   \n\n       Avg_home_odds  Avg_draw_odds  ...  AwayDrawRatio  \\\n0           1.496667       3.533333  ...       0.000000   \n1           2.116667       3.028333  ...       0.000000   \n2           1.278333       4.616667  ...       0.000000   \n3           1.355000       3.941667  ...       0.000000   \n4           1.621667       3.383333  ...       0.000000   \n...              ...            ...  ...            ...   \n41324       3.317143       3.300000  ...       0.257062   \n41325       3.097143       3.217143  ...       0.263066   \n41326       2.488571       3.325714  ...       0.288501   \n41327       2.387143       3.244286  ...       0.273988   \n41328      11.280000       6.182857  ...       0.192683   \n\n       HomeTeamAvgShotsOnTarget  AwayTeamAvgShotsOnTarget  \\\n0                      6.000000                       NaN   \n1                      9.000000                  3.000000   \n2                      8.000000                  6.000000   \n3                      5.000000                  3.000000   \n4                      4.000000                  7.000000   \n...                         ...                       ...   \n41324                  4.741573                  4.851695   \n41325                  4.769580                  4.428571   \n41326                  3.988528                  4.753945   \n41327                  4.688346                  5.109827   \n41328                  4.582471                  6.556850   \n\n       HomeTeamScoredRatio AwayTeamScoredRatio  Target_regr  Target_clas  \\\n0                 0.500000                 NaN          2.0            1   \n1                 0.800000            0.000000          2.0           -1   \n2                 0.666667            1.000000          2.0           -1   \n3                 1.000000            0.333333          6.0            0   \n4                 0.000000            0.000000          0.0           -1   \n...                    ...                 ...          ...          ...   \n41324             0.455877            0.479381          1.0            0   \n41325             0.481901            0.457237          2.0           -1   \n41326             0.484754            0.480952          6.0            0   \n41327             0.477663            0.469613          5.0            1   \n41328             0.480486            0.635910          0.0           -1   \n\n       Bookie_Prediction_A  Bookie_Prediction_D  Bookie_Prediction_H  \n0                    False                False                 True  \n1                    False                False                 True  \n2                    False                False                 True  \n3                    False                False                 True  \n4                    False                False                 True  \n...                    ...                  ...                  ...  \n41324                 True                False                False  \n41325                 True                False                False  \n41326                False                False                 True  \n41327                False                False                 True  \n41328                 True                False                False  \n\n[41329 rows x 962 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Date</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>league</th>\n      <th>season</th>\n      <th>Time</th>\n      <th>Avg_away_odds</th>\n      <th>Avg_home_odds</th>\n      <th>Avg_draw_odds</th>\n      <th>...</th>\n      <th>AwayDrawRatio</th>\n      <th>HomeTeamAvgShotsOnTarget</th>\n      <th>AwayTeamAvgShotsOnTarget</th>\n      <th>HomeTeamScoredRatio</th>\n      <th>AwayTeamScoredRatio</th>\n      <th>Target_regr</th>\n      <th>Target_clas</th>\n      <th>Bookie_Prediction_A</th>\n      <th>Bookie_Prediction_D</th>\n      <th>Bookie_Prediction_H</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>2002-01-01</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5.775000</td>\n      <td>1.496667</td>\n      <td>3.533333</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>0.500000</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31</td>\n      <td>2002-01-01</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.150000</td>\n      <td>2.116667</td>\n      <td>3.028333</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>3.000000</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>2002-01-01</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>8.250000</td>\n      <td>1.278333</td>\n      <td>4.616667</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>2002-01-01</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>7.666667</td>\n      <td>1.355000</td>\n      <td>3.941667</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>2002-01-01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.733333</td>\n      <td>1.621667</td>\n      <td>3.383333</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>7.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41324</th>\n      <td>43301</td>\n      <td>2016-12-31</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>2.227143</td>\n      <td>3.317143</td>\n      <td>3.300000</td>\n      <td>...</td>\n      <td>0.257062</td>\n      <td>4.741573</td>\n      <td>4.851695</td>\n      <td>0.455877</td>\n      <td>0.479381</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>41325</th>\n      <td>43302</td>\n      <td>2016-12-31</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>2.364286</td>\n      <td>3.097143</td>\n      <td>3.217143</td>\n      <td>...</td>\n      <td>0.263066</td>\n      <td>4.769580</td>\n      <td>4.428571</td>\n      <td>0.481901</td>\n      <td>0.457237</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>41326</th>\n      <td>43303</td>\n      <td>2016-12-31</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>2.814286</td>\n      <td>2.488571</td>\n      <td>3.325714</td>\n      <td>...</td>\n      <td>0.288501</td>\n      <td>3.988528</td>\n      <td>4.753945</td>\n      <td>0.484754</td>\n      <td>0.480952</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>41327</th>\n      <td>43304</td>\n      <td>2016-12-31</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>3.230000</td>\n      <td>2.387143</td>\n      <td>3.244286</td>\n      <td>...</td>\n      <td>0.273988</td>\n      <td>4.688346</td>\n      <td>5.109827</td>\n      <td>0.477663</td>\n      <td>0.469613</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>41328</th>\n      <td>43305</td>\n      <td>2017-12-31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>1.262857</td>\n      <td>11.280000</td>\n      <td>6.182857</td>\n      <td>...</td>\n      <td>0.192683</td>\n      <td>4.582471</td>\n      <td>6.556850</td>\n      <td>0.480486</td>\n      <td>0.635910</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>41329 rows × 962 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train[\"df_england\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:56.171382800Z",
     "start_time": "2024-01-07T20:52:56.127005300Z"
    }
   },
   "id": "309339a0458df882"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def impute_nan_values(dfs):\n",
    "    for df in dfs.values():\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "                df[col] = df.groupby(\"season\")[col].transform(lambda x: x.fillna(x.mean()))\n",
    "        df.dropna(inplace=True)\n",
    "impute_nan_values(dfs_train)\n",
    "impute_nan_values(dfs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:18.624159400Z",
     "start_time": "2024-01-07T21:07:16.815845400Z"
    }
   },
   "id": "6a00c509f5e49cb3"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "           Date  league  season   Time  Avg_away_odds  Avg_home_odds  \\\n0    2022-07-22     1.0    22.0  19:45       1.898333       3.995000   \n1    2022-07-23     1.0    22.0  15:00       4.631667       1.673333   \n2    2022-07-23     1.0    22.0  17:15       2.838333       2.373333   \n3    2022-07-23     1.0    22.0  17:15       3.023333       2.191667   \n4    2022-07-23     1.0    22.0  19:45       1.898333       4.076667   \n..          ...     ...     ...    ...            ...            ...   \n301  2023-04-23     1.0    22.0  17:30       9.054000       1.300000   \n302  2023-04-23     1.0    22.0  17:30      11.662000       1.210000   \n303  2023-04-23     1.0    22.0  17:30       1.542000       5.442000   \n304  2023-04-23     1.0    22.0  17:30       2.492000       2.590000   \n305  2023-04-23     1.0    22.0  17:30       2.188000       2.968000   \n\n     Avg_draw_odds  heavy_favour  Var_away_odds  Var_home_odds  ...  \\\n0         3.520000      2.096667       0.003017       0.064550  ...   \n1         3.933333     -2.958333       0.049417       0.002107  ...   \n2         3.441667     -0.465000       0.001497       0.003307  ...   \n3         3.538333     -0.831667       0.011267       0.001417  ...   \n4         3.411667      2.178333       0.000697       0.022107  ...   \n..             ...           ...            ...            ...  ...   \n301       5.528000     -7.754000       0.363330       0.000050  ...   \n302       6.620000    -10.452000       0.226220       0.000100  ...   \n303       4.340000      3.900000       0.000320       0.043070  ...   \n304       3.628000      0.098000       0.000570       0.004250  ...   \n305       3.694000      0.780000       0.001470       0.002120  ...   \n\n     AwayLossRatio AwayDrawRatio  HomeTeamAvgShotsOnTarget  \\\n0         0.251089      0.256894                  5.079035   \n1         0.386018      0.255319                  4.668905   \n2         0.494382      0.269663                  4.636262   \n3         0.375954      0.257634                  4.712715   \n4         0.455516      0.234875                  4.457536   \n..             ...           ...                       ...   \n301       0.182085      0.195301                  5.618007   \n302       0.161290      0.161290                  5.140558   \n303       0.494382      0.269663                  4.636262   \n304       0.156342      0.225664                  4.632774   \n305       0.375954      0.257634                  4.712715   \n\n     AwayTeamAvgShotsOnTarget  HomeTeamScoredRatio  AwayTeamScoredRatio  \\\n0                    5.140558             0.599895             0.576087   \n1                    4.175931             0.479131             0.382775   \n2                    4.632774             0.486023             0.436929   \n3                    3.212121             0.488789             0.298969   \n4                    5.548387             0.437746             0.720430   \n..                        ...                  ...                  ...   \n301                  4.175931             0.674206             0.382775   \n302                  4.584977             0.576087             0.434226   \n303                  5.548387             0.486023             0.720430   \n304                  5.079035             0.436929             0.599895   \n305                  4.490662             0.488789             0.428992   \n\n     Target_regr  Target_clas  Bookie_Prediction_A  Bookie_Prediction_H  \n0              4           -1                 True                False  \n1              4            1                False                 True  \n2              2            0                False                 True  \n3              2            1                False                 True  \n4              2           -1                 True                False  \n..           ...          ...                  ...                  ...  \n301            7            1                False                 True  \n302            3            0                False                 True  \n303            6            0                 True                False  \n304            5            1                 True                False  \n305            5            0                 True                False  \n\n[306 rows x 110 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>league</th>\n      <th>season</th>\n      <th>Time</th>\n      <th>Avg_away_odds</th>\n      <th>Avg_home_odds</th>\n      <th>Avg_draw_odds</th>\n      <th>heavy_favour</th>\n      <th>Var_away_odds</th>\n      <th>Var_home_odds</th>\n      <th>...</th>\n      <th>AwayLossRatio</th>\n      <th>AwayDrawRatio</th>\n      <th>HomeTeamAvgShotsOnTarget</th>\n      <th>AwayTeamAvgShotsOnTarget</th>\n      <th>HomeTeamScoredRatio</th>\n      <th>AwayTeamScoredRatio</th>\n      <th>Target_regr</th>\n      <th>Target_clas</th>\n      <th>Bookie_Prediction_A</th>\n      <th>Bookie_Prediction_H</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-07-22</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>19:45</td>\n      <td>1.898333</td>\n      <td>3.995000</td>\n      <td>3.520000</td>\n      <td>2.096667</td>\n      <td>0.003017</td>\n      <td>0.064550</td>\n      <td>...</td>\n      <td>0.251089</td>\n      <td>0.256894</td>\n      <td>5.079035</td>\n      <td>5.140558</td>\n      <td>0.599895</td>\n      <td>0.576087</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-07-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>15:00</td>\n      <td>4.631667</td>\n      <td>1.673333</td>\n      <td>3.933333</td>\n      <td>-2.958333</td>\n      <td>0.049417</td>\n      <td>0.002107</td>\n      <td>...</td>\n      <td>0.386018</td>\n      <td>0.255319</td>\n      <td>4.668905</td>\n      <td>4.175931</td>\n      <td>0.479131</td>\n      <td>0.382775</td>\n      <td>4</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-07-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:15</td>\n      <td>2.838333</td>\n      <td>2.373333</td>\n      <td>3.441667</td>\n      <td>-0.465000</td>\n      <td>0.001497</td>\n      <td>0.003307</td>\n      <td>...</td>\n      <td>0.494382</td>\n      <td>0.269663</td>\n      <td>4.636262</td>\n      <td>4.632774</td>\n      <td>0.486023</td>\n      <td>0.436929</td>\n      <td>2</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-07-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:15</td>\n      <td>3.023333</td>\n      <td>2.191667</td>\n      <td>3.538333</td>\n      <td>-0.831667</td>\n      <td>0.011267</td>\n      <td>0.001417</td>\n      <td>...</td>\n      <td>0.375954</td>\n      <td>0.257634</td>\n      <td>4.712715</td>\n      <td>3.212121</td>\n      <td>0.488789</td>\n      <td>0.298969</td>\n      <td>2</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-07-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>19:45</td>\n      <td>1.898333</td>\n      <td>4.076667</td>\n      <td>3.411667</td>\n      <td>2.178333</td>\n      <td>0.000697</td>\n      <td>0.022107</td>\n      <td>...</td>\n      <td>0.455516</td>\n      <td>0.234875</td>\n      <td>4.457536</td>\n      <td>5.548387</td>\n      <td>0.437746</td>\n      <td>0.720430</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>2023-04-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:30</td>\n      <td>9.054000</td>\n      <td>1.300000</td>\n      <td>5.528000</td>\n      <td>-7.754000</td>\n      <td>0.363330</td>\n      <td>0.000050</td>\n      <td>...</td>\n      <td>0.182085</td>\n      <td>0.195301</td>\n      <td>5.618007</td>\n      <td>4.175931</td>\n      <td>0.674206</td>\n      <td>0.382775</td>\n      <td>7</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>2023-04-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:30</td>\n      <td>11.662000</td>\n      <td>1.210000</td>\n      <td>6.620000</td>\n      <td>-10.452000</td>\n      <td>0.226220</td>\n      <td>0.000100</td>\n      <td>...</td>\n      <td>0.161290</td>\n      <td>0.161290</td>\n      <td>5.140558</td>\n      <td>4.584977</td>\n      <td>0.576087</td>\n      <td>0.434226</td>\n      <td>3</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>2023-04-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:30</td>\n      <td>1.542000</td>\n      <td>5.442000</td>\n      <td>4.340000</td>\n      <td>3.900000</td>\n      <td>0.000320</td>\n      <td>0.043070</td>\n      <td>...</td>\n      <td>0.494382</td>\n      <td>0.269663</td>\n      <td>4.636262</td>\n      <td>5.548387</td>\n      <td>0.486023</td>\n      <td>0.720430</td>\n      <td>6</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>2023-04-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:30</td>\n      <td>2.492000</td>\n      <td>2.590000</td>\n      <td>3.628000</td>\n      <td>0.098000</td>\n      <td>0.000570</td>\n      <td>0.004250</td>\n      <td>...</td>\n      <td>0.156342</td>\n      <td>0.225664</td>\n      <td>4.632774</td>\n      <td>5.079035</td>\n      <td>0.436929</td>\n      <td>0.599895</td>\n      <td>5</td>\n      <td>1</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>2023-04-23</td>\n      <td>1.0</td>\n      <td>22.0</td>\n      <td>17:30</td>\n      <td>2.188000</td>\n      <td>2.968000</td>\n      <td>3.694000</td>\n      <td>0.780000</td>\n      <td>0.001470</td>\n      <td>0.002120</td>\n      <td>...</td>\n      <td>0.375954</td>\n      <td>0.257634</td>\n      <td>4.712715</td>\n      <td>4.490662</td>\n      <td>0.488789</td>\n      <td>0.428992</td>\n      <td>5</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>306 rows × 110 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test[\"df_belgium\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:52:57.867656800Z",
     "start_time": "2024-01-07T20:52:57.851449100Z"
    }
   },
   "id": "6e315a8a0232c7d4"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# validation set\n",
    "dfs_valid_reg_X = {}\n",
    "dfs_valid_reg_y = {}\n",
    "dfs_train_reg_X = {}\n",
    "dfs_train_reg_y = {}\n",
    "dfs_valid_clas_X = {}\n",
    "dfs_valid_clas_y = {}\n",
    "dfs_train_clas_X = {}\n",
    "dfs_train_clas_y = {}\n",
    "dfs_test_clas_X = {}\n",
    "dfs_test_clas_y = {}\n",
    "dfs_test_reg_X = {}\n",
    "dfs_test_reg_y = {}\n",
    "\n",
    "cols_to_drop = ['FTHG', 'FTAG', 'MatchTeams', 'SameHomeTeam', 'Target', 'Target_regr', 'Target_clas', \"Unnamed: 0\", \"index\", \"Date\", \"Time\"]\n",
    "\n",
    "for country in dfs_train:\n",
    "    dfs_train[country] =   dfs_train[country][dfs_train[country][\"season\"] > 17]\n",
    "    dfs_train[country]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_train[country]['FTAG'], dfs_train[country]['FTHG'])]\n",
    "\n",
    "    dfs_valid_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_regr\"]\n",
    "    dfs_valid_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_train_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_train_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_valid_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_clas\"]\n",
    "    dfs_valid_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "for country in dfs_test:\n",
    "    dfs_test_reg_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_test_reg_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_test_clas_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_test_clas_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:18.844839100Z",
     "start_time": "2024-01-07T21:07:18.723365100Z"
    }
   },
   "id": "bc85102fe8888b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns=[\"country\"])\n",
    "test_results = pd.DataFrame(columns=[\"country\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:21.850731Z",
     "start_time": "2024-01-07T21:07:21.839203800Z"
    }
   },
   "id": "adc91403dbf185be"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "train_results[\"country\"] = dfs_train_clas_X.keys()\n",
    "test_results[\"country\"] = dfs_train_clas_X.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:22.927303300Z",
     "start_time": "2024-01-07T21:07:22.918200500Z"
    }
   },
   "id": "4fbe116bc1af055e"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "leagues = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    leagues[country] = dfs_test_clas_X[country][\"league\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:24.242528100Z",
     "start_time": "2024-01-07T21:07:24.222051400Z"
    }
   },
   "id": "9539ffac57545ecb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62e081768868c695"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    leagues[country] = dfs_test_clas_X[country][\"league\"]\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_columns = dfs_train_clas_X[country].select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Scale only the numeric columns\n",
    "    dfs_train_clas_X[country][numeric_columns] = scaler.fit_transform(dfs_train_clas_X[country][numeric_columns])\n",
    "    dfs_valid_clas_X[country][numeric_columns] = scaler.transform(dfs_valid_clas_X[country][numeric_columns])\n",
    "    dfs_test_clas_X[country][numeric_columns] = scaler.transform(dfs_test_clas_X[country][numeric_columns])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:06:25.329601900Z",
     "start_time": "2024-01-07T21:06:25.252796Z"
    }
   },
   "id": "9d6866e75a8203e2"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 2., 3.])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leagues[\"england\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:07:28.730358700Z",
     "start_time": "2024-01-07T21:07:28.712377500Z"
    }
   },
   "id": "78c84024ae125029"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification task\n",
    "We decided to go with Voting Classifier consisting of 3 classification algorithms -  Gaussian Naive Bayes, RandomForestClassifier & Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382011daf10761e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71023eb496babff"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on validation data for belgium is 0.40676487255434624 for C = 10 and penalty = l1\n",
      "Best performance on validation data for england is 0.39070511142421166 for C = 10 and penalty = l1\n",
      "Best performance on validation data for france is 0.4037408568443051 for C = 1 and penalty = l1\n",
      "Best performance on validation data for germany is 0.366087962962963 for C = 0.1 and penalty = l1\n",
      "Best performance on validation data for greece is 0.43630099444052933 for C = 0.1 and penalty = l2\n",
      "Best performance on validation data for italy is 0.4450274784647433 for C = 1 and penalty = l1\n",
      "Best performance on validation data for netherlands is 0.4488143754348474 for C = 10 and penalty = l2\n",
      "Best performance on validation data for portugal is 0.4419271748038871 for C = 100 and penalty = l2\n",
      "Best performance on validation data for scotland is 0.39457980191270264 for C = 10 and penalty = l2\n",
      "Best performance on validation data for spain is 0.409007792346506 for C = 100 and penalty = l1\n",
      "Best performance on validation data for turkey is 0.4172581112145979 for C = 1 and penalty = l1\n"
     ]
    }
   ],
   "source": [
    "dfs_test_predict = {}\n",
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_best_params_lr = {}\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]  # Example values for regularization parameter C\n",
    "penalty_values = ['l1', 'l2']  # Example values for penalty (regularization term)\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    max_value = 0\n",
    "    result = [[0 for _ in range(len(penalty_values))] for _ in range(len(C_values))]\n",
    "    max_i = -1\n",
    "    max_j = -1\n",
    "\n",
    "    for i, C in enumerate(C_values):\n",
    "        for j, penalty in enumerate(penalty_values):\n",
    "            lr = LogisticRegression(C=C, penalty=penalty, solver='liblinear', max_iter=10000)\n",
    "            lr.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "            dfs_valid_predict[country] = lr.predict(dfs_valid_clas_X[country])\n",
    "            result[i][j] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    for i in range(len(C_values)):\n",
    "        for j in range(len(penalty_values)):\n",
    "            current_value = result[i][j]\n",
    "            if current_value > max_value:\n",
    "                max_value = current_value\n",
    "                max_i = i\n",
    "                max_j = j\n",
    "\n",
    "    best_C = C_values[max_i]\n",
    "    best_penalty = penalty_values[max_j]\n",
    "    dfs_best_params_lr[country] = {\"C\": best_C, \"penalty\": best_penalty}\n",
    "    test_results.loc[train_results[\"country\"] == country, \"lr\"] = max_value\n",
    "    print(f\"Best performance on validation data for {country} is {max_value} for C = {best_C} and penalty = {best_penalty}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:53:17.382094200Z",
     "start_time": "2024-01-07T20:52:58.167538700Z"
    }
   },
   "id": "4ff2d034a0f25a24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Model\n",
    "\n",
    "Utilization of basic grid search to find best parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594858abcbcb887e"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "rfm = RandomForestClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:53:17.399199700Z",
     "start_time": "2024-01-07T20:53:17.382613800Z"
    }
   },
   "id": "c6f8b8ba6737e767"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "train_results_random_forest = {}\n",
    "def random_forest(params):\n",
    "    rfm.set_params(**params)\n",
    "    rfm.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = rfm.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = rfm.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = rfm.predict(dfs_test_clas_X[country])\n",
    "        \n",
    "    # print(f\"Average Depth of Decision Trees for {country}: {average_depth}\")\n",
    "    train_results[params[\"max_depth\"]] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    result_train = f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')\n",
    "    result_valid = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    result_test =  f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    return result_valid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:53:17.417195900Z",
     "start_time": "2024-01-07T20:53:17.396696100Z"
    }
   },
   "id": "4359c844e840482b"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on validation data for belgium is 0.4469785533615321 for max_depth = 12 and min_samples_split = 2\n",
      "Best performance on validation data for england is 0.40347792539676997 for max_depth = 24 and min_samples_split = 2\n",
      "Best performance on validation data for france is 0.4501253123850208 for max_depth = 23 and min_samples_split = 2\n",
      "Best performance on validation data for germany is 0.4146716155013576 for max_depth = 24 and min_samples_split = 2\n",
      "Best performance on validation data for greece is 0.4473618453930929 for max_depth = 16 and min_samples_split = 5\n",
      "Best performance on validation data for italy is 0.45523025012097684 for max_depth = 17 and min_samples_split = 5\n",
      "Best performance on validation data for netherlands is 0.46151989456288867 for max_depth = 17 and min_samples_split = 2\n",
      "Best performance on validation data for portugal is 0.5231190871478641 for max_depth = 11 and min_samples_split = 2\n",
      "Best performance on validation data for scotland is 0.4111449774066567 for max_depth = 18 and min_samples_split = 2\n",
      "Best performance on validation data for spain is 0.4301976644909747 for max_depth = 20 and min_samples_split = 15\n",
      "Best performance on validation data for turkey is 0.42858167683692866 for max_depth = 15 and min_samples_split = 20\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_best_params_rfm = {}\n",
    "max_depth_values = [i for i in range(10, 25)]\n",
    "min_samples_split_values = [2, 5, 15, 10, 20]\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    max_value = 0\n",
    "    result = [[0 for _ in range(len(min_samples_split_values))] for _ in range(len(max_depth_values))]\n",
    "    max_i = -1\n",
    "    max_j = -1\n",
    "\n",
    "    for i, max_depth in enumerate(max_depth_values):\n",
    "        for j, min_samples_split in enumerate(min_samples_split_values):\n",
    "            result[i][j] = random_forest({\"max_depth\": max_depth + 1, \"min_samples_split\": min_samples_split})\n",
    "\n",
    "    for i in range(len(max_depth_values)):\n",
    "        for j in range(len(min_samples_split_values)):\n",
    "            current_value = result[i][j]\n",
    "            if current_value > max_value:\n",
    "                max_value = current_value\n",
    "                max_i = i\n",
    "                max_j = j\n",
    "\n",
    "    best_max_depth = max_depth_values[max_i]\n",
    "    best_min_samples_split = min_samples_split_values[max_j]\n",
    "    test_results.loc[test_results[\"country\"] == country, \"rfm\"] = max_value\n",
    "    dfs_best_params_rfm[country] = {\"max_depth\": best_max_depth, \"min_samples_split\": best_min_samples_split}\n",
    "\n",
    "    print(f\"Best performance on validation data for {country} is {max_value} for max_depth = {best_max_depth} and min_samples_split = {best_min_samples_split}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:53.896811400Z",
     "start_time": "2024-01-07T20:53:17.416195700Z"
    }
   },
   "id": "5eda447e36f2dcef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MultinomialNaive Bayes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab31cc39a53d29b"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:53.908878100Z",
     "start_time": "2024-01-07T20:57:53.894547Z"
    }
   },
   "id": "561c2f796f6b828a"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Multinomial Naive Bayes model on train data for belgium: 0.42855553042622935\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for belgium: 0.4018406843007843\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for belgium: 0.45186126065854165\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for england: 0.46418180895356476\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for england: 0.37246179695679243\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for england: 0.36166073721735464\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for france: 0.4854222740765013\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for france: 0.41928853654021686\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for france: 0.4240027166856435\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for germany: 0.4373485317229672\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for germany: 0.3643708829774592\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for germany: 0.3890711388135904\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for greece: 0.5220799733666416\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for greece: 0.4224933458976012\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for greece: 0.4847767174460837\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for italy: 0.49242329542328384\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for italy: 0.4189222098523822\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for italy: 0.44459352926362666\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for netherlands: 0.46917565328102234\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for netherlands: 0.45062731766359204\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for netherlands: 0.48018192960578815\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for portugal: 0.5350162846238716\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for portugal: 0.5098417918022241\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for portugal: 0.5614049198253975\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for scotland: 0.486174319995577\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for scotland: 0.3897126008211405\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for scotland: 0.39698336111524907\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for spain: 0.49270701624264684\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for spain: 0.4013407383237712\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for spain: 0.39444361907591735\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for turkey: 0.45602357374613484\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for turkey: 0.39242360151666333\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for turkey: 0.4069677790869961\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # X_train = scaler.fit_transform(dfs_train_clas_X[country])\n",
    "    # X_valid = scaler.fit_transform(dfs_valid_clas_X[country])\n",
    "    # X_test = scaler.fit_transform(dfs_test_clas_X[country])\n",
    "    \n",
    "    nb.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = nb.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = nb.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = nb.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    test_results.loc[test_results[\"country\"] == country, \"nb\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"nb\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:54.114492100Z",
     "start_time": "2024-01-07T20:57:53.910383300Z"
    }
   },
   "id": "35ee17d02a2f0cc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3b120342bd53c8"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:54.159584800Z",
     "start_time": "2024-01-07T20:57:54.114492100Z"
    }
   },
   "id": "21b749850dc349dc"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline KNeighbors model on train data for belgium: 0.5956657523796139\n",
      "F1-score for baseline KNeighbors model on validation data for belgium: 0.4063827335635992\n",
      "F1-score for baseline KNeighbors model on test data for belgium: 0.3828666746990084\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for england: 0.5894038189987336\n",
      "F1-score for baseline KNeighbors model on validation data for england: 0.3672349280260135\n",
      "F1-score for baseline KNeighbors model on test data for england: 0.3526896760514356\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for france: 0.5893777623544728\n",
      "F1-score for baseline KNeighbors model on validation data for france: 0.3873262007695735\n",
      "F1-score for baseline KNeighbors model on test data for france: 0.3935528295993412\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for germany: 0.6071573809090861\n",
      "F1-score for baseline KNeighbors model on validation data for germany: 0.3734543373915255\n",
      "F1-score for baseline KNeighbors model on test data for germany: 0.38647196197503747\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for greece: 0.6254500993998674\n",
      "F1-score for baseline KNeighbors model on validation data for greece: 0.37116236513278733\n",
      "F1-score for baseline KNeighbors model on test data for greece: 0.5050683508525132\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for italy: 0.6205218832130982\n",
      "F1-score for baseline KNeighbors model on validation data for italy: 0.3945067963586482\n",
      "F1-score for baseline KNeighbors model on test data for italy: 0.4108030216004572\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for netherlands: 0.6410906489925271\n",
      "F1-score for baseline KNeighbors model on validation data for netherlands: 0.43825560839023653\n",
      "F1-score for baseline KNeighbors model on test data for netherlands: 0.40813311057745644\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for portugal: 0.6572295207155533\n",
      "F1-score for baseline KNeighbors model on validation data for portugal: 0.4976469294628622\n",
      "F1-score for baseline KNeighbors model on test data for portugal: 0.4731018410349188\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for scotland: 0.6102427179431109\n",
      "F1-score for baseline KNeighbors model on validation data for scotland: 0.3916073663010979\n",
      "F1-score for baseline KNeighbors model on test data for scotland: 0.43605416696601873\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for spain: 0.5731117904565322\n",
      "F1-score for baseline KNeighbors model on validation data for spain: 0.4027106401260378\n",
      "F1-score for baseline KNeighbors model on test data for spain: 0.3696877284361899\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for turkey: 0.5720573710311552\n",
      "F1-score for baseline KNeighbors model on validation data for turkey: 0.34882032781798866\n",
      "F1-score for baseline KNeighbors model on test data for turkey: 0.3493139645147328\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    kn.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = kn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = kn.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = kn.predict(dfs_test_clas_X[country])\n",
    "    test_results.loc[test_results[\"country\"] == country, \"kn\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"kn\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline KNeighbors model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:55.630912100Z",
     "start_time": "2024-01-07T20:57:54.132037600Z"
    }
   },
   "id": "cfd82a05eab38d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1155353c873345e8"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:57:55.657426800Z",
     "start_time": "2024-01-07T20:57:55.632913400Z"
    }
   },
   "id": "ca95c293c0f6ad91"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline GradientBoostingClassifier model on train data for belgium: 0.9732463877195846\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for belgium: 0.4180688162886305\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for belgium: 0.40327229419433985\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for england: 0.5974750127516913\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for england: 0.3831094568174671\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for england: 0.37912762263840727\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for france: 0.8224382023286632\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for france: 0.4069527603870234\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for france: 0.4078353502279672\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for germany: 0.8675345967053584\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for germany: 0.3893512822650736\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for germany: 0.393580028502629\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for greece: 0.9813143899288117\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for greece: 0.4035501978085711\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for greece: 0.49265725670291083\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for italy: 0.7782408667919322\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for italy: 0.45230949359025013\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for italy: 0.4217008026845443\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for netherlands: 0.9688863439671863\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for netherlands: 0.4043145537932185\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for netherlands: 0.45835765975347237\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for portugal: 0.9652965172604615\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for portugal: 0.5238069855408938\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for portugal: 0.4672195251453801\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for scotland: 0.8336812844019129\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for scotland: 0.39440930803765833\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for scotland: 0.3972757077827784\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for spain: 0.7774570326069772\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for spain: 0.3894806042337011\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for spain: 0.40775245711823177\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for turkey: 0.9358555356448984\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for turkey: 0.40925960204035583\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for turkey: 0.4178614698377452\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    gbc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = gbc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = gbc.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = gbc.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    test_results.loc[test_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:58:34.704498800Z",
     "start_time": "2024-01-07T20:57:55.650419100Z"
    }
   },
   "id": "4cc3cc37f905e8df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ada Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9dc950798a686f6"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline AdaBoostClassifier model on train data for belgium: 0.6071820013242607\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for belgium: 0.41347361772033153\n",
      "F1-score for baseline AdaBoostClassifier model on test data for belgium: 0.402224017729969\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for england: 0.44678403450765036\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for england: 0.4015629213123116\n",
      "F1-score for baseline AdaBoostClassifier model on test data for england: 0.36640692210123965\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for france: 0.5385211687702087\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for france: 0.39494952744692063\n",
      "F1-score for baseline AdaBoostClassifier model on test data for france: 0.42741770309795557\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for germany: 0.5390574650849018\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for germany: 0.3907464071453362\n",
      "F1-score for baseline AdaBoostClassifier model on test data for germany: 0.41343476685814834\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for greece: 0.6465980636142613\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for greece: 0.3875281634103149\n",
      "F1-score for baseline AdaBoostClassifier model on test data for greece: 0.4908344403619879\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for italy: 0.5155910752351823\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for italy: 0.4368665753851659\n",
      "F1-score for baseline AdaBoostClassifier model on test data for italy: 0.3933948403589265\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for netherlands: 0.5853889297285524\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for netherlands: 0.44398968852610127\n",
      "F1-score for baseline AdaBoostClassifier model on test data for netherlands: 0.46887926737891256\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for portugal: 0.6625235404896422\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for portugal: 0.4662633847865387\n",
      "F1-score for baseline AdaBoostClassifier model on test data for portugal: 0.45111779018176607\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for scotland: 0.5573658625528904\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for scotland: 0.38586704724083726\n",
      "F1-score for baseline AdaBoostClassifier model on test data for scotland: 0.4406086016040754\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for spain: 0.49440203269997945\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for spain: 0.3971061560944646\n",
      "F1-score for baseline AdaBoostClassifier model on test data for spain: 0.3678031703622419\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for turkey: 0.5790352578278275\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for turkey: 0.43361204959298166\n",
      "F1-score for baseline AdaBoostClassifier model on test data for turkey: 0.44499311174303324\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_test_predict = {}\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    # Create an AdaBoostClassifier\n",
    "    abc = AdaBoostClassifier(n_estimators=50, random_state=42)  # You can adjust the hyperparameters as needed\n",
    "\n",
    "    # Train the AdaBoostClassifier\n",
    "    abc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "\n",
    "    # Make predictions on train, validation, and test sets\n",
    "    dfs_train_predict[country] = abc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = abc.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = abc.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    # Calculate and store F1-score on validation set\n",
    "    test_results.loc[test_results[\"country\"] == country, \"abc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"abc\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    # Print F1-scores\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:58:39.757072900Z",
     "start_time": "2024-01-07T20:58:34.698988700Z"
    }
   },
   "id": "8aa6d89b47e54141"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing Voting Classifier\n",
    "Our voting classifier is designed to use the 3 best performing classifiers and use them for the final prediction "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed85c4ceff50c438"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for i, row in test_results.iterrows():\n",
    "    best_models.append(pd.to_numeric(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"abc\"]]).nlargest(4).index.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:58:39.772134800Z",
     "start_time": "2024-01-07T20:58:39.766633900Z"
    }
   },
   "id": "1143fe15b8757fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def voting_classifier(best_models_country, X_train, y_train, X_val, y_val, country: str, X_test, y_test):\n",
    "    \"\"\"\"\"\"\n",
    "    models = {\n",
    "        \"nb\": nb,\n",
    "        \"kn\": kn,\n",
    "        \"gbc\": GradientBoostingClassifier(random_state=42),\n",
    "        \"rfm\": RandomForestClassifier(random_state=42),\n",
    "        \"lr\": LogisticRegression(random_state=42, solver='liblinear', max_iter=10000),\n",
    "        \"abc\": AdaBoostClassifier()\n",
    "        \n",
    "    }\n",
    "    print(best_models_country)\n",
    "    clf1 = models[best_models_country[0]] if best_models_country[0] != \"rfm\" else models[best_models_country[0]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf2 = models[best_models_country[1]] if best_models_country[1] != \"rfm\" else models[best_models_country[1]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf3 = models[best_models_country[2]] if best_models_country[2] != \"rfm\" else models[best_models_country[2]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    \n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[(best_models_country[0], clf1 ), (best_models_country[1], clf2 ),(best_models_country[2], clf3 )],\n",
    "        voting='soft', weights=[1.6,1,1]\n",
    "    ) \n",
    "    eclf.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_predict = eclf.predict(X_train)\n",
    "    y_val_predict = eclf.predict(X_val)\n",
    "    \n",
    "    y_test_predict = eclf.predict(X_test)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    y_valid_best_model = clf1.predict(X_val)\n",
    "    y_test_best_model = clf1.predict(X_test)\n",
    "    \n",
    "    print(f\"F1-score for voting classifier model on train data for {country}: {f1_score(y_train, y_train_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on validation data for {country}: {f1_score(y_val, y_val_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on test data for {country}: {f1_score(y_test, y_test_predict, average='macro')}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"F1-score for best model ({best_models_country[0]}) on valid data for {country}: {f1_score(y_val, y_valid_best_model, average='macro')}\")\n",
    "    print(f\"F1-score for best model ({best_models_country[0]}) on test data for {country}: {f1_score(y_test, y_test_best_model, average='macro')}\\n --------\")\n",
    "    final_prediction = y_test_predict if f1_score(y_val, y_val_predict, average='macro') > f1_score(y_val, y_valid_best_model, average='macro') else y_test_best_model\n",
    "\n",
    "    return final_prediction, max(f1_score(y_test, y_test_best_model, average='macro'), f1_score(y_val, y_val_predict, average='macro'))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:58:39.801747200Z",
     "start_time": "2024-01-07T20:58:39.775138100Z"
    }
   },
   "id": "fdb58c1352b112f8"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rfm', 'gbc', 'abc', 'lr']\n",
      "F1-score for voting classifier model on train data for belgium: 0.9978463190364916\n",
      "F1-score for voting classifier model on validation data for belgium: 0.4338941580062557\n",
      "F1-score for voting classifier model on test data for belgium: 0.4215135106439454\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for belgium: 0.42281606967515284\n",
      "F1-score for best model (rfm) on test data for belgium: 0.4370509795070321\n",
      " --------\n",
      "['rfm', 'abc', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for england: 0.9078504752768765\n",
      "F1-score for voting classifier model on validation data for england: 0.3892855945580786\n",
      "F1-score for voting classifier model on test data for england: 0.36515996995259137\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for england: 0.3920182822725506\n",
      "F1-score for best model (rfm) on test data for england: 0.37781303618620377\n",
      " --------\n",
      "['rfm', 'nb', 'gbc', 'lr']\n",
      "F1-score for voting classifier model on train data for france: 0.9712747716131406\n",
      "F1-score for voting classifier model on validation data for france: 0.42720436753807217\n",
      "F1-score for voting classifier model on test data for france: 0.4248307572398022\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for france: 0.42709243998761764\n",
      "F1-score for best model (rfm) on test data for france: 0.4123008778035879\n",
      " --------\n",
      "['rfm', 'abc', 'gbc', 'kn']\n",
      "F1-score for voting classifier model on train data for germany: 0.9975730477771481\n",
      "F1-score for voting classifier model on validation data for germany: 0.3982076784566139\n",
      "F1-score for voting classifier model on test data for germany: 0.39602334919272214\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for germany: 0.41245791245791247\n",
      "F1-score for best model (rfm) on test data for germany: 0.4106279101142915\n",
      " --------\n",
      "['rfm', 'lr', 'nb', 'gbc']\n",
      "F1-score for voting classifier model on train data for greece: 0.8297998967779989\n",
      "F1-score for voting classifier model on validation data for greece: 0.42845037494923083\n",
      "F1-score for voting classifier model on test data for greece: 0.5160969298900333\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for greece: 0.4402492548834012\n",
      "F1-score for best model (rfm) on test data for greece: 0.49360018403496664\n",
      " --------\n",
      "['rfm', 'gbc', 'lr', 'abc']\n",
      "F1-score for voting classifier model on train data for italy: 0.8696891904200847\n",
      "F1-score for voting classifier model on validation data for italy: 0.44874209063570475\n",
      "F1-score for voting classifier model on test data for italy: 0.43902600417217047\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for italy: 0.4463380802563246\n",
      "F1-score for best model (rfm) on test data for italy: 0.39131793061694425\n",
      " --------\n",
      "['rfm', 'nb', 'lr', 'abc']\n",
      "F1-score for voting classifier model on train data for netherlands: 0.8194538713974918\n",
      "F1-score for voting classifier model on validation data for netherlands: 0.46408987084529985\n",
      "F1-score for voting classifier model on test data for netherlands: 0.43313546423135457\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for netherlands: 0.4498055677165151\n",
      "F1-score for best model (rfm) on test data for netherlands: 0.4551914904106737\n",
      " --------\n",
      "['gbc', 'rfm', 'nb', 'kn']\n",
      "F1-score for voting classifier model on train data for portugal: 0.9118586707915313\n",
      "F1-score for voting classifier model on validation data for portugal: 0.48973871080773\n",
      "F1-score for voting classifier model on test data for portugal: 0.5256582633053221\n",
      "\n",
      "\n",
      "F1-score for best model (gbc) on valid data for portugal: 0.5238069855408938\n",
      "F1-score for best model (gbc) on test data for portugal: 0.4672195251453801\n",
      " --------\n",
      "['rfm', 'lr', 'gbc', 'kn']\n",
      "F1-score for voting classifier model on train data for scotland: 0.9313361248713594\n",
      "F1-score for voting classifier model on validation data for scotland: 0.3746690608533834\n",
      "F1-score for voting classifier model on test data for scotland: 0.4169736856086028\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for scotland: 0.3903458297532692\n",
      "F1-score for best model (rfm) on test data for scotland: 0.405895631925397\n",
      " --------\n",
      "['rfm', 'lr', 'kn', 'nb']\n",
      "F1-score for voting classifier model on train data for spain: 0.7304609556980529\n",
      "F1-score for voting classifier model on validation data for spain: 0.4378340396416451\n",
      "F1-score for voting classifier model on test data for spain: 0.4018518972801684\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for spain: 0.41347668857230574\n",
      "F1-score for best model (rfm) on test data for spain: 0.42559475511784983\n",
      " --------\n",
      "['abc', 'rfm', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for turkey: 0.6829426169636351\n",
      "F1-score for voting classifier model on validation data for turkey: 0.4026875471139489\n",
      "F1-score for voting classifier model on test data for turkey: 0.41147235055097414\n",
      "\n",
      "\n",
      "F1-score for best model (abc) on valid data for turkey: 0.43361204959298166\n",
      "F1-score for best model (abc) on test data for turkey: 0.44499311174303324\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "final_predict = {}\n",
    "final_f1_score = [0 for _ in range(len(dfs_train_clas_X.keys()))]\n",
    "for i, country in enumerate(dfs_train_clas_X.keys()):\n",
    "    final_predict[country], final_f1_score[i] = voting_classifier(best_models[i], dfs_train_clas_X[country], dfs_train_clas_y[country], dfs_valid_clas_X[country], dfs_valid_clas_y[country],country, dfs_test_clas_X[country], dfs_test_clas_y[country])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:59:10.439783700Z",
     "start_time": "2024-01-07T20:58:39.788961400Z"
    }
   },
   "id": "876472e32da6e2"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4408238628501137"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(final_f1_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:09:56.467182600Z",
     "start_time": "2024-01-07T21:09:56.456874100Z"
    }
   },
   "id": "56ea743663853947"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "     league  season  Avg_away_odds  Avg_home_odds  Avg_draw_odds  \\\n0       0.0     1.0       0.037660       0.230656       0.062541   \n1       0.0     1.0       0.185062       0.044501       0.144174   \n2       0.0     1.0       0.088352       0.100628       0.047070   \n3       0.0     1.0       0.098328       0.086062       0.066162   \n4       0.0     1.0       0.037660       0.237204       0.041145   \n..      ...     ...            ...            ...            ...   \n301     0.0     1.0       0.423548       0.014566       0.459118   \n302     0.0     1.0       0.564192       0.007350       0.674786   \n303     0.0     1.0       0.018443       0.346679       0.224490   \n304     0.0     1.0       0.069675       0.118001       0.083871   \n305     0.0     1.0       0.053281       0.148310       0.096906   \n\n     heavy_favour  Var_away_odds  Var_home_odds  Var_draw_odds  \\\n0        0.668118       0.000210       0.044073       0.017564   \n1        0.505132       0.003490       0.001438       0.114474   \n2        0.585523       0.000103       0.002258       0.041137   \n3        0.573701       0.000793       0.000967       0.040390   \n4        0.670751       0.000046       0.015094       0.036653   \n..            ...            ...            ...            ...   \n301      0.350508       0.025675       0.000034       0.181745   \n302      0.263518       0.015985       0.000068       0.308950   \n303      0.726261       0.000020       0.029407       0.032885   \n304      0.603676       0.000037       0.002902       0.022926   \n305      0.625665       0.000101       0.001447       0.031353   \n\n     LastMatchAwayGoals  ...  AwayWinRatio  AwayLossRatio  AwayDrawRatio  \\\n0              0.166667  ...      0.492017       0.351524       0.561956   \n1              0.666667  ...      0.358663       0.540426       0.558511   \n2              0.166667  ...      0.235955       0.692135       0.589888   \n3              0.000000  ...      0.366412       0.526336       0.563573   \n4              0.166667  ...      0.309609       0.637722       0.513790   \n..                  ...  ...           ...            ...            ...   \n301            0.333333  ...      0.622614       0.254919       0.427221   \n302            0.166667  ...      0.677419       0.225806       0.352823   \n303            0.249409  ...      0.235955       0.692135       0.589888   \n304            0.333333  ...      0.617994       0.218879       0.493639   \n305            0.166667  ...      0.366412       0.526336       0.563573   \n\n     HomeTeamAvgShotsOnTarget  AwayTeamAvgShotsOnTarget  HomeTeamScoredRatio  \\\n0                    0.749167                  0.478548             0.599895   \n1                    0.570051                  0.223118             0.479131   \n2                    0.555794                  0.344088             0.486023   \n3                    0.589184                 -0.032097             0.488789   \n4                    0.477739                  0.586540             0.437746   \n..                        ...                       ...                  ...   \n301                  0.984552                  0.223118             0.674206   \n302                  0.776036                  0.331432             0.576087   \n303                  0.555794                  0.586540             0.486023   \n304                  0.554271                  0.462257             0.436929   \n305                  0.589184                  0.306457             0.488789   \n\n     AwayTeamScoredRatio  Bookie_Prediction_A  Bookie_Prediction_H  \\\n0               0.593822                 True                False   \n1               0.288592                False                 True   \n2               0.374098                False                 True   \n3               0.156267                False                 True   \n4               0.821732                 True                False   \n..                   ...                  ...                  ...   \n301             0.288592                False                 True   \n302             0.369830                False                 True   \n303             0.821732                 True                False   \n304             0.631412                 True                False   \n305             0.361566                 True                False   \n\n     final_predict  \n0                D  \n1                H  \n2                A  \n3                H  \n4                A  \n..             ...  \n301              H  \n302              H  \n303              A  \n304              A  \n305              A  \n\n[306 rows x 105 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>league</th>\n      <th>season</th>\n      <th>Avg_away_odds</th>\n      <th>Avg_home_odds</th>\n      <th>Avg_draw_odds</th>\n      <th>heavy_favour</th>\n      <th>Var_away_odds</th>\n      <th>Var_home_odds</th>\n      <th>Var_draw_odds</th>\n      <th>LastMatchAwayGoals</th>\n      <th>...</th>\n      <th>AwayWinRatio</th>\n      <th>AwayLossRatio</th>\n      <th>AwayDrawRatio</th>\n      <th>HomeTeamAvgShotsOnTarget</th>\n      <th>AwayTeamAvgShotsOnTarget</th>\n      <th>HomeTeamScoredRatio</th>\n      <th>AwayTeamScoredRatio</th>\n      <th>Bookie_Prediction_A</th>\n      <th>Bookie_Prediction_H</th>\n      <th>final_predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.037660</td>\n      <td>0.230656</td>\n      <td>0.062541</td>\n      <td>0.668118</td>\n      <td>0.000210</td>\n      <td>0.044073</td>\n      <td>0.017564</td>\n      <td>0.166667</td>\n      <td>...</td>\n      <td>0.492017</td>\n      <td>0.351524</td>\n      <td>0.561956</td>\n      <td>0.749167</td>\n      <td>0.478548</td>\n      <td>0.599895</td>\n      <td>0.593822</td>\n      <td>True</td>\n      <td>False</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.185062</td>\n      <td>0.044501</td>\n      <td>0.144174</td>\n      <td>0.505132</td>\n      <td>0.003490</td>\n      <td>0.001438</td>\n      <td>0.114474</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0.358663</td>\n      <td>0.540426</td>\n      <td>0.558511</td>\n      <td>0.570051</td>\n      <td>0.223118</td>\n      <td>0.479131</td>\n      <td>0.288592</td>\n      <td>False</td>\n      <td>True</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.088352</td>\n      <td>0.100628</td>\n      <td>0.047070</td>\n      <td>0.585523</td>\n      <td>0.000103</td>\n      <td>0.002258</td>\n      <td>0.041137</td>\n      <td>0.166667</td>\n      <td>...</td>\n      <td>0.235955</td>\n      <td>0.692135</td>\n      <td>0.589888</td>\n      <td>0.555794</td>\n      <td>0.344088</td>\n      <td>0.486023</td>\n      <td>0.374098</td>\n      <td>False</td>\n      <td>True</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.098328</td>\n      <td>0.086062</td>\n      <td>0.066162</td>\n      <td>0.573701</td>\n      <td>0.000793</td>\n      <td>0.000967</td>\n      <td>0.040390</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.366412</td>\n      <td>0.526336</td>\n      <td>0.563573</td>\n      <td>0.589184</td>\n      <td>-0.032097</td>\n      <td>0.488789</td>\n      <td>0.156267</td>\n      <td>False</td>\n      <td>True</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.037660</td>\n      <td>0.237204</td>\n      <td>0.041145</td>\n      <td>0.670751</td>\n      <td>0.000046</td>\n      <td>0.015094</td>\n      <td>0.036653</td>\n      <td>0.166667</td>\n      <td>...</td>\n      <td>0.309609</td>\n      <td>0.637722</td>\n      <td>0.513790</td>\n      <td>0.477739</td>\n      <td>0.586540</td>\n      <td>0.437746</td>\n      <td>0.821732</td>\n      <td>True</td>\n      <td>False</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.423548</td>\n      <td>0.014566</td>\n      <td>0.459118</td>\n      <td>0.350508</td>\n      <td>0.025675</td>\n      <td>0.000034</td>\n      <td>0.181745</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.622614</td>\n      <td>0.254919</td>\n      <td>0.427221</td>\n      <td>0.984552</td>\n      <td>0.223118</td>\n      <td>0.674206</td>\n      <td>0.288592</td>\n      <td>False</td>\n      <td>True</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.564192</td>\n      <td>0.007350</td>\n      <td>0.674786</td>\n      <td>0.263518</td>\n      <td>0.015985</td>\n      <td>0.000068</td>\n      <td>0.308950</td>\n      <td>0.166667</td>\n      <td>...</td>\n      <td>0.677419</td>\n      <td>0.225806</td>\n      <td>0.352823</td>\n      <td>0.776036</td>\n      <td>0.331432</td>\n      <td>0.576087</td>\n      <td>0.369830</td>\n      <td>False</td>\n      <td>True</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.018443</td>\n      <td>0.346679</td>\n      <td>0.224490</td>\n      <td>0.726261</td>\n      <td>0.000020</td>\n      <td>0.029407</td>\n      <td>0.032885</td>\n      <td>0.249409</td>\n      <td>...</td>\n      <td>0.235955</td>\n      <td>0.692135</td>\n      <td>0.589888</td>\n      <td>0.555794</td>\n      <td>0.586540</td>\n      <td>0.486023</td>\n      <td>0.821732</td>\n      <td>True</td>\n      <td>False</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.069675</td>\n      <td>0.118001</td>\n      <td>0.083871</td>\n      <td>0.603676</td>\n      <td>0.000037</td>\n      <td>0.002902</td>\n      <td>0.022926</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.617994</td>\n      <td>0.218879</td>\n      <td>0.493639</td>\n      <td>0.554271</td>\n      <td>0.462257</td>\n      <td>0.436929</td>\n      <td>0.631412</td>\n      <td>True</td>\n      <td>False</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.053281</td>\n      <td>0.148310</td>\n      <td>0.096906</td>\n      <td>0.625665</td>\n      <td>0.000101</td>\n      <td>0.001447</td>\n      <td>0.031353</td>\n      <td>0.166667</td>\n      <td>...</td>\n      <td>0.366412</td>\n      <td>0.526336</td>\n      <td>0.563573</td>\n      <td>0.589184</td>\n      <td>0.306457</td>\n      <td>0.488789</td>\n      <td>0.361566</td>\n      <td>True</td>\n      <td>False</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n<p>306 rows × 105 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test_clas_X[\"belgium\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:03:14.617229500Z",
     "start_time": "2024-01-07T21:03:14.590212500Z"
    }
   },
   "id": "88da80e3831873df"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for country in final_predict:\n",
    "    dfs_test_clas_X[country][\"season\"] = leagues[country]\n",
    "    dfs_test_clas_X[country][\"final_predict\"] = np.where(final_predict[country] == 0, 'A', np.where(final_predict[country] == 1, 'H', 'D'))\n",
    "    df = dfs_test_clas_X[country]\n",
    "    # print(df[\"league\"].unique())\n",
    "    for league in list(df[\"league\"].unique()):\n",
    "        df[df[\"league\"] == league][\"final_predict\"].to_csv(f\"final_results/{country}_{int(league)}.csv\", index= False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:08:59.461908300Z",
     "start_time": "2024-01-07T21:08:59.414981400Z"
    }
   },
   "id": "f65ead21d81d9a6a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5714e184674fcc0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
