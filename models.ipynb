{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:29:54.112979700Z",
     "start_time": "2024-01-05T18:29:52.839132600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6491863b8ff047b2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dfs_train = {}\n",
    "dfs_test = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:29:54.129049200Z",
     "start_time": "2024-01-05T18:29:54.113981Z"
    }
   },
   "id": "67e99dc3b60e9c20"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "for root, directory, files in os.walk(\"data/train_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_train[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            try:\n",
    "                dfs_train[file[:-4]] = pd.get_dummies(dfs_train[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "lens_test = 0\n",
    "for root, directory, files in os.walk(\"data/test_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_test[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            try:\n",
    "                dfs_test[file[:-4]] = pd.get_dummies(dfs_test[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "            lens_test += dfs_test[file[:-4]].shape[0]\n",
    "print(\"---\")\n",
    "lens_orig = 0\n",
    "df_test_y = pd.DataFrame()\n",
    "for root, directory, files in os.walk(\"data/orig_data\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            # print(pd.read_csv(f\"{root}/{file}\").shape)\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            lens_orig += tmp.shape[0]\n",
    "            tmp[\"country\"] = file[:-5]\n",
    "            df_test_y = pd.concat([df_test_y, tmp], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:34.390321400Z",
     "start_time": "2024-01-05T19:11:29.895913Z"
    }
   },
   "id": "c7af8ff6f8ea0ba"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "df_test_y[\"Date\"] = pd.to_datetime(df_test_y[\"Date\"], format = '%d/%m/%Y', dayfirst=True)\n",
    "\n",
    "df_test_y.sort_values(by=\"Date\", inplace=True, ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:34.392322900Z",
     "start_time": "2024-01-05T19:11:34.374445500Z"
    }
   },
   "id": "ff5e531d024f1fd8"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "    Div       Date   Time       HomeTeam     AwayTeam  FTHG  FTAG FTR  HTHG  \\\n0    E1 2022-07-29  20:00   Huddersfield      Burnley     0     1   A   0.0   \n6    E3 2022-07-30  15:00       Rochdale        Crewe     1     2   A   0.0   \n5    E3 2022-07-30  15:00    Northampton   Colchester     3     2   H   1.0   \n4    E3 2022-07-30  15:00  Leyton Orient      Grimsby     2     0   H   0.0   \n11   E2 2022-07-30  15:00        Wycombe       Burton     3     0   H   3.0   \n..   ..        ...    ...            ...          ...   ...   ...  ..   ...   \n375  E0 2023-05-28  16:30        Everton  Bournemouth     1     0   H   0.0   \n372  E0 2023-05-28  16:30      Brentford     Man City     1     0   H   0.0   \n377  E0 2023-05-28  16:30      Leicester     West Ham     2     1   H   1.0   \n378  E0 2023-05-28  16:30     Man United       Fulham     2     1   H   1.0   \n379  E0 2023-05-28  16:30    Southampton    Liverpool     4     4   D   2.0   \n\n     HTAG  ... B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  AvgCAHH  \\\n0     1.0  ...     2.09      1.81   2.10   1.82     2.14     1.83     2.09   \n6     2.0  ...     1.70      2.10   1.78   2.12     1.85     2.17     1.75   \n5     1.0  ...     2.00      1.85   2.02   1.87     2.02     1.92     1.96   \n4     0.0  ...     1.80      2.05   1.79   2.10     1.86     2.10     1.80   \n11    0.0  ...     2.00      1.85   2.00   1.88     2.03     1.92     1.96   \n..    ...  ...      ...       ...    ...    ...      ...      ...      ...   \n375   0.0  ...     2.02      1.77   2.10   1.81     2.17     1.92     2.03   \n372   0.0  ...     1.93      1.97   2.05   1.86     2.28     1.97     2.01   \n377   0.0  ...     1.75      2.05   1.85   2.06     1.90     2.16     1.82   \n378   1.0  ...     1.98      1.92   1.98   1.93     2.07     1.98     1.97   \n379   2.0  ...     1.82      2.08   1.85   2.07     1.96     2.12     1.88   \n\n     AvgCAHA  country      Referee  \n0       1.78  england  J Linington  \n6       2.07  england    A Kitchen  \n5       1.85  england      M Woods  \n4       2.02  england    C Pollard  \n11      1.85  england       G Ward  \n..       ...      ...          ...  \n375     1.83  england    S Attwell  \n372     1.85  england     J Brooks  \n377     2.04  england     S Hooper  \n378     1.89  england      R Jones  \n379     1.98  england    D England  \n\n[2036 rows x 107 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>...</th>\n      <th>B365CAHH</th>\n      <th>B365CAHA</th>\n      <th>PCAHH</th>\n      <th>PCAHA</th>\n      <th>MaxCAHH</th>\n      <th>MaxCAHA</th>\n      <th>AvgCAHH</th>\n      <th>AvgCAHA</th>\n      <th>country</th>\n      <th>Referee</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E1</td>\n      <td>2022-07-29</td>\n      <td>20:00</td>\n      <td>Huddersfield</td>\n      <td>Burnley</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.09</td>\n      <td>1.81</td>\n      <td>2.10</td>\n      <td>1.82</td>\n      <td>2.14</td>\n      <td>1.83</td>\n      <td>2.09</td>\n      <td>1.78</td>\n      <td>england</td>\n      <td>J Linington</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Rochdale</td>\n      <td>Crewe</td>\n      <td>1</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.70</td>\n      <td>2.10</td>\n      <td>1.78</td>\n      <td>2.12</td>\n      <td>1.85</td>\n      <td>2.17</td>\n      <td>1.75</td>\n      <td>2.07</td>\n      <td>england</td>\n      <td>A Kitchen</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Northampton</td>\n      <td>Colchester</td>\n      <td>3</td>\n      <td>2</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.00</td>\n      <td>1.85</td>\n      <td>2.02</td>\n      <td>1.87</td>\n      <td>2.02</td>\n      <td>1.92</td>\n      <td>1.96</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>M Woods</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E3</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Leyton Orient</td>\n      <td>Grimsby</td>\n      <td>2</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.80</td>\n      <td>2.05</td>\n      <td>1.79</td>\n      <td>2.10</td>\n      <td>1.86</td>\n      <td>2.10</td>\n      <td>1.80</td>\n      <td>2.02</td>\n      <td>england</td>\n      <td>C Pollard</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>E2</td>\n      <td>2022-07-30</td>\n      <td>15:00</td>\n      <td>Wycombe</td>\n      <td>Burton</td>\n      <td>3</td>\n      <td>0</td>\n      <td>H</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.00</td>\n      <td>1.85</td>\n      <td>2.00</td>\n      <td>1.88</td>\n      <td>2.03</td>\n      <td>1.92</td>\n      <td>1.96</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>G Ward</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Everton</td>\n      <td>Bournemouth</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.02</td>\n      <td>1.77</td>\n      <td>2.10</td>\n      <td>1.81</td>\n      <td>2.17</td>\n      <td>1.92</td>\n      <td>2.03</td>\n      <td>1.83</td>\n      <td>england</td>\n      <td>S Attwell</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Brentford</td>\n      <td>Man City</td>\n      <td>1</td>\n      <td>0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.93</td>\n      <td>1.97</td>\n      <td>2.05</td>\n      <td>1.86</td>\n      <td>2.28</td>\n      <td>1.97</td>\n      <td>2.01</td>\n      <td>1.85</td>\n      <td>england</td>\n      <td>J Brooks</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Leicester</td>\n      <td>West Ham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.75</td>\n      <td>2.05</td>\n      <td>1.85</td>\n      <td>2.06</td>\n      <td>1.90</td>\n      <td>2.16</td>\n      <td>1.82</td>\n      <td>2.04</td>\n      <td>england</td>\n      <td>S Hooper</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Man United</td>\n      <td>Fulham</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.98</td>\n      <td>1.92</td>\n      <td>1.98</td>\n      <td>1.93</td>\n      <td>2.07</td>\n      <td>1.98</td>\n      <td>1.97</td>\n      <td>1.89</td>\n      <td>england</td>\n      <td>R Jones</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>E0</td>\n      <td>2023-05-28</td>\n      <td>16:30</td>\n      <td>Southampton</td>\n      <td>Liverpool</td>\n      <td>4</td>\n      <td>4</td>\n      <td>D</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.82</td>\n      <td>2.08</td>\n      <td>1.85</td>\n      <td>2.07</td>\n      <td>1.96</td>\n      <td>2.12</td>\n      <td>1.88</td>\n      <td>1.98</td>\n      <td>england</td>\n      <td>D England</td>\n    </tr>\n  </tbody>\n</table>\n<p>2036 rows × 107 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_y[df_test_y[\"country\"]==\"england\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:34.496297600Z",
     "start_time": "2024-01-05T19:11:34.390321400Z"
    }
   },
   "id": "afbab6d2afef5660"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "for country in df_test_y[\"country\"].unique():\n",
    "    col1 = df_test_y[df_test_y[\"country\"] == country][\"FTHG\"].reset_index()\n",
    "    col2 = df_test_y[df_test_y[\"country\"] == country][\"FTAG\"].reset_index()\n",
    "\n",
    "    target_values = col1[\"FTHG\"] + col2[\"FTAG\"]\n",
    "\n",
    "    dfs_test[f\"df_{country}\"][\"Target_regr\"] = target_values\n",
    "    dfs_test[f\"df_{country}\"][\"FTHG\"] = col1[\"FTHG\"]\n",
    "    dfs_test[f\"df_{country}\"][\"FTAG\"] = col2[\"FTAG\"]\n",
    "    dfs_test[f\"df_{country}\"]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_test[f\"df_{country}\"]['FTAG'], dfs_test[f\"df_{country}\"]['FTHG'])]\n",
    "    dfs_test[f\"df_{country}\"].drop(columns=[\"FTHG\", \"FTAG\", \"Unnamed: 0\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:34.528434Z",
     "start_time": "2024-01-05T19:11:34.451721600Z"
    }
   },
   "id": "85233e29ca135574"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  FTHG  FTAG  season  Avg_away_odds  Avg_home_odds  \\\n3275        3575   2.0   0.0    13.0        8.76250        1.32500   \n3276        3576   1.0   0.0    13.0        3.90500        1.89000   \n3277        3577   3.0   0.0    13.0        6.72375        1.42125   \n3278        3578   1.0   1.0    13.0        3.81625        1.88375   \n3279        3579   1.0   1.0    13.0        1.86875        3.93750   \n...          ...   ...   ...     ...            ...            ...   \n5487        5787   3.0   0.0    21.0        3.91400        1.87000   \n5488        5788   2.0   0.0    21.0        7.97000        1.33000   \n5489        5789   2.0   3.0    21.0        1.39200        7.32000   \n5490        5790   5.0   0.0    21.0       11.12800        1.22800   \n5491        5791   0.0   2.0    21.0        1.48200        6.23400   \n\n      Avg_draw_odds  Var_away_odds  Var_home_odds  Var_draw_odds  ...  \\\n3275        4.92000       1.036964       0.000543       0.077629  ...   \n3276        3.44125       0.033914       0.002400       0.024184  ...   \n3277        4.47375       0.826227       0.001270       0.088855  ...   \n3278        3.50750       0.075541       0.001370       0.026736  ...   \n3279        3.48500       0.001870       0.063393       0.017229  ...   \n...             ...            ...            ...            ...  ...   \n5487        3.57400       0.010480       0.001150       0.013380  ...   \n5488        5.29000       0.092000       0.000350       0.045500  ...   \n5489        4.75200       0.001270       0.130750       0.026770  ...   \n5490        6.25200       2.046920       0.000370       0.062520  ...   \n5491        4.43000       0.000470       0.137530       0.019500  ...   \n\n     AwayLossRatio  AwayDrawRatio  HomeTeamAvgShotsOnTarget  \\\n3275      0.438961       0.231169                  5.476707   \n3276      0.438596       0.333333                  4.576918   \n3277      0.575758       0.272727                  5.218518   \n3278      0.445141       0.225705                  4.648457   \n3279      0.297821       0.242131                  4.348466   \n...            ...            ...                       ...   \n5487      0.249637       0.258345                  4.455075   \n5488      0.426195       0.237006                  5.613602   \n5489      0.156342       0.227139                  4.648310   \n5490      0.424581       0.312849                  5.128811   \n5491      0.280415       0.240356                  3.272727   \n\n      AwayTeamAvgShotsOnTarget  HomeTeamScoredRatio  AwayTeamScoredRatio  \\\n3275                  4.584037             0.657729             0.438647   \n3276                  4.727606             0.483425             0.422222   \n3277                  4.326821             0.580016             0.326087   \n3278                  4.629278             0.438108             0.449309   \n3279                  4.981359             0.363636             0.559594   \n...                        ...                  ...                  ...   \n5487                  5.083699             0.436352             0.600632   \n5488                  4.621183             0.673558             0.445467   \n5489                  5.431673             0.486462             0.683400   \n5490                  4.660707             0.574391             0.441392   \n5491                  5.192850             0.312500             0.577734   \n\n      Target_regr  Target_clas  Bookie_Prediction_A  Bookie_Prediction_H  \n3275          2.0            1                False                 True  \n3276          1.0            1                False                 True  \n3277          3.0            1                False                 True  \n3278          2.0           -1                False                 True  \n3279          2.0           -1                 True                False  \n...           ...          ...                  ...                  ...  \n5487          3.0            1                False                 True  \n5488          2.0            1                False                 True  \n5489          5.0            0                 True                False  \n5490          5.0            1                False                 True  \n5491          2.0            0                 True                False  \n\n[2217 rows x 111 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>season</th>\n      <th>Avg_away_odds</th>\n      <th>Avg_home_odds</th>\n      <th>Avg_draw_odds</th>\n      <th>Var_away_odds</th>\n      <th>Var_home_odds</th>\n      <th>Var_draw_odds</th>\n      <th>...</th>\n      <th>AwayLossRatio</th>\n      <th>AwayDrawRatio</th>\n      <th>HomeTeamAvgShotsOnTarget</th>\n      <th>AwayTeamAvgShotsOnTarget</th>\n      <th>HomeTeamScoredRatio</th>\n      <th>AwayTeamScoredRatio</th>\n      <th>Target_regr</th>\n      <th>Target_clas</th>\n      <th>Bookie_Prediction_A</th>\n      <th>Bookie_Prediction_H</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3275</th>\n      <td>3575</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>8.76250</td>\n      <td>1.32500</td>\n      <td>4.92000</td>\n      <td>1.036964</td>\n      <td>0.000543</td>\n      <td>0.077629</td>\n      <td>...</td>\n      <td>0.438961</td>\n      <td>0.231169</td>\n      <td>5.476707</td>\n      <td>4.584037</td>\n      <td>0.657729</td>\n      <td>0.438647</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3276</th>\n      <td>3576</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>3.90500</td>\n      <td>1.89000</td>\n      <td>3.44125</td>\n      <td>0.033914</td>\n      <td>0.002400</td>\n      <td>0.024184</td>\n      <td>...</td>\n      <td>0.438596</td>\n      <td>0.333333</td>\n      <td>4.576918</td>\n      <td>4.727606</td>\n      <td>0.483425</td>\n      <td>0.422222</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3277</th>\n      <td>3577</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>6.72375</td>\n      <td>1.42125</td>\n      <td>4.47375</td>\n      <td>0.826227</td>\n      <td>0.001270</td>\n      <td>0.088855</td>\n      <td>...</td>\n      <td>0.575758</td>\n      <td>0.272727</td>\n      <td>5.218518</td>\n      <td>4.326821</td>\n      <td>0.580016</td>\n      <td>0.326087</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3278</th>\n      <td>3578</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>3.81625</td>\n      <td>1.88375</td>\n      <td>3.50750</td>\n      <td>0.075541</td>\n      <td>0.001370</td>\n      <td>0.026736</td>\n      <td>...</td>\n      <td>0.445141</td>\n      <td>0.225705</td>\n      <td>4.648457</td>\n      <td>4.629278</td>\n      <td>0.438108</td>\n      <td>0.449309</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3279</th>\n      <td>3579</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>1.86875</td>\n      <td>3.93750</td>\n      <td>3.48500</td>\n      <td>0.001870</td>\n      <td>0.063393</td>\n      <td>0.017229</td>\n      <td>...</td>\n      <td>0.297821</td>\n      <td>0.242131</td>\n      <td>4.348466</td>\n      <td>4.981359</td>\n      <td>0.363636</td>\n      <td>0.559594</td>\n      <td>2.0</td>\n      <td>-1</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5487</th>\n      <td>5787</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>3.91400</td>\n      <td>1.87000</td>\n      <td>3.57400</td>\n      <td>0.010480</td>\n      <td>0.001150</td>\n      <td>0.013380</td>\n      <td>...</td>\n      <td>0.249637</td>\n      <td>0.258345</td>\n      <td>4.455075</td>\n      <td>5.083699</td>\n      <td>0.436352</td>\n      <td>0.600632</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5488</th>\n      <td>5788</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>7.97000</td>\n      <td>1.33000</td>\n      <td>5.29000</td>\n      <td>0.092000</td>\n      <td>0.000350</td>\n      <td>0.045500</td>\n      <td>...</td>\n      <td>0.426195</td>\n      <td>0.237006</td>\n      <td>5.613602</td>\n      <td>4.621183</td>\n      <td>0.673558</td>\n      <td>0.445467</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5489</th>\n      <td>5789</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>1.39200</td>\n      <td>7.32000</td>\n      <td>4.75200</td>\n      <td>0.001270</td>\n      <td>0.130750</td>\n      <td>0.026770</td>\n      <td>...</td>\n      <td>0.156342</td>\n      <td>0.227139</td>\n      <td>4.648310</td>\n      <td>5.431673</td>\n      <td>0.486462</td>\n      <td>0.683400</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5490</th>\n      <td>5790</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>11.12800</td>\n      <td>1.22800</td>\n      <td>6.25200</td>\n      <td>2.046920</td>\n      <td>0.000370</td>\n      <td>0.062520</td>\n      <td>...</td>\n      <td>0.424581</td>\n      <td>0.312849</td>\n      <td>5.128811</td>\n      <td>4.660707</td>\n      <td>0.574391</td>\n      <td>0.441392</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5491</th>\n      <td>5791</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>1.48200</td>\n      <td>6.23400</td>\n      <td>4.43000</td>\n      <td>0.000470</td>\n      <td>0.137530</td>\n      <td>0.019500</td>\n      <td>...</td>\n      <td>0.280415</td>\n      <td>0.240356</td>\n      <td>3.272727</td>\n      <td>5.192850</td>\n      <td>0.312500</td>\n      <td>0.577734</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>2217 rows × 111 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train[\"df_belgium\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:08:18.905981800Z",
     "start_time": "2024-01-05T19:08:18.874171600Z"
    }
   },
   "id": "309339a0458df882"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def impute_nan_values(dfs):\n",
    "    for df in dfs.values():\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "                df[col] = df.groupby(\"season\")[col].transform(lambda x: x.fillna(x.mean()))\n",
    "        df.dropna(inplace=True)\n",
    "impute_nan_values(dfs_train)\n",
    "impute_nan_values(dfs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:37.862680800Z",
     "start_time": "2024-01-05T19:11:36.616014300Z"
    }
   },
   "id": "6a00c509f5e49cb3"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# validation set\n",
    "dfs_valid_reg_X = {}\n",
    "dfs_valid_reg_y = {}\n",
    "dfs_train_reg_X = {}\n",
    "dfs_train_reg_y = {}\n",
    "dfs_valid_clas_X = {}\n",
    "dfs_valid_clas_y = {}\n",
    "dfs_train_clas_X = {}\n",
    "dfs_train_clas_y = {}\n",
    "dfs_test_clas_X = {}\n",
    "dfs_test_clas_y = {}\n",
    "dfs_test_reg_X = {}\n",
    "dfs_test_reg_y = {}\n",
    "\n",
    "cols_to_drop = ['FTHG', 'FTAG', 'MatchTeams', 'SameHomeTeam', 'Target', 'Target_regr', 'Target_clas', \"Unnamed: 0\", \"index\"]\n",
    "\n",
    "for country in dfs_train:\n",
    "    dfs_train[country] =   dfs_train[country][  dfs_train[country][\"season\"] > 1]\n",
    "    dfs_train[country]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_train[country]['FTAG'], dfs_train[country]['FTHG'])]\n",
    "\n",
    "    dfs_valid_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_regr\"]\n",
    "    dfs_valid_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_train_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_train_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_valid_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_clas\"]\n",
    "    dfs_valid_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "for country in dfs_test:\n",
    "    dfs_test_reg_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_test_reg_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_test_clas_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_test_clas_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:38.649838900Z",
     "start_time": "2024-01-05T19:11:37.868200500Z"
    }
   },
   "id": "bc85102fe8888b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns=[\"country\"])\n",
    "test_results = pd.DataFrame(columns=[\"country\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:13:10.079177700Z",
     "start_time": "2024-01-05T19:13:10.062023300Z"
    }
   },
   "id": "adc91403dbf185be"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "train_results[\"country\"] = dfs_train_clas_X.keys()\n",
    "test_results[\"country\"] = dfs_train_clas_X.keys()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:13:11.701122400Z",
     "start_time": "2024-01-05T19:13:11.686191300Z"
    }
   },
   "id": "4fbe116bc1af055e"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "        country\n0       belgium\n1       england\n2        france\n3       germany\n4        greece\n5         italy\n6   netherlands\n7      portugal\n8      scotland\n9         spain\n10       turkey",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:03:42.341539900Z",
     "start_time": "2024-01-05T19:03:42.323581600Z"
    }
   },
   "id": "9d6866e75a8203e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification task\n",
    "We decided to go with Voting Classifier consisting of 3 classification algorithms -  Gaussian Naive Bayes, RandomForestClassifier & Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382011daf10761e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71023eb496babff"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, multi_class='multinomial', max_iter=10000) ### Cesta je snizit hloubku stromu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:11:50.854679100Z",
     "start_time": "2024-01-05T19:11:50.847170900Z"
    }
   },
   "id": "849fa728bd3dfd6d"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline model on train data for belgium: 0.43324213514260723\n",
      "F1-score for baseline model on validation data for belgium: 0.40667163551580465\n",
      "F1-score for baseline model on test data for belgium: 0.35256625206326925\n",
      " --------\n",
      "F1-score for baseline model on train data for england: 0.3878445995512461\n",
      "F1-score for baseline model on validation data for england: 0.40085214827836646\n",
      "F1-score for baseline model on test data for england: 0.3040747837058228\n",
      " --------\n",
      "F1-score for baseline model on train data for france: 0.3960376185319634\n",
      "F1-score for baseline model on validation data for france: 0.3793925942828063\n",
      "F1-score for baseline model on test data for france: 0.34674629852675815\n",
      " --------\n",
      "F1-score for baseline model on train data for germany: 0.38280615248837274\n",
      "F1-score for baseline model on validation data for germany: 0.381335522714833\n",
      "F1-score for baseline model on test data for germany: 0.3464547514586684\n",
      " --------\n",
      "F1-score for baseline model on train data for greece: 0.5008389847768439\n",
      "F1-score for baseline model on validation data for greece: 0.4392725622941451\n",
      "F1-score for baseline model on test data for greece: 0.39924432956392825\n",
      " --------\n",
      "F1-score for baseline model on train data for italy: 0.44554760819858613\n",
      "F1-score for baseline model on validation data for italy: 0.4095494535842506\n",
      "F1-score for baseline model on test data for italy: 0.33841004217105763\n",
      " --------\n",
      "F1-score for baseline model on train data for netherlands: 0.4231417064280083\n",
      "F1-score for baseline model on validation data for netherlands: 0.40360312702051376\n",
      "F1-score for baseline model on test data for netherlands: 0.38281717391581066\n",
      " --------\n",
      "F1-score for baseline model on train data for portugal: 0.4740808437259951\n",
      "F1-score for baseline model on validation data for portugal: 0.4456099456099456\n",
      "F1-score for baseline model on test data for portugal: 0.4197285698299897\n",
      " --------\n",
      "F1-score for baseline model on train data for scotland: 0.4116545794966684\n",
      "F1-score for baseline model on validation data for scotland: 0.37026677316711615\n",
      "F1-score for baseline model on test data for scotland: 0.3400067728675264\n",
      " --------\n",
      "F1-score for baseline model on train data for spain: 0.39197068861130074\n",
      "F1-score for baseline model on validation data for spain: 0.3986410440212826\n",
      "F1-score for baseline model on test data for spain: 0.3283817930028143\n",
      " --------\n",
      "F1-score for baseline model on train data for turkey: 0.43132999225399304\n",
      "F1-score for baseline model on validation data for turkey: 0.41761394636534327\n",
      "F1-score for baseline model on test data for turkey: 0.3538426150988078\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_test_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    lr.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = lr.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = lr.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = lr.predict(dfs_test_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"lr\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    test_results.loc[test_results[\"country\"] == country, \"lr\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    \n",
    "    print(f\"F1-score for baseline model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:16:03.487743900Z",
     "start_time": "2024-01-05T19:13:43.284576700Z"
    }
   },
   "id": "e9ec9754db98e2da"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "        country        lr\n0       belgium  0.352566\n1       england  0.304075\n2        france  0.346746\n3       germany  0.346455\n4        greece  0.399244\n5         italy  0.338410\n6   netherlands  0.382817\n7      portugal  0.419729\n8      scotland  0.340007\n9         spain  0.328382\n10       turkey  0.353843",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n      <td>0.352566</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n      <td>0.304075</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n      <td>0.346746</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n      <td>0.346455</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n      <td>0.399244</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n      <td>0.338410</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n      <td>0.382817</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n      <td>0.419729</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n      <td>0.340007</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n      <td>0.328382</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n      <td>0.353843</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        country\n0       belgium\n1       england\n2        france\n3       germany\n4        greece\n5         italy\n6   netherlands\n7      portugal\n8      scotland\n9         spain\n10       turkey",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_results[[\"country\", \"lr\"]])\n",
    "display(test_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:17:05.376733600Z",
     "start_time": "2024-01-05T19:17:05.348162800Z"
    }
   },
   "id": "9d17b1c40657c011"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Baseline Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594858abcbcb887e"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "rfm = RandomForestClassifier(random_state=42, max_depth=12) ### Cesta je snizit hloubku stromu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:35.455071700Z",
     "start_time": "2024-01-05T17:48:35.436828500Z"
    }
   },
   "id": "f34af3475c665b37"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Random Forest model on train data for belgium: 0.9588011524407691\n",
      "F1-score for baseline Random model on validation data for belgium: 0.39641823130666937\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for england: 0.3966153174713389\n",
      "F1-score for baseline Random model on validation data for england: 0.37411725066326\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for france: 0.7360234892340599\n",
      "F1-score for baseline Random model on validation data for france: 0.3957340717952769\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for germany: 0.7086838610863483\n",
      "F1-score for baseline Random model on validation data for germany: 0.35646305565893766\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for greece: 0.9525638619682809\n",
      "F1-score for baseline Random model on validation data for greece: 0.42765271615554656\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for italy: 0.7238808793390804\n",
      "F1-score for baseline Random model on validation data for italy: 0.40969478533638365\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for netherlands: 0.9087532434975677\n",
      "F1-score for baseline Random model on validation data for netherlands: 0.43003641036624546\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for portugal: 0.9394270590266199\n",
      "F1-score for baseline Random model on validation data for portugal: 0.4466302567092895\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for scotland: 0.5784547546543407\n",
      "F1-score for baseline Random model on validation data for scotland: 0.3746326479150907\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for spain: 0.6613454158538911\n",
      "F1-score for baseline Random model on validation data for spain: 0.3995771941380504\n",
      " --------\n",
      "F1-score for baseline Random Forest model on train data for turkey: 0.8707136989587703\n",
      "F1-score for baseline Random model on validation data for turkey: 0.39348469059289953\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    rfm.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = rfm.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = rfm.predict(dfs_valid_clas_X[country])\n",
    "    # Calculate the average depth of all decision trees\n",
    "    average_depth = sum(tree.get_depth() for tree in rfm.estimators_) / len(rfm.estimators_)\n",
    "\n",
    "    # print(f\"Average Depth of Decision Trees for {country}: {average_depth}\")\n",
    "    train_results.loc[train_results[\"country\"] == country, \"rfm\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    # print(f\"Accuracy for baseline model on validation data for {country}: {round(accuracy_score(dfs_valid_clas_y[country], dfs_train_predict[country])*100, ndigits=4)}%\")\n",
    "    print(f\"F1-score for baseline Random Forest model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Random model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:47.058591300Z",
     "start_time": "2024-01-05T17:48:35.452069Z"
    }
   },
   "id": "57ec67f0a3906196"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MultinomialNaive Bayes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab31cc39a53d29b"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:47.076170Z",
     "start_time": "2024-01-05T17:48:47.059105300Z"
    }
   },
   "id": "561c2f796f6b828a"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Multinomial Naive Bayes model on train data for belgium: 0.44324675869002944\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for belgium: 0.47122532022420777\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for england: 0.43686657947350005\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for england: 0.4453726950951576\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for france: 0.4657072628643342\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for france: 0.4265940415167743\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for germany: 0.45486702518673355\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for germany: 0.42009765221039846\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for greece: 0.4968840620068689\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for greece: 0.410870000223942\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for italy: 0.4759553091288777\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for italy: 0.46410366283109133\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for netherlands: 0.47219718235918906\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for netherlands: 0.4753845991574533\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for portugal: 0.4969845412503721\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for portugal: 0.5498575059891112\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for scotland: 0.4542854634239841\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for scotland: 0.4490614172082375\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for spain: 0.4325596085281824\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for spain: 0.40160872009639376\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for turkey: 0.46159637818265215\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for turkey: 0.4271554838464338\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    nb.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = nb.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = nb.predict(dfs_valid_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"nb\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:47.421878800Z",
     "start_time": "2024-01-05T17:48:47.075169200Z"
    }
   },
   "id": "35ee17d02a2f0cc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3b120342bd53c8"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:47.435602700Z",
     "start_time": "2024-01-05T17:48:47.419876900Z"
    }
   },
   "id": "21b749850dc349dc"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline KNeighbors model on train data for belgium: 0.5827771341903464\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for belgium: 0.39529002686897413\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for england: 0.5880131199462958\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for england: 0.37459397413994583\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for france: 0.5991169941551583\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for france: 0.42872444831200207\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for germany: 0.5928079694344451\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for germany: 0.4256512457558741\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for greece: 0.6317739931833501\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for greece: 0.4101284958427816\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for italy: 0.5999432631477486\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for italy: 0.44297561318434187\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for netherlands: 0.5989926874829244\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for netherlands: 0.43141459687995365\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for portugal: 0.6212773816064113\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for portugal: 0.5161809997630894\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for scotland: 0.599506047101046\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for scotland: 0.42718833689952157\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for spain: 0.5977170900085134\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for spain: 0.4232897391436882\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for turkey: 0.5859660496551161\n",
      "F1-score for baseline KNeighbors Naive Bayes model on validation data for turkey: 0.36078405721262863\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    kn.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = kn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = kn.predict(dfs_valid_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"kn\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline KNeighbors model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:52.307693700Z",
     "start_time": "2024-01-05T17:48:47.434602100Z"
    }
   },
   "id": "cfd82a05eab38d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1155353c873345e8"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:48:52.323754900Z",
     "start_time": "2024-01-05T17:48:52.308721900Z"
    }
   },
   "id": "ca95c293c0f6ad91"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline GradientBoostingClassifier model on train data for belgium: 0.682812682426516\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for belgium: 0.3473273269899056\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for england: 0.43290020067473717\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for england: 0.40375494180210986\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for france: 0.5436839244825307\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for france: 0.41419574311996116\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for germany: 0.563480932282584\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for germany: 0.39950312603804194\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for greece: 0.7437732516561878\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for greece: 0.3997208271517622\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for italy: 0.5506030190928843\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for italy: 0.42555024702162064\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for netherlands: 0.6355793215461302\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for netherlands: 0.4848722407905582\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for portugal: 0.7271579552928288\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for portugal: 0.45426900584795327\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for scotland: 0.5163986928648335\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for scotland: 0.4388182153724817\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for spain: 0.5275764715616683\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for spain: 0.4238319112048914\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for turkey: 0.6718312356049395\n",
      "F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for turkey: 0.39078712292998014\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    gbc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = gbc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = gbc.predict(dfs_valid_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:51:39.068768500Z",
     "start_time": "2024-01-05T17:48:52.322753500Z"
    }
   },
   "id": "4cc3cc37f905e8df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Search\n",
    "Use random search to get best parameters for each country"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7270aca6b067226"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forrest "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2464b62827b657ce"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for best random search model on train data for belgium: 0.4013348326540933\n",
      "F1-score for best random search model on validation data for belgium: 0.4097130242825607\n",
      " --------\n",
      "F1-score for best random search model on train data for england: 0.35561755228684744\n",
      "F1-score for best random search model on validation data for england: 0.37083351270954307\n",
      " --------\n",
      "F1-score for best random search model on train data for france: 0.3555419801702601\n",
      "F1-score for best random search model on validation data for france: 0.3558850805059682\n",
      " --------\n",
      "F1-score for best random search model on train data for germany: 0.371584221333324\n",
      "F1-score for best random search model on validation data for germany: 0.35823950599676196\n",
      " --------\n",
      "F1-score for best random search model on train data for greece: 0.43080812944451435\n",
      "F1-score for best random search model on validation data for greece: 0.36575415995705846\n",
      " --------\n",
      "F1-score for best random search model on train data for italy: 0.3697237669491424\n",
      "F1-score for best random search model on validation data for italy: 0.37891491260413496\n",
      " --------\n",
      "F1-score for best random search model on train data for netherlands: 0.4144607945308267\n",
      "F1-score for best random search model on validation data for netherlands: 0.3997685185185185\n",
      " --------\n",
      "F1-score for best random search model on train data for portugal: 0.4418926392058719\n",
      "F1-score for best random search model on validation data for portugal: 0.4151733087659861\n",
      " --------\n",
      "F1-score for best random search model on train data for scotland: 0.3863894611035639\n",
      "F1-score for best random search model on validation data for scotland: 0.36446743176710755\n",
      " --------\n",
      "F1-score for best random search model on train data for spain: 0.37971882767237397\n",
      "F1-score for best random search model on validation data for spain: 0.36153782343786894\n",
      " --------\n",
      "F1-score for best random search model on train data for turkey: 0.3747584263980679\n",
      "F1-score for best random search model on validation data for turkey: 0.3928294147806343\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [i for i in range(1, 30)],\n",
    "    'min_samples_split': [i for i in range(1, 300)],\n",
    "    'min_samples_leaf': [i for i in range(1, 200)]\n",
    "}\n",
    "rfm = RandomForestClassifier(random_state=42)\n",
    "dfs_train_predict_random = {}\n",
    "dfs_valid_predict_random = {}\n",
    "dfs_best_params_rfm = {}\n",
    "random_search = RandomizedSearchCV(estimator=rfm, param_distributions=param_grid, n_iter=40,\n",
    "                                   cv=5, random_state=42, n_jobs=-1)\n",
    "dfs_train_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    \n",
    "    random_search.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    \n",
    "    best_params = random_search.best_params_\n",
    "    best_random_forest = random_search.best_estimator_\n",
    "    \n",
    "    dfs_best_params_rfm[country] = best_params\n",
    "    dfs_train_predict_random[country] = best_random_forest.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict_random[country] = best_random_forest.predict(dfs_valid_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"rfm_rs\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    train_results.loc[train_results[\"country\"] == country, \"best_params\"] = best_params\n",
    "    print(f\"F1-score for best random search model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict_random[country], average='macro')}\")\n",
    "    print(f\"F1-score for best random search model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict_random[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T17:53:54.189714Z",
     "start_time": "2024-01-05T17:51:39.071771200Z"
    }
   },
   "id": "bd22878a7300438b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LogReg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9aa65dcc10ce4f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                 # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],     # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga'],        # Algorithm to use in the optimization problem\n",
    "    'max_iter': [8000]               # Maximum number of iterations for optimization\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "dfs_train_predict_random = {}\n",
    "dfs_valid_predict_random = {}\n",
    "dfs_best_params_lr = {}\n",
    "random_search = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, n_iter=10,\n",
    "                                   cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "fs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    random_search.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    dfs_best_params_lr[country] = best_params\n",
    "\n",
    "    best_knn = random_search.best_estimator_\n",
    "    dfs_train_predict[country] = best_knn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = best_knn.predict(dfs_valid_clas_X[country])\n",
    "    train_results.loc[train_results[\"country\"] == country, \"lr_rc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for best LogReg model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for best LogReg model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-05T18:22:34.497597400Z"
    }
   },
   "id": "cdccfd1037befcb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90bfbc58b135c34e"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "        country        lr       rfm        nb        kn       gbc    rfm_rs  \\\n0       belgium  0.416161  0.396418  0.471225  0.395290  0.347327  0.347327   \n1       england  0.406660  0.374117  0.445373  0.374594  0.403755  0.403755   \n2        france  0.394840  0.395734  0.426594  0.428724  0.414196  0.414196   \n3       germany  0.411588  0.356463  0.420098  0.425651  0.399503  0.399503   \n4        greece  0.435277  0.427653  0.410870  0.410128  0.399721  0.399721   \n5         italy  0.410251  0.409695  0.464104  0.442976  0.425550  0.425550   \n6   netherlands  0.410742  0.430036  0.475385  0.431415  0.484872  0.484872   \n7      portugal  0.439967  0.446630  0.549858  0.516181  0.454269  0.454269   \n8      scotland  0.390106  0.374633  0.449061  0.427188  0.438818  0.438818   \n9         spain  0.411941  0.399577  0.401609  0.423290  0.423832  0.423832   \n10       turkey  0.382845  0.393485  0.427155  0.360784  0.390787  0.390787   \n\n    best_params     lr_rc  \n0           NaN  0.409721  \n1           NaN  0.372328  \n2           NaN  0.355784  \n3           NaN  0.360561  \n4           NaN  0.470566  \n5           NaN  0.384639  \n6           NaN  0.394598  \n7           NaN  0.398209  \n8           NaN  0.362090  \n9           NaN  0.378776  \n10          NaN  0.408670  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>lr</th>\n      <th>rfm</th>\n      <th>nb</th>\n      <th>kn</th>\n      <th>gbc</th>\n      <th>rfm_rs</th>\n      <th>best_params</th>\n      <th>lr_rc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>belgium</td>\n      <td>0.416161</td>\n      <td>0.396418</td>\n      <td>0.471225</td>\n      <td>0.395290</td>\n      <td>0.347327</td>\n      <td>0.347327</td>\n      <td>NaN</td>\n      <td>0.409721</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>england</td>\n      <td>0.406660</td>\n      <td>0.374117</td>\n      <td>0.445373</td>\n      <td>0.374594</td>\n      <td>0.403755</td>\n      <td>0.403755</td>\n      <td>NaN</td>\n      <td>0.372328</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>france</td>\n      <td>0.394840</td>\n      <td>0.395734</td>\n      <td>0.426594</td>\n      <td>0.428724</td>\n      <td>0.414196</td>\n      <td>0.414196</td>\n      <td>NaN</td>\n      <td>0.355784</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>germany</td>\n      <td>0.411588</td>\n      <td>0.356463</td>\n      <td>0.420098</td>\n      <td>0.425651</td>\n      <td>0.399503</td>\n      <td>0.399503</td>\n      <td>NaN</td>\n      <td>0.360561</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greece</td>\n      <td>0.435277</td>\n      <td>0.427653</td>\n      <td>0.410870</td>\n      <td>0.410128</td>\n      <td>0.399721</td>\n      <td>0.399721</td>\n      <td>NaN</td>\n      <td>0.470566</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>italy</td>\n      <td>0.410251</td>\n      <td>0.409695</td>\n      <td>0.464104</td>\n      <td>0.442976</td>\n      <td>0.425550</td>\n      <td>0.425550</td>\n      <td>NaN</td>\n      <td>0.384639</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n      <td>0.410742</td>\n      <td>0.430036</td>\n      <td>0.475385</td>\n      <td>0.431415</td>\n      <td>0.484872</td>\n      <td>0.484872</td>\n      <td>NaN</td>\n      <td>0.394598</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>portugal</td>\n      <td>0.439967</td>\n      <td>0.446630</td>\n      <td>0.549858</td>\n      <td>0.516181</td>\n      <td>0.454269</td>\n      <td>0.454269</td>\n      <td>NaN</td>\n      <td>0.398209</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>scotland</td>\n      <td>0.390106</td>\n      <td>0.374633</td>\n      <td>0.449061</td>\n      <td>0.427188</td>\n      <td>0.438818</td>\n      <td>0.438818</td>\n      <td>NaN</td>\n      <td>0.362090</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spain</td>\n      <td>0.411941</td>\n      <td>0.399577</td>\n      <td>0.401609</td>\n      <td>0.423290</td>\n      <td>0.423832</td>\n      <td>0.423832</td>\n      <td>NaN</td>\n      <td>0.378776</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>turkey</td>\n      <td>0.382845</td>\n      <td>0.393485</td>\n      <td>0.427155</td>\n      <td>0.360784</td>\n      <td>0.390787</td>\n      <td>0.390787</td>\n      <td>NaN</td>\n      <td>0.408670</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:06:15.587628100Z",
     "start_time": "2024-01-05T18:06:15.570571300Z"
    }
   },
   "id": "e38e9ecb0fa5fd39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed85c4ceff50c438"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for i, row in train_results.iterrows():\n",
    "    # display(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"rfm_rs\"]])\n",
    "    best_models.append(pd.to_numeric(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"rfm_rs\", \"lr_rc\"]]).nlargest(3).index.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:04:49.425362400Z",
     "start_time": "2024-01-05T18:04:49.411352900Z"
    }
   },
   "id": "1143fe15b8757fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": lr,\n",
    "    \"rfm\": rfm,\n",
    "    \"nb\": nb,\n",
    "    \"kn\": kn,\n",
    "    \"gbc\": gbc,\n",
    "    \"rfm_rs\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "def voting_classifier(best_models_country, X_train, y_train, X_val, y_val, country: str):\n",
    "    \"\"\"\"\"\"\n",
    "    models = {\n",
    "        \"lr\": lr,\n",
    "        \"rfm\": rfm,\n",
    "        \"nb\": nb,\n",
    "        \"kn\": kn,\n",
    "        \"gbc\": gbc,\n",
    "        \"rfm_rs\": RandomForestClassifier(random_state=42),\n",
    "        \"lr_rc\": LogisticRegression(random_state=42)\n",
    "        \n",
    "    }\n",
    "    print(best_models_country)\n",
    "    clf1 = models[best_models_country[0]] if best_models_country[0] != \"rfm_rs\" else models[best_models_country[0]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf2 = models[best_models_country[1]] if best_models_country[1] != \"rfm_rs\" else models[best_models_country[1]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf3 = models[best_models_country[2]] if best_models_country[2] != \"rfm_rs\" else models[best_models_country[2]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr_rc\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    \n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[(best_models_country[0], clf1 ), (best_models_country[1], clf2 ),(best_models_country[2], clf3 )],\n",
    "        voting='hard'\n",
    "    ) \n",
    "    eclf.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_predict = eclf.predict(X_train)\n",
    "    y_val_predict = eclf.predict(X_val)\n",
    "    \n",
    "    \n",
    "    print(f\"F1-score for best random search model on train data for {country}: {f1_score(y_train, y_train_predict, average='macro')}\")\n",
    "    print(f\"F1-score for best random search model on validation data for {country}: {f1_score(y_val, y_val_predict, average='macro')}\\n --------\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:04:50.472394Z",
     "start_time": "2024-01-05T18:04:50.455472500Z"
    }
   },
   "id": "fdb58c1352b112f8"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nb', 'lr', 'lr_rc']\n",
      "F1-score for best random search model on train data for belgium: 0.4373195170022232\n",
      "F1-score for best random search model on validation data for belgium: 0.4479299321271508\n",
      " --------\n",
      "['nb', 'lr', 'gbc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\SDKs\\ml_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, country in enumerate(dfs_train_clas_X.keys()):\n",
    "    voting_classifier(best_models[i], dfs_train_clas_X[country], dfs_train_clas_y[country], dfs_valid_clas_X[country], dfs_valid_clas_y[country],country)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T18:04:58.228411200Z",
     "start_time": "2024-01-05T18:04:52.893590300Z"
    }
   },
   "id": "876472e32da6e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
