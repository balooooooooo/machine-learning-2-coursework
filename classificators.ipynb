{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:52.956339300Z",
     "start_time": "2024-01-07T22:02:52.804636Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6491863b8ff047b2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dfs_train = {}\n",
    "dfs_test = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:53.083762600Z",
     "start_time": "2024-01-07T22:02:52.823730600Z"
    }
   },
   "id": "67e99dc3b60e9c20"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def drop_columns_with_div(df):\n",
    "    # Get a list of columns containing \"Div\" in their name\n",
    "    div_cols = [col for col in df.columns if 'Div' in col]\n",
    "\n",
    "    # Drop the identified columns\n",
    "    df.drop(columns=div_cols, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:53.122299600Z",
     "start_time": "2024-01-07T22:02:52.837572700Z"
    }
   },
   "id": "b6801d4967639f7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "for root, directory, files in os.walk(\"data/train_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_train[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            dfs_train[file[:-4]] = drop_columns_with_div(dfs_train[file[:-4]])\n",
    "            try:\n",
    "                dfs_train[file[:-4]] = pd.get_dummies(dfs_train[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "            except KeyError:\n",
    "                pass\n",
    "lens_test = 0\n",
    "for root, directory, files in os.walk(\"data/test_preprocessed\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            dfs_test[file[:-4]] = pd.read_csv(f\"{root}/{file}\")\n",
    "            dfs_test[file[:-4]] = drop_columns_with_div(dfs_test[file[:-4]])\n",
    "    try:\n",
    "        dfs_test[file[:-4]] = pd.get_dummies(dfs_test[file[:-4]], columns=[\"Avg_bookie_prediction\"], prefix='Bookie_Prediction')\n",
    "    except KeyError:\n",
    "        pass\n",
    "            # lens_test += dfs_test[file[:-4]].shape[0]\n",
    "print(\"---\")\n",
    "lens_orig = 0\n",
    "df_test_y = pd.DataFrame()\n",
    "for root, directory, files in os.walk(\"data/orig_data\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            # print(pd.read_csv(f\"{root}/{file}\").shape)\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            lens_orig += tmp.shape[0]\n",
    "            tmp[\"country\"] = file[:-5]\n",
    "            \n",
    "            df_test_y = pd.concat([df_test_y, tmp], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:57.255543500Z",
     "start_time": "2024-01-07T22:02:52.856157300Z"
    }
   },
   "id": "c7af8ff6f8ea0ba"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dfs_test_copy = dfs_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:57.265825300Z",
     "start_time": "2024-01-07T22:02:57.248537400Z"
    }
   },
   "id": "7482cfca1a53487a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "for country in df_test_y[\"country\"].unique():\n",
    "    col1 = df_test_y[df_test_y[\"country\"] == country][\"FTHG\"].reset_index()\n",
    "    col2 = df_test_y[df_test_y[\"country\"] == country][\"FTAG\"].reset_index()\n",
    "\n",
    "    target_values = col1[\"FTHG\"] + col2[\"FTAG\"]\n",
    "\n",
    "    dfs_test[f\"df_{country}\"][\"Target_regr\"] = target_values\n",
    "    dfs_test[f\"df_{country}\"][\"FTHG\"] = col1[\"FTHG\"]\n",
    "    dfs_test[f\"df_{country}\"][\"FTAG\"] = col2[\"FTAG\"]\n",
    "    dfs_test[f\"df_{country}\"]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_test[f\"df_{country}\"]['FTAG'], dfs_test[f\"df_{country}\"]['FTHG'])]\n",
    "    dfs_test[f\"df_{country}\"].drop(columns=[\"FTHG\", \"FTAG\", \"Unnamed: 0\"], inplace=True)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:57.324921500Z",
     "start_time": "2024-01-07T22:02:57.266935800Z"
    }
   },
   "id": "85233e29ca135574"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def impute_nan_values(dfs):\n",
    "    for df in dfs.values():\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "                df[col] = df.groupby(\"season\")[col].transform(lambda x: x.fillna(x.mean()))\n",
    "        df.dropna(inplace=True)\n",
    "impute_nan_values(dfs_train)\n",
    "impute_nan_values(dfs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.384415300Z",
     "start_time": "2024-01-07T22:02:57.342966200Z"
    }
   },
   "id": "6a00c509f5e49cb3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# validation set\n",
    "dfs_valid_reg_X = {}\n",
    "dfs_valid_reg_y = {}\n",
    "dfs_train_reg_X = {}\n",
    "dfs_train_reg_y = {}\n",
    "dfs_valid_clas_X = {}\n",
    "dfs_valid_clas_y = {}\n",
    "dfs_train_clas_X = {}\n",
    "dfs_train_clas_y = {}\n",
    "dfs_test_clas_X = {}\n",
    "dfs_test_clas_y = {}\n",
    "dfs_test_reg_X = {}\n",
    "dfs_test_reg_y = {}\n",
    "\n",
    "cols_to_drop = ['FTHG', 'FTAG', 'MatchTeams', 'SameHomeTeam', 'Target', 'Target_regr', 'Target_clas', \"Unnamed: 0\", \"index\", \"Date\", \"Time\"]\n",
    "\n",
    "for country in dfs_train:\n",
    "    dfs_train[country] = dfs_train[country][dfs_train[country][\"season\"] > 17]\n",
    "    dfs_train[country]['Target_clas'] = [0 if a > h else 1 if h > a else -1 for a, h in zip(dfs_train[country]['FTAG'], dfs_train[country]['FTHG'])]\n",
    "\n",
    "    dfs_valid_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_regr\"]\n",
    "    dfs_valid_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_reg_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_train_reg_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    dfs_train_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_train_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_valid_clas_y[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21][\"Target_clas\"]\n",
    "    dfs_valid_clas_X[country[3:]] = dfs_train[country][dfs_train[country][\"season\"] == 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "for country in dfs_test:\n",
    "    dfs_test_reg_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_regr\"]\n",
    "    dfs_test_reg_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    dfs_test_clas_y[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21][\"Target_clas\"]\n",
    "    dfs_test_clas_X[country[3:]] = dfs_test[country][dfs_test[country][\"season\"] != 21].drop(columns=cols_to_drop, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.507794300Z",
     "start_time": "2024-01-07T22:02:59.382872100Z"
    }
   },
   "id": "bc85102fe8888b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns=[\"country\"])\n",
    "test_results = pd.DataFrame(columns=[\"country\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.525462700Z",
     "start_time": "2024-01-07T22:02:59.504277100Z"
    }
   },
   "id": "adc91403dbf185be"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_results[\"country\"] = dfs_train_clas_X.keys()\n",
    "test_results[\"country\"] = dfs_train_clas_X.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.553510600Z",
     "start_time": "2024-01-07T22:02:59.517954900Z"
    }
   },
   "id": "4fbe116bc1af055e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "leagues = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    leagues[country] = dfs_test_clas_X[country][\"league\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.553510600Z",
     "start_time": "2024-01-07T22:02:59.533479700Z"
    }
   },
   "id": "9539ffac57545ecb"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    leagues[country] = dfs_test_clas_X[country][\"league\"]\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_columns = dfs_train_clas_X[country].select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Scale only the numeric columns\n",
    "    dfs_train_clas_X[country][numeric_columns] = scaler.fit_transform(dfs_train_clas_X[country][numeric_columns])\n",
    "    dfs_valid_clas_X[country][numeric_columns] = scaler.transform(dfs_valid_clas_X[country][numeric_columns])\n",
    "    dfs_test_clas_X[country][numeric_columns] = scaler.transform(dfs_test_clas_X[country][numeric_columns])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.664000300Z",
     "start_time": "2024-01-07T22:02:59.549505600Z"
    }
   },
   "id": "9d6866e75a8203e2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 2., 3.])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leagues[\"england\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:02:59.674849300Z",
     "start_time": "2024-01-07T22:02:59.658994700Z"
    }
   },
   "id": "78c84024ae125029"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification task\n",
    "We decided to go with Voting Classifier consisting of 3 classification algorithms -  Gaussian Naive Bayes, RandomForestClassifier & Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382011daf10761e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71023eb496babff"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on validation data for belgium is 0.40676487255434624 for C = 10 and penalty = l1\n",
      "Best performance on validation data for england is 0.39070511142421166 for C = 10 and penalty = l1\n",
      "Best performance on validation data for france is 0.4037236424660721 for C = 1 and penalty = l1\n",
      "Best performance on validation data for germany is 0.366087962962963 for C = 0.1 and penalty = l1\n",
      "Best performance on validation data for greece is 0.43630099444052933 for C = 0.1 and penalty = l2\n",
      "Best performance on validation data for italy is 0.4450274784647433 for C = 1 and penalty = l1\n",
      "Best performance on validation data for netherlands is 0.4488143754348474 for C = 10 and penalty = l2\n",
      "Best performance on validation data for portugal is 0.4419271748038871 for C = 100 and penalty = l2\n",
      "Best performance on validation data for scotland is 0.39457980191270264 for C = 10 and penalty = l2\n",
      "Best performance on validation data for spain is 0.409007792346506 for C = 100 and penalty = l1\n",
      "Best performance on validation data for turkey is 0.4172581112145979 for C = 1 and penalty = l1\n"
     ]
    }
   ],
   "source": [
    "dfs_test_predict = {}\n",
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_best_params_lr = {}\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]  # Example values for regularization parameter C\n",
    "penalty_values = ['l1', 'l2']  # Example values for penalty (regularization term)\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    max_value = 0\n",
    "    result = [[0 for _ in range(len(penalty_values))] for _ in range(len(C_values))]\n",
    "    max_i = -1\n",
    "    max_j = -1\n",
    "\n",
    "    for i, C in enumerate(C_values):\n",
    "        for j, penalty in enumerate(penalty_values):\n",
    "            lr = LogisticRegression(C=C, penalty=penalty, solver='liblinear', max_iter=10000)\n",
    "            lr.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "            dfs_valid_predict[country] = lr.predict(dfs_valid_clas_X[country])\n",
    "            result[i][j] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "\n",
    "    for i in range(len(C_values)):\n",
    "        for j in range(len(penalty_values)):\n",
    "            current_value = result[i][j]\n",
    "            if current_value > max_value:\n",
    "                max_value = current_value\n",
    "                max_i = i\n",
    "                max_j = j\n",
    "\n",
    "    best_C = C_values[max_i]\n",
    "    best_penalty = penalty_values[max_j]\n",
    "    dfs_best_params_lr[country] = {\"C\": best_C, \"penalty\": best_penalty}\n",
    "    test_results.loc[train_results[\"country\"] == country, \"lr\"] = max_value\n",
    "    print(f\"Best performance on validation data for {country} is {max_value} for C = {best_C} and penalty = {best_penalty}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:03:18.801798400Z",
     "start_time": "2024-01-07T22:02:59.681869900Z"
    }
   },
   "id": "4ff2d034a0f25a24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Model\n",
    "\n",
    "Utilization of basic grid search to find best parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594858abcbcb887e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "rfm = RandomForestClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:03:18.834315Z",
     "start_time": "2024-01-07T22:03:18.803307500Z"
    }
   },
   "id": "c6f8b8ba6737e767"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_results_random_forest = {}\n",
    "def random_forest(params):\n",
    "    rfm.set_params(**params)\n",
    "    rfm.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = rfm.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = rfm.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = rfm.predict(dfs_test_clas_X[country])\n",
    "        \n",
    "    # print(f\"Average Depth of Decision Trees for {country}: {average_depth}\")\n",
    "    train_results[params[\"max_depth\"]] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    result_train = f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')\n",
    "    result_valid = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    result_test =  f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    return result_valid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:03:18.834315Z",
     "start_time": "2024-01-07T22:03:18.817579200Z"
    }
   },
   "id": "4359c844e840482b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on validation data for belgium is 0.4469785533615321 for max_depth = 12 and min_samples_split = 2\n",
      "Best performance on validation data for england is 0.40347792539676997 for max_depth = 24 and min_samples_split = 2\n",
      "Best performance on validation data for france is 0.4501253123850208 for max_depth = 23 and min_samples_split = 2\n",
      "Best performance on validation data for germany is 0.4146716155013576 for max_depth = 24 and min_samples_split = 2\n",
      "Best performance on validation data for greece is 0.4473618453930929 for max_depth = 16 and min_samples_split = 5\n",
      "Best performance on validation data for italy is 0.45523025012097684 for max_depth = 17 and min_samples_split = 5\n",
      "Best performance on validation data for netherlands is 0.46151989456288867 for max_depth = 17 and min_samples_split = 2\n",
      "Best performance on validation data for portugal is 0.5231190871478641 for max_depth = 11 and min_samples_split = 2\n",
      "Best performance on validation data for scotland is 0.4111449774066567 for max_depth = 18 and min_samples_split = 2\n",
      "Best performance on validation data for spain is 0.4301976644909747 for max_depth = 20 and min_samples_split = 15\n",
      "Best performance on validation data for turkey is 0.42858167683692866 for max_depth = 15 and min_samples_split = 20\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_best_params_rfm = {}\n",
    "max_depth_values = [i for i in range(10, 25)]\n",
    "min_samples_split_values = [2, 5, 15, 10, 20]\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    max_value = 0\n",
    "    result = [[0 for _ in range(len(min_samples_split_values))] for _ in range(len(max_depth_values))]\n",
    "    max_i = -1\n",
    "    max_j = -1\n",
    "\n",
    "    for i, max_depth in enumerate(max_depth_values):\n",
    "        for j, min_samples_split in enumerate(min_samples_split_values):\n",
    "            result[i][j] = random_forest({\"max_depth\": max_depth + 1, \"min_samples_split\": min_samples_split})\n",
    "\n",
    "    for i in range(len(max_depth_values)):\n",
    "        for j in range(len(min_samples_split_values)):\n",
    "            current_value = result[i][j]\n",
    "            if current_value > max_value:\n",
    "                max_value = current_value\n",
    "                max_i = i\n",
    "                max_j = j\n",
    "\n",
    "    best_max_depth = max_depth_values[max_i]\n",
    "    best_min_samples_split = min_samples_split_values[max_j]\n",
    "    test_results.loc[test_results[\"country\"] == country, \"rfm\"] = max_value\n",
    "    dfs_best_params_rfm[country] = {\"max_depth\": best_max_depth, \"min_samples_split\": best_min_samples_split}\n",
    "\n",
    "    print(f\"Best performance on validation data for {country} is {max_value} for max_depth = {best_max_depth} and min_samples_split = {best_min_samples_split}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:54.445916400Z",
     "start_time": "2024-01-07T22:03:18.834315Z"
    }
   },
   "id": "5eda447e36f2dcef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MultinomialNaive Bayes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab31cc39a53d29b"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:54.462424100Z",
     "start_time": "2024-01-07T22:07:54.446924500Z"
    }
   },
   "id": "561c2f796f6b828a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline Multinomial Naive Bayes model on train data for belgium: 0.42855553042622935\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for belgium: 0.4018406843007843\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for belgium: 0.45186126065854165\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for england: 0.46418180895356476\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for england: 0.37246179695679243\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for england: 0.36166073721735464\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for france: 0.4854222740765013\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for france: 0.41928853654021686\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for france: 0.4240027166856435\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for germany: 0.4373485317229672\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for germany: 0.3643708829774592\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for germany: 0.3890711388135904\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for greece: 0.5220799733666416\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for greece: 0.4224933458976012\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for greece: 0.4847767174460837\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for italy: 0.49242329542328384\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for italy: 0.4189222098523822\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for italy: 0.44459352926362666\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for netherlands: 0.46917565328102234\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for netherlands: 0.45062731766359204\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for netherlands: 0.48018192960578815\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for portugal: 0.5350162846238716\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for portugal: 0.5098417918022241\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for portugal: 0.5614049198253975\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for scotland: 0.486174319995577\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for scotland: 0.3897126008211405\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for scotland: 0.39698336111524907\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for spain: 0.49270701624264684\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for spain: 0.4013407383237712\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for spain: 0.39444361907591735\n",
      " --------\n",
      "F1-score for baseline Multinomial Naive Bayes model on train data for turkey: 0.45602357374613484\n",
      "F1-score for baseline Multinomial Naive Bayes model on validation data for turkey: 0.39242360151666333\n",
      "F1-score for baseline Multinomial Naive Bayes model on test data for turkey: 0.4069677790869961\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # X_train = scaler.fit_transform(dfs_train_clas_X[country])\n",
    "    # X_valid = scaler.fit_transform(dfs_valid_clas_X[country])\n",
    "    # X_test = scaler.fit_transform(dfs_test_clas_X[country])\n",
    "    \n",
    "    nb.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = nb.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = nb.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = nb.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    test_results.loc[test_results[\"country\"] == country, \"nb\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"nb\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline Multinomial Naive Bayes model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:54.650315900Z",
     "start_time": "2024-01-07T22:07:54.462424100Z"
    }
   },
   "id": "35ee17d02a2f0cc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3b120342bd53c8"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:54.693855100Z",
     "start_time": "2024-01-07T22:07:54.652317400Z"
    }
   },
   "id": "21b749850dc349dc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline KNeighbors model on train data for belgium: 0.5956657523796139\n",
      "F1-score for baseline KNeighbors model on validation data for belgium: 0.4063827335635992\n",
      "F1-score for baseline KNeighbors model on test data for belgium: 0.3828666746990084\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for england: 0.5894038189987336\n",
      "F1-score for baseline KNeighbors model on validation data for england: 0.3672349280260135\n",
      "F1-score for baseline KNeighbors model on test data for england: 0.3526896760514356\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for france: 0.5893777623544728\n",
      "F1-score for baseline KNeighbors model on validation data for france: 0.3873262007695735\n",
      "F1-score for baseline KNeighbors model on test data for france: 0.3935528295993412\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for germany: 0.6071573809090861\n",
      "F1-score for baseline KNeighbors model on validation data for germany: 0.3734543373915255\n",
      "F1-score for baseline KNeighbors model on test data for germany: 0.38647196197503747\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for greece: 0.6254500993998674\n",
      "F1-score for baseline KNeighbors model on validation data for greece: 0.37116236513278733\n",
      "F1-score for baseline KNeighbors model on test data for greece: 0.5050683508525132\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for italy: 0.6205218832130982\n",
      "F1-score for baseline KNeighbors model on validation data for italy: 0.3945067963586482\n",
      "F1-score for baseline KNeighbors model on test data for italy: 0.4108030216004572\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for netherlands: 0.6410906489925271\n",
      "F1-score for baseline KNeighbors model on validation data for netherlands: 0.43825560839023653\n",
      "F1-score for baseline KNeighbors model on test data for netherlands: 0.40813311057745644\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for portugal: 0.6572295207155533\n",
      "F1-score for baseline KNeighbors model on validation data for portugal: 0.4976469294628622\n",
      "F1-score for baseline KNeighbors model on test data for portugal: 0.4731018410349188\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for scotland: 0.6102427179431109\n",
      "F1-score for baseline KNeighbors model on validation data for scotland: 0.3916073663010979\n",
      "F1-score for baseline KNeighbors model on test data for scotland: 0.43605416696601873\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for spain: 0.5731117904565322\n",
      "F1-score for baseline KNeighbors model on validation data for spain: 0.4027106401260378\n",
      "F1-score for baseline KNeighbors model on test data for spain: 0.3696877284361899\n",
      " --------\n",
      "F1-score for baseline KNeighbors model on train data for turkey: 0.5720573710311552\n",
      "F1-score for baseline KNeighbors model on validation data for turkey: 0.34882032781798866\n",
      "F1-score for baseline KNeighbors model on test data for turkey: 0.3493139645147328\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    kn.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = kn.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = kn.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = kn.predict(dfs_test_clas_X[country])\n",
    "    test_results.loc[test_results[\"country\"] == country, \"kn\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"kn\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    print(f\"F1-score for baseline KNeighbors model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline KNeighbors model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:56.260801100Z",
     "start_time": "2024-01-07T22:07:54.666336300Z"
    }
   },
   "id": "cfd82a05eab38d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1155353c873345e8"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:07:56.281383600Z",
     "start_time": "2024-01-07T22:07:56.261960100Z"
    }
   },
   "id": "ca95c293c0f6ad91"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline GradientBoostingClassifier model on train data for belgium: 0.9732463877195846\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for belgium: 0.4180688162886305\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for belgium: 0.40327229419433985\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for england: 0.5974750127516913\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for england: 0.3831094568174671\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for england: 0.37912762263840727\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for france: 0.8224382023286632\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for france: 0.4069527603870234\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for france: 0.4078353502279672\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for germany: 0.8675345967053584\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for germany: 0.3893512822650736\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for germany: 0.393580028502629\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for greece: 0.9813143899288117\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for greece: 0.4035501978085711\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for greece: 0.49265725670291083\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for italy: 0.7782408667919322\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for italy: 0.45230949359025013\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for italy: 0.4217008026845443\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for netherlands: 0.9688863439671863\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for netherlands: 0.4043145537932185\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for netherlands: 0.45835765975347237\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for portugal: 0.9652965172604615\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for portugal: 0.5238069855408938\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for portugal: 0.4672195251453801\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for scotland: 0.8336812844019129\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for scotland: 0.39440930803765833\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for scotland: 0.3972757077827784\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for spain: 0.7774570326069772\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for spain: 0.3894806042337011\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for spain: 0.40775245711823177\n",
      " --------\n",
      "F1-score for baseline GradientBoostingClassifier model on train data for turkey: 0.9358555356448984\n",
      "F1-score for baseline GradientBoostingClassifier model on validation data for turkey: 0.40925960204035583\n",
      "F1-score for baseline GradientBoostingClassifier model on test data for turkey: 0.4178614698377452\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    gbc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "    dfs_train_predict[country] = gbc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = gbc.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = gbc.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    test_results.loc[test_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"gbc\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline GradientBoostingClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:08:35.541287900Z",
     "start_time": "2024-01-07T22:07:56.278381Z"
    }
   },
   "id": "4cc3cc37f905e8df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ada Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9dc950798a686f6"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for baseline AdaBoostClassifier model on train data for belgium: 0.6071820013242607\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for belgium: 0.41347361772033153\n",
      "F1-score for baseline AdaBoostClassifier model on test data for belgium: 0.402224017729969\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for england: 0.44678403450765036\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for england: 0.4015629213123116\n",
      "F1-score for baseline AdaBoostClassifier model on test data for england: 0.36640692210123965\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for france: 0.5385211687702087\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for france: 0.39494952744692063\n",
      "F1-score for baseline AdaBoostClassifier model on test data for france: 0.42741770309795557\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for germany: 0.5390574650849018\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for germany: 0.3907464071453362\n",
      "F1-score for baseline AdaBoostClassifier model on test data for germany: 0.41343476685814834\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for greece: 0.6465980636142613\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for greece: 0.3875281634103149\n",
      "F1-score for baseline AdaBoostClassifier model on test data for greece: 0.4908344403619879\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for italy: 0.5155910752351823\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for italy: 0.4368665753851659\n",
      "F1-score for baseline AdaBoostClassifier model on test data for italy: 0.3933948403589265\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for netherlands: 0.5853889297285524\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for netherlands: 0.44398968852610127\n",
      "F1-score for baseline AdaBoostClassifier model on test data for netherlands: 0.46887926737891256\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for portugal: 0.6625235404896422\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for portugal: 0.4662633847865387\n",
      "F1-score for baseline AdaBoostClassifier model on test data for portugal: 0.45111779018176607\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for scotland: 0.5573658625528904\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for scotland: 0.38586704724083726\n",
      "F1-score for baseline AdaBoostClassifier model on test data for scotland: 0.4406086016040754\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for spain: 0.49440203269997945\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for spain: 0.3971061560944646\n",
      "F1-score for baseline AdaBoostClassifier model on test data for spain: 0.3678031703622419\n",
      " --------\n",
      "F1-score for baseline AdaBoostClassifier model on train data for turkey: 0.5790352578278275\n",
      "F1-score for baseline AdaBoostClassifier model on validation data for turkey: 0.43361204959298166\n",
      "F1-score for baseline AdaBoostClassifier model on test data for turkey: 0.44499311174303324\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dfs_train_predict = {}\n",
    "dfs_valid_predict = {}\n",
    "dfs_test_predict = {}\n",
    "\n",
    "for country in dfs_train_clas_X.keys():\n",
    "    # Create an AdaBoostClassifier\n",
    "    abc = AdaBoostClassifier(n_estimators=50, random_state=42)  # You can adjust the hyperparameters as needed\n",
    "\n",
    "    # Train the AdaBoostClassifier\n",
    "    abc.fit(dfs_train_clas_X[country], dfs_train_clas_y[country])\n",
    "\n",
    "    # Make predictions on train, validation, and test sets\n",
    "    dfs_train_predict[country] = abc.predict(dfs_train_clas_X[country])\n",
    "    dfs_valid_predict[country] = abc.predict(dfs_valid_clas_X[country])\n",
    "    dfs_test_predict[country] = abc.predict(dfs_test_clas_X[country])\n",
    "\n",
    "    # Calculate and store F1-score on validation set\n",
    "    test_results.loc[test_results[\"country\"] == country, \"abc\"] = f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')\n",
    "    # test_results.loc[test_results[\"country\"] == country, \"abc\"] = f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')\n",
    "\n",
    "    # Print F1-scores\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on train data for {country}: {f1_score(dfs_train_clas_y[country], dfs_train_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on validation data for {country}: {f1_score(dfs_valid_clas_y[country], dfs_valid_predict[country], average='macro')}\")\n",
    "    print(f\"F1-score for baseline AdaBoostClassifier model on test data for {country}: {f1_score(dfs_test_clas_y[country], dfs_test_predict[country], average='macro')}\\n --------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:08:40.873496200Z",
     "start_time": "2024-01-07T22:08:35.543930700Z"
    }
   },
   "id": "8aa6d89b47e54141"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing Voting Classifier\n",
    "Our voting classifier is designed to use the 3 best performing classifiers and use them for the final prediction "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed85c4ceff50c438"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for i, row in test_results.iterrows():\n",
    "    best_models.append(pd.to_numeric(row[[\"lr\", \"rfm\", \"nb\", \"kn\", \"gbc\", \"abc\"]]).nlargest(4).index.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:08:40.893194900Z",
     "start_time": "2024-01-07T22:08:40.874497600Z"
    }
   },
   "id": "1143fe15b8757fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def voting_classifier(best_models_country, X_train, y_train, X_val, y_val, country: str, X_test, y_test):\n",
    "    \"\"\"\"\"\"\n",
    "    models = {\n",
    "        \"nb\": nb,\n",
    "        \"kn\": kn,\n",
    "        \"gbc\": GradientBoostingClassifier(random_state=42),\n",
    "        \"rfm\": RandomForestClassifier(random_state=42),\n",
    "        \"lr\": LogisticRegression(random_state=42, solver='liblinear', max_iter=10000),\n",
    "        \"abc\": AdaBoostClassifier()\n",
    "        \n",
    "    }\n",
    "    print(best_models_country)\n",
    "    clf1 = models[best_models_country[0]] if best_models_country[0] != \"rfm\" else models[best_models_country[0]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf2 = models[best_models_country[1]] if best_models_country[1] != \"rfm\" else models[best_models_country[1]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    clf3 = models[best_models_country[2]] if best_models_country[2] != \"rfm\" else models[best_models_country[2]].set_params(**dfs_best_params_rfm[country]) if best_models_country[0] != \"lr\" else models[best_models_country[0]].set_params(**dfs_best_params_lr[country])\n",
    "    \n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[(best_models_country[0], clf1 ), (best_models_country[1], clf2 ),(best_models_country[2], clf3 )],\n",
    "        voting='soft', weights=[1.6,1,1]\n",
    "    ) \n",
    "    eclf.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_predict = eclf.predict(X_train)\n",
    "    y_val_predict = eclf.predict(X_val)\n",
    "    \n",
    "    y_test_predict = eclf.predict(X_test)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    y_valid_best_model = clf1.predict(X_val)\n",
    "    y_test_best_model = clf1.predict(X_test)\n",
    "    \n",
    "    print(f\"F1-score for voting classifier model on train data for {country}: {f1_score(y_train, y_train_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on validation data for {country}: {f1_score(y_val, y_val_predict, average='macro')}\")\n",
    "    print(f\"F1-score for voting classifier model on test data for {country}: {f1_score(y_test, y_test_predict, average='macro')}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"F1-score for best model ({best_models_country[0]}) on valid data for {country}: {f1_score(y_val, y_valid_best_model, average='macro')}\")\n",
    "    print(f\"F1-score for best model ({best_models_country[0]}) on test data for {country}: {f1_score(y_test, y_test_best_model, average='macro')}\\n --------\")\n",
    "    final_prediction = y_test_predict if f1_score(y_val, y_val_predict, average='macro') > f1_score(y_val, y_valid_best_model, average='macro') else y_test_best_model\n",
    "\n",
    "    return final_prediction, max(f1_score(y_test, y_test_best_model, average='macro'), f1_score(y_val, y_val_predict, average='macro'))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:08:40.903392500Z",
     "start_time": "2024-01-07T22:08:40.895196600Z"
    }
   },
   "id": "fdb58c1352b112f8"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rfm', 'gbc', 'abc', 'lr']\n",
      "F1-score for voting classifier model on train data for belgium: 0.9978463190364916\n",
      "F1-score for voting classifier model on validation data for belgium: 0.4338941580062557\n",
      "F1-score for voting classifier model on test data for belgium: 0.4215135106439454\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for belgium: 0.42281606967515284\n",
      "F1-score for best model (rfm) on test data for belgium: 0.4370509795070321\n",
      " --------\n",
      "['rfm', 'abc', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for england: 0.9078504752768765\n",
      "F1-score for voting classifier model on validation data for england: 0.3892855945580786\n",
      "F1-score for voting classifier model on test data for england: 0.36515996995259137\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for england: 0.3920182822725506\n",
      "F1-score for best model (rfm) on test data for england: 0.37781303618620377\n",
      " --------\n",
      "['rfm', 'nb', 'gbc', 'lr']\n",
      "F1-score for voting classifier model on train data for france: 0.9712747716131406\n",
      "F1-score for voting classifier model on validation data for france: 0.42720436753807217\n",
      "F1-score for voting classifier model on test data for france: 0.4248307572398022\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for france: 0.42709243998761764\n",
      "F1-score for best model (rfm) on test data for france: 0.4123008778035879\n",
      " --------\n",
      "['rfm', 'abc', 'gbc', 'kn']\n",
      "F1-score for voting classifier model on train data for germany: 0.9975730477771481\n",
      "F1-score for voting classifier model on validation data for germany: 0.3982076784566139\n",
      "F1-score for voting classifier model on test data for germany: 0.39602334919272214\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for germany: 0.41245791245791247\n",
      "F1-score for best model (rfm) on test data for germany: 0.4106279101142915\n",
      " --------\n",
      "['rfm', 'lr', 'nb', 'gbc']\n",
      "F1-score for voting classifier model on train data for greece: 0.8297998967779989\n",
      "F1-score for voting classifier model on validation data for greece: 0.42845037494923083\n",
      "F1-score for voting classifier model on test data for greece: 0.5160969298900333\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for greece: 0.4402492548834012\n",
      "F1-score for best model (rfm) on test data for greece: 0.49360018403496664\n",
      " --------\n",
      "['rfm', 'gbc', 'lr', 'abc']\n",
      "F1-score for voting classifier model on train data for italy: 0.8696891904200847\n",
      "F1-score for voting classifier model on validation data for italy: 0.44874209063570475\n",
      "F1-score for voting classifier model on test data for italy: 0.43902600417217047\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for italy: 0.4463380802563246\n",
      "F1-score for best model (rfm) on test data for italy: 0.39131793061694425\n",
      " --------\n",
      "['rfm', 'nb', 'lr', 'abc']\n",
      "F1-score for voting classifier model on train data for netherlands: 0.8194538713974918\n",
      "F1-score for voting classifier model on validation data for netherlands: 0.46408987084529985\n",
      "F1-score for voting classifier model on test data for netherlands: 0.43313546423135457\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for netherlands: 0.4498055677165151\n",
      "F1-score for best model (rfm) on test data for netherlands: 0.4551914904106737\n",
      " --------\n",
      "['gbc', 'rfm', 'nb', 'kn']\n",
      "F1-score for voting classifier model on train data for portugal: 0.9118586707915313\n",
      "F1-score for voting classifier model on validation data for portugal: 0.48973871080773\n",
      "F1-score for voting classifier model on test data for portugal: 0.5256582633053221\n",
      "\n",
      "\n",
      "F1-score for best model (gbc) on valid data for portugal: 0.5238069855408938\n",
      "F1-score for best model (gbc) on test data for portugal: 0.4672195251453801\n",
      " --------\n",
      "['rfm', 'lr', 'gbc', 'kn']\n",
      "F1-score for voting classifier model on train data for scotland: 0.9313361248713594\n",
      "F1-score for voting classifier model on validation data for scotland: 0.3746690608533834\n",
      "F1-score for voting classifier model on test data for scotland: 0.4169736856086028\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for scotland: 0.3903458297532692\n",
      "F1-score for best model (rfm) on test data for scotland: 0.405895631925397\n",
      " --------\n",
      "['rfm', 'lr', 'kn', 'nb']\n",
      "F1-score for voting classifier model on train data for spain: 0.7304609556980529\n",
      "F1-score for voting classifier model on validation data for spain: 0.4378340396416451\n",
      "F1-score for voting classifier model on test data for spain: 0.4018518972801684\n",
      "\n",
      "\n",
      "F1-score for best model (rfm) on valid data for spain: 0.41347668857230574\n",
      "F1-score for best model (rfm) on test data for spain: 0.42559475511784983\n",
      " --------\n",
      "['abc', 'rfm', 'lr', 'gbc']\n",
      "F1-score for voting classifier model on train data for turkey: 0.6829426169636351\n",
      "F1-score for voting classifier model on validation data for turkey: 0.4026875471139489\n",
      "F1-score for voting classifier model on test data for turkey: 0.41147235055097414\n",
      "\n",
      "\n",
      "F1-score for best model (abc) on valid data for turkey: 0.43361204959298166\n",
      "F1-score for best model (abc) on test data for turkey: 0.44499311174303324\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "final_predict = {}\n",
    "final_f1_score = [0 for _ in range(len(dfs_train_clas_X.keys()))]\n",
    "for i, country in enumerate(dfs_train_clas_X.keys()):\n",
    "    final_predict[country], final_f1_score[i] = voting_classifier(best_models[i], dfs_train_clas_X[country], dfs_train_clas_y[country], dfs_valid_clas_X[country], dfs_valid_clas_y[country],country, dfs_test_clas_X[country], dfs_test_clas_y[country])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:09:12.901514600Z",
     "start_time": "2024-01-07T22:08:40.908358400Z"
    }
   },
   "id": "876472e32da6e2"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4408238628501137"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we used test data only for our curiosity, we made no choices about the models used as that would defeat the purpose of the assignment\n",
    "mean(final_f1_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:09:12.946062700Z",
     "start_time": "2024-01-07T22:09:12.901514600Z"
    }
   },
   "id": "56ea743663853947"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.4370509795070321,\n 0.3892855945580786,\n 0.42720436753807217,\n 0.4106279101142915,\n 0.49360018403496664,\n 0.44874209063570475,\n 0.46408987084529985,\n 0.48973871080773,\n 0.405895631925397,\n 0.4378340396416451,\n 0.44499311174303324]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_f1_score "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:09:12.950569800Z",
     "start_time": "2024-01-07T22:09:12.917803200Z"
    }
   },
   "id": "5351c0d3542d4bff"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "for country in final_predict:\n",
    "    dfs_test_clas_X[country][\"season\"] = leagues[country]\n",
    "    dfs_test_clas_X[country][\"final_predict\"] = np.where(final_predict[country] == 0, 'A', np.where(final_predict[country] == 1, 'H', 'D'))\n",
    "    df = dfs_test_clas_X[country]\n",
    "    for league in list(df[\"league\"].unique()):\n",
    "        df[df[\"league\"] == league][\"final_predict\"].to_csv(f\"final_results/{country}_{int(league)}.csv\", index= False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T22:09:13.008024600Z",
     "start_time": "2024-01-07T22:09:12.933436600Z"
    }
   },
   "id": "f65ead21d81d9a6a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5714e184674fcc0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
