{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2714e0ed",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:22.900621700Z",
     "start_time": "2023-11-12T18:36:22.627556700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaf693b8e5b699",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load train data\n",
    "\n",
    "- iterate through train data folder \n",
    "- feature engineer the **country** and **league** from parent folder name\n",
    "- join the loaded csv files by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64ab231c00a3a93c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:44.627753700Z",
     "start_time": "2023-11-12T18:36:22.642690100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Div      Date   HomeTeam     AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  ...  \\\n0  B1  20/05/01   Mechelen       Lierse   1.0   1.0   D   1.0   1.0   D  ...   \n1  B1  17/09/00   Germinal  Club Brugge   2.0   3.0   A   0.0   1.0   A  ...   \n2  B1  14/10/00    Beveren     Standard   0.0   3.0   A   0.0   2.0   A  ...   \n3  B1  06/09/00    Lokeren     Mechelen   3.0   2.0   H   0.0   2.0   A  ...   \n4  B1  27/08/00  Charleroi      Antwerp   1.0   0.0   H   1.0   0.0   H  ...   \n\n   LBAHA  LBAH  LB  LB.1  LB.2   HT   AT  Unnamed: 32  Unnamed: 33  \\\n0    NaN   NaN NaN   NaN   NaN  NaN  NaN          NaN          NaN   \n1    NaN   NaN NaN   NaN   NaN  NaN  NaN          NaN          NaN   \n2    NaN   NaN NaN   NaN   NaN  NaN  NaN          NaN          NaN   \n3    NaN   NaN NaN   NaN   NaN  NaN  NaN          NaN          NaN   \n4    NaN   NaN NaN   NaN   NaN  NaN  NaN          NaN          NaN   \n\n   Unnamed: 34  \n0          NaN  \n1          NaN  \n2          NaN  \n3          NaN  \n4          NaN  \n\n[5 rows x 174 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>...</th>\n      <th>LBAHA</th>\n      <th>LBAH</th>\n      <th>LB</th>\n      <th>LB.1</th>\n      <th>LB.2</th>\n      <th>HT</th>\n      <th>AT</th>\n      <th>Unnamed: 32</th>\n      <th>Unnamed: 33</th>\n      <th>Unnamed: 34</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B1</td>\n      <td>20/05/01</td>\n      <td>Mechelen</td>\n      <td>Lierse</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>D</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>D</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B1</td>\n      <td>17/09/00</td>\n      <td>Germinal</td>\n      <td>Club Brugge</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>A</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B1</td>\n      <td>14/10/00</td>\n      <td>Beveren</td>\n      <td>Standard</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>A</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B1</td>\n      <td>06/09/00</td>\n      <td>Lokeren</td>\n      <td>Mechelen</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>A</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B1</td>\n      <td>27/08/00</td>\n      <td>Charleroi</td>\n      <td>Antwerp</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>H</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>H</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 174 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for root, directory, files in os.walk(\"data/train\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            # Remove empty rows and columns\n",
    "            tmp = tmp.dropna(how='all', axis=0)\n",
    "            tmp = tmp.dropna(how='all', axis=1)\n",
    "            # Derive additional columns\n",
    "            tmp[\"league\"] = int(root.split(\"\\\\\")[2])\n",
    "            tmp[\"country\"] = root.split(\"\\\\\")[1]\n",
    "            tmp[\"season\"] = int(file[:2]) # no. of season - 00/01 - 0th season, 21/22 - 21st season\n",
    "            df = pd.concat([df, tmp], axis = 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bc86b",
   "metadata": {},
   "source": [
    "# Data validation\n",
    "\n",
    "In some cases, the data is wrong. This section correct the loaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not imputable data\n",
    "\n",
    "In some cases, missing data cause the data to be unusable and can't be computed. This applies to variables\n",
    "\n",
    "- HomeTeam\n",
    "- AwayTeam"
   ],
   "id": "226a8a0d7973afc3"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:44.783870800Z",
     "start_time": "2023-11-12T18:36:44.629288900Z"
    }
   },
   "outputs": [],
   "source": [
    "crucial_cols = ['Date', 'HomeTeam', 'AwayTeam']\n",
    "df = df.dropna(subset = crucial_cols)"
   ],
   "id": "f77b42e283336b88"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:44.830273400Z",
     "start_time": "2023-11-12T18:36:44.784872200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              HFKC         AFKC\ncount  1306.000000  1306.000000\nmean     16.622511    17.283308\nstd       4.389023     4.734092\nmin       2.000000     2.000000\n25%      14.000000    14.000000\n50%      16.000000    17.000000\n75%      19.750000    20.000000\nmax      32.000000    34.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HFKC</th>\n      <th>AFKC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1306.000000</td>\n      <td>1306.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16.622511</td>\n      <td>17.283308</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.389023</td>\n      <td>4.734092</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>14.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>16.000000</td>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19.750000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>32.000000</td>\n      <td>34.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"HFKC\", \"AFKC\"]].describe()"
   ],
   "id": "732f40399344462b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal validation\n",
    "\n",
    "Some goals are incorrect and they need to be fixed.\n",
    "\n"
   ],
   "id": "6d25790611d96fb9"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:44.922664100Z",
     "start_time": "2023-11-12T18:36:44.816935300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                FTHG           FTAG           HTHG           HTAG\ncount  153476.000000  153458.000000  153426.000000  153433.000000\nmean        2.221813       1.131671       0.655032       0.494333\nstd        21.960074       1.109022       0.808892       0.708273\nmin         0.000000      -1.000000       0.000000       0.000000\n25%         1.000000       0.000000       0.000000       0.000000\n50%         1.000000       1.000000       0.000000       0.000000\n75%         2.000000       2.000000       1.000000       1.000000\nmax       998.000000      13.000000       7.000000       6.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>153476.000000</td>\n      <td>153458.000000</td>\n      <td>153426.000000</td>\n      <td>153433.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.221813</td>\n      <td>1.131671</td>\n      <td>0.655032</td>\n      <td>0.494333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>21.960074</td>\n      <td>1.109022</td>\n      <td>0.808892</td>\n      <td>0.708273</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>998.000000</td>\n      <td>13.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_cols = [\"FTHG\", \"FTAG\", \"HTHG\", \"HTAG\"]\n",
    "df[goal_cols].describe()"
   ],
   "id": "775e811c8d7784b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be several issues:\n",
    "\n",
    "- the max value for **FTHG** is absurd\n",
    "- the min value for **FTAG** does not make sense\n",
    "- some values are missing"
   ],
   "id": "49e386d46f65c71b"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:44.922664100Z",
     "start_time": "2023-11-12T18:36:44.863602700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FTHG\n1.0      51309\n2.0      37397\n0.0      35796\n3.0      18313\n4.0       7154\n5.0       2325\n6.0        741\n7.0        182\n8.0         41\n9.0         14\n10.0         5\n339.0        5\nName: count, dtype: int64"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"FTHG\"].value_counts().head(12)"
   ],
   "id": "a8aa0767674c3394"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove all rows where the Full Time Home Goals are greater than 10."
   ],
   "id": "2e92b30b460e06bb"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.061882100Z",
     "start_time": "2023-11-12T18:36:44.879122700Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df[\"FTHG\"] <= 10]"
   ],
   "id": "da3ad2beef1659cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, all Full Time Away goals that are less than zero are inspected. Since we are not sure which values are good and bad, all of them are removed."
   ],
   "id": "97b0ffe740656dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.189341700Z",
     "start_time": "2023-11-12T18:36:45.034027700Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df[\"FTAG\"] >= 0]"
   ],
   "id": "c34743041a81b73b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's left are the missing values. We have no way of recomputing these as well and these rows are again excluded."
   ],
   "id": "cd01849fd00b63f9"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.335755300Z",
     "start_time": "2023-11-12T18:36:45.190341900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df[goal_cols].isna().sum(axis=1) == 0]"
   ],
   "id": "cdf84d39956eadc6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the describe() function again, we can see that the counts are the same and min/max statistics make sense."
   ],
   "id": "3bfc7f7e2d7f23d5"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.372976700Z",
     "start_time": "2023-11-12T18:36:45.329998900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                FTHG           FTAG           HTHG           HTAG\ncount  152796.000000  152796.000000  152796.000000  152796.000000\nmean        1.484699       1.134284       0.655096       0.494496\nstd         1.252576       1.107143       0.808871       0.708516\nmin         0.000000       0.000000       0.000000       0.000000\n25%         1.000000       0.000000       0.000000       0.000000\n50%         1.000000       1.000000       0.000000       0.000000\n75%         2.000000       2.000000       1.000000       1.000000\nmax        10.000000      13.000000       7.000000       6.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>152796.000000</td>\n      <td>152796.000000</td>\n      <td>152796.000000</td>\n      <td>152796.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.484699</td>\n      <td>1.134284</td>\n      <td>0.655096</td>\n      <td>0.494496</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.252576</td>\n      <td>1.107143</td>\n      <td>0.808871</td>\n      <td>0.708516</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10.000000</td>\n      <td>13.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[goal_cols].describe()"
   ],
   "id": "d766cee93635a417"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result validation\n",
    "\n",
    "Another thing that needs to be validated is the result classification, which are re-classified - this is the easiest data validation process."
   ],
   "id": "8483080ed972a444"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.436619300Z",
     "start_time": "2023-11-12T18:36:45.363449500Z"
    }
   },
   "outputs": [],
   "source": [
    "half_conds = [df[\"HTHG\"] > df[\"HTAG\"], df[\"HTHG\"] < df[\"HTAG\"], df[\"HTHG\"] == df[\"HTAG\"]]\n",
    "half_choic = [\"H\"                    , \"A\"                    , \"D\"]\n",
    "df.loc[:, \"HTR\"] = np.select(half_conds, half_choic)\n",
    "full_conds = [df[\"FTHG\"] > df[\"FTAG\"], df[\"FTHG\"] < df[\"FTAG\"], df[\"FTHG\"] == df[\"FTAG\"]]\n",
    "full_choic = [\"H\"                    , \"A\"                    , \"D\"]\n",
    "df.loc[:, \"FTR\"] = np.select(full_conds, full_choic)"
   ],
   "id": "f29087ba4af3f001"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of other statistics\n",
    "\n",
    "First step is to look at simple descriptive statistics."
   ],
   "id": "664924458ef4583"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.561951900Z",
     "start_time": "2023-11-12T18:36:45.394518800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Attendance            HS            AS           HST           AST  \\\ncount   6641.000000  91684.000000  91726.000000  90775.000000  90804.000000   \nmean   12853.621894     12.675352     10.296895      5.231551      4.209748   \nstd    13873.200798      4.925163      4.384494      2.808289      2.456644   \nmin      123.000000      0.000000      0.000000      0.000000      0.000000   \n25%     3530.000000      9.000000      7.000000      3.000000      2.000000   \n50%     7014.000000     12.000000     10.000000      5.000000      4.000000   \n75%    17608.000000     16.000000     13.000000      7.000000      6.000000   \nmax    69000.000000     46.000000     45.000000     27.000000     23.000000   \n\n               HHW          AHW            HC            AC            HF  \\\ncount  6472.000000  6484.000000  91276.000000  91327.000000  89647.000000   \nmean      0.351823     0.260950      5.722841      4.647300     12.849644   \nstd       0.610765     0.543137      2.937912      2.624468      4.556054   \nmin       0.000000     0.000000      0.000000      0.000000      0.000000   \n25%       0.000000     0.000000      4.000000      3.000000     10.000000   \n50%       0.000000     0.000000      5.000000      4.000000     12.000000   \n75%       1.000000     0.000000      7.000000      6.000000     16.000000   \nmax       4.000000    10.000000     26.000000     21.000000    145.000000   \n\n       ...         HFKC         AFKC           HO           AO            HY  \\\ncount  ...  1298.000000  1298.000000  6485.000000  6466.000000  91875.000000   \nmean   ...    16.620955    17.298921     3.258288     3.250541      1.642580   \nstd    ...     4.394704     4.740125     2.368060     2.519042      1.293023   \nmin    ...     2.000000     2.000000     0.000000     0.000000      0.000000   \n25%    ...    14.000000    14.000000     2.000000     1.000000      1.000000   \n50%    ...    16.000000    17.000000     3.000000     3.000000      1.000000   \n75%    ...    20.000000    20.000000     5.000000     5.000000      2.000000   \nmax    ...    32.000000    34.000000    16.000000    18.000000     11.000000   \n\n                 AY            HR           AR          HBP          ABP  \ncount  91874.000000  91897.000000  91839.00000  6652.000000  6639.000000  \nmean       1.960413      0.087000      0.11996    15.496843    20.928604  \nstd        1.365235      0.299434      0.35185    14.991016    17.225443  \nmin        0.000000      0.000000      0.00000     0.000000     0.000000  \n25%        1.000000      0.000000      0.00000     0.000000    10.000000  \n50%        2.000000      0.000000      0.00000    10.000000    20.000000  \n75%        3.000000      0.000000      0.00000    20.000000    30.000000  \nmax       10.000000      3.000000      9.00000   115.000000   150.000000  \n\n[8 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attendance</th>\n      <th>HS</th>\n      <th>AS</th>\n      <th>HST</th>\n      <th>AST</th>\n      <th>HHW</th>\n      <th>AHW</th>\n      <th>HC</th>\n      <th>AC</th>\n      <th>HF</th>\n      <th>...</th>\n      <th>HFKC</th>\n      <th>AFKC</th>\n      <th>HO</th>\n      <th>AO</th>\n      <th>HY</th>\n      <th>AY</th>\n      <th>HR</th>\n      <th>AR</th>\n      <th>HBP</th>\n      <th>ABP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6641.000000</td>\n      <td>91684.000000</td>\n      <td>91726.000000</td>\n      <td>90775.000000</td>\n      <td>90804.000000</td>\n      <td>6472.000000</td>\n      <td>6484.000000</td>\n      <td>91276.000000</td>\n      <td>91327.000000</td>\n      <td>89647.000000</td>\n      <td>...</td>\n      <td>1298.000000</td>\n      <td>1298.000000</td>\n      <td>6485.000000</td>\n      <td>6466.000000</td>\n      <td>91875.000000</td>\n      <td>91874.000000</td>\n      <td>91897.000000</td>\n      <td>91839.00000</td>\n      <td>6652.000000</td>\n      <td>6639.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>12853.621894</td>\n      <td>12.675352</td>\n      <td>10.296895</td>\n      <td>5.231551</td>\n      <td>4.209748</td>\n      <td>0.351823</td>\n      <td>0.260950</td>\n      <td>5.722841</td>\n      <td>4.647300</td>\n      <td>12.849644</td>\n      <td>...</td>\n      <td>16.620955</td>\n      <td>17.298921</td>\n      <td>3.258288</td>\n      <td>3.250541</td>\n      <td>1.642580</td>\n      <td>1.960413</td>\n      <td>0.087000</td>\n      <td>0.11996</td>\n      <td>15.496843</td>\n      <td>20.928604</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13873.200798</td>\n      <td>4.925163</td>\n      <td>4.384494</td>\n      <td>2.808289</td>\n      <td>2.456644</td>\n      <td>0.610765</td>\n      <td>0.543137</td>\n      <td>2.937912</td>\n      <td>2.624468</td>\n      <td>4.556054</td>\n      <td>...</td>\n      <td>4.394704</td>\n      <td>4.740125</td>\n      <td>2.368060</td>\n      <td>2.519042</td>\n      <td>1.293023</td>\n      <td>1.365235</td>\n      <td>0.299434</td>\n      <td>0.35185</td>\n      <td>14.991016</td>\n      <td>17.225443</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>123.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3530.000000</td>\n      <td>9.000000</td>\n      <td>7.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>14.000000</td>\n      <td>14.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7014.000000</td>\n      <td>12.000000</td>\n      <td>10.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>12.000000</td>\n      <td>...</td>\n      <td>16.000000</td>\n      <td>17.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>10.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>17608.000000</td>\n      <td>16.000000</td>\n      <td>13.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>16.000000</td>\n      <td>...</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>20.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>69000.000000</td>\n      <td>46.000000</td>\n      <td>45.000000</td>\n      <td>27.000000</td>\n      <td>23.000000</td>\n      <td>4.000000</td>\n      <td>10.000000</td>\n      <td>26.000000</td>\n      <td>21.000000</td>\n      <td>145.000000</td>\n      <td>...</td>\n      <td>32.000000</td>\n      <td>34.000000</td>\n      <td>16.000000</td>\n      <td>18.000000</td>\n      <td>11.000000</td>\n      <td>10.000000</td>\n      <td>3.000000</td>\n      <td>9.00000</td>\n      <td>115.000000</td>\n      <td>150.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_cols = [\n",
    "    'Attendance', 'HS', 'AS', 'HST', 'AST', 'HHW', 'AHW',\n",
    "    'HC', 'AC', 'HF', 'AF', 'HFKC', 'AFKC', 'HO', 'AO', 'HY', 'AY', 'HR', 'AR', \"HBP\", \"ABP\"\n",
    "]\n",
    "\n",
    "df[stat_cols].describe()"
   ],
   "id": "b73f2517a510058b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take a look at boxplots for variables where at least one variable falls out of the interval\n",
    "\n",
    "$$\n",
    "(\\text{q}_{0.25} - 3 * \\text{IQR},\\space \\text{q}_{0.75} + 3 * \\text{IQR})\n",
    "$$"
   ],
   "id": "75779084c512fc8f"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T18:36:45.661706600Z",
     "start_time": "2023-11-12T18:36:45.563967700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Attendance      109\nHS               14\nAS               23\nHST              18\nAST               8\nAHW            1435\nHC              174\nAC               73\nHF               21\nAF               25\nHO                4\nAO                2\nHY              633\nAY                2\nHR             7548\nAR            10254\nHBP              13\nABP              24\ndtype: int64"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outliers(x, multi = 3):\n",
    "    q25 = x.quantile(0.25)\n",
    "    q75 = x.quantile(0.75)\n",
    "    iqr = q75 - q25\n",
    "    outliers = x[(x < q25 - multi * iqr) | (x > q75 + multi * iqr)]\n",
    "    return len(outliers)\n",
    "\n",
    "stat_outliers = df[stat_cols].apply(lambda x: outliers(x))\n",
    "stat_outliers = stat_outliers[stat_outliers != 0]\n",
    "stat_outliers"
   ],
   "id": "5c42b907e5bb93c1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!\n",
    "Bylo by cool se pÅ™idat nÄ›jak jitter tÄ›ch bodÅ¯, aby bylo vidÄ›t, jestli je jeden nebo je jich vÃ­c, ale nepodaÅ™ilo se mi to dÃ¡t dohromady."
   ],
   "id": "2b4db496d47e316"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols = 6, figsize = (12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(stat_outliers.index):\n",
    "    # Data\n",
    "    df[col].plot(kind='box', ax = axes[i])\n",
    "    # Styling\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a5cb814aa8ad868"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can se that some outliers are not that extreme. For example variables *HO*, *AO* or *HY* have extreme values, but won't remove them. This is because even tho they can be considered as extreme, there seems to be a natural way how they occured and tehre are no huge jumps between them.\n",
    "\n",
    "On the other hand, variables *AHW*, *HF*, *AF* and *AR* seem to have some variables that are far away from the other data. Note that we do not consider variables in *HR* as outliers because it looks like it's a discrete variable with mostly zeros."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67ada88180c3393"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stat_jump = [\n",
    "    \"AS\", \"AHW\", \"HF\", \"AF\", \"AR\", \"ABP\"\n",
    "]\n",
    "stats_cut = [\n",
    "    38, 6, 100, 60, 6, 130\n",
    "]\n",
    "\n",
    "print(\"Number of extreme values:\")\n",
    "for i, col in enumerate(stat_jump):\n",
    "    cutoff = stats_cut[i]\n",
    "    x = df[col].to_numpy()\n",
    "    extreme = x[x > cutoff]\n",
    "    print(f\"{col}: {extreme}, (count: {len(extreme)})\")\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c722b689d769f74a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the analysis, we see that these extreme values occur at most twice. This is why we chose to remove them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35230d5924ce9225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criteria = dict(zip(stat_jump, stats_cut))\n",
    "for column, value in criteria.items():\n",
    "    # .isna() is important because otherwise all na rows are dropped\n",
    "    df = df[df[column].lt(value) | df[column].isna()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b659ccb24eb5be1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we will double-check with boxplots."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa102cb69a666ee2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols = 3, figsize = (8, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(stat_jump):\n",
    "    # Data\n",
    "    df[col].plot(kind='box', ax = axes[i])\n",
    "    # Styling\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47981d097e27552"
  },
  {
   "cell_type": "markdown",
   "source": [
    "IT looks like variable *HF* contains another outlier, but this process should be done only once. Hence, no outliers are removed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8733da0a1b0a17b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random unnamed data\n",
    "\n",
    "File *'data/train/portugal/1/0304.csv'* contains random data in columns *'Unnamed: 33'* and *'Unnamed: 34'*."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d39e5dcedb04e7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unnamed_cols_df = df[['Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34']]\n",
    "unnamed_cols_df[unnamed_cols_df.notnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d70af7e34f1d55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we do not know what these columns represent, and it is only one non-NA row from the whole dataset, this column is removed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfe5dd77dceb6f76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns = unnamed_cols_df.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52b2df9d6e32886c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrong betting odds names\n",
    "\n",
    "File *'data/train/germany/2/0405.csv'* contains columns **LB**, **LB.1** and **LB.2**, which are unique only to this file. After further investigation, they represent the betting odds data for Ladbrokers. After looking at the data more thoroughly, it can be guessed that all three columns represent odds for home win, away win, and draw."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f9ce1affaaab46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(\"data/train/germany/2/0405.csv\")\n",
    "# Remove empty rows and columns\n",
    "tmp = tmp.dropna(how='all', axis=0)\n",
    "tmp = tmp.dropna(how='all', axis=1)\n",
    "tmp = tmp.loc[:, ~tmp.columns.str.startswith('Unnamed:')]\n",
    "tmp = tmp[tmp[['LB', 'LB.1', 'LB.2']].notnull().any(axis=1)]\n",
    "tmp.filter(regex='[HDAB12]$').iloc[:, -12:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a30d4c64f092de02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on column similarity, we can make an edjucated guess that\n",
    "\n",
    "- **LB** should be **LBH**,\n",
    "- **LB.1** should be **LBD**, and\n",
    "- **LB.2** should be **LBA**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0581b5e986eb6de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If LB is not null, use that value and replace it in LBH\n",
    "df[\"LBH\"] = df[\"LBH\"].mask(df[\"LB\"  ].notnull(), df[\"LB\"])\n",
    "df[\"LBD\"] = df[\"LBD\"].mask(df[\"LB.1\"].notnull(), df[\"LB.1\"])\n",
    "df[\"LBA\"] = df[\"LBA\"].mask(df[\"LB.2\"].notnull(), df[\"LB.2\"])\n",
    "df = df.drop(columns = [\"LB\", \"LB.1\", \"LB.2\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da1d5fec8a4711d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Same name for different things\n",
    "\n",
    "In some cases, columns are named differently. We will standardize to use column names that are in *'notes.txt'*\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75cf1f7e93b33aa0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for root, directory, files in os.walk(\"data/train\", topdown=False):\n",
    "    if files:\n",
    "        for file in files:\n",
    "            tmp = pd.read_csv(f\"{root}/{file}\")\n",
    "            if \"HT\" in tmp.columns:\n",
    "                print(f\"Cases for HT: {root}, {file}\")\n",
    "            if \"AT\" in tmp.columns:\n",
    "                print(f\"Cases for AT: {root}, {file}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a517547d6425c03f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only affected data are in Greece."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32dfc2746b0096cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"HomeTeam\"] = df[\"HomeTeam\"].mask(df[\"HT\"].notnull(), df[\"HT\"])\n",
    "df[\"AwayTeam\"] = df[\"AwayTeam\"].mask(df[\"AT\"].notnull(), df[\"AT\"])\n",
    "df = df.drop(columns = [\"HT\", \"AT\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71bd3d01e49260f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Date normalization\n",
    "\n",
    "Date is not consistent and it needs to be unified in order to format it as date."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "661038dd7b393843"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "potential_fixes = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "equal = potential_fixes[potential_fixes.isnull()].index.equals(df[df[\"Date\"].isnull()].index)\n",
    "# if True, all non-na dates have been converted\n",
    "if equal:\n",
    "    df[\"Date\"] = potential_fixes\n",
    "else:\n",
    "    sys.exit(\"Date indexes are not equal. Something wrong with the conversion??\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46cea86f2154d60a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bookies analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e12538d24ac865"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#minor warning suppression\n",
    "import shutup\n",
    "shutup.please()\n",
    "\n",
    "away_odds = df[[\"B365A\", \"BSA\", \"BWA\", \"GBA\", \"IWA\", \"LBA\", \"PSA\", \"SOA\", \"SBA\", \"SJA\", \"SYA\", \"VCA\", \"WHA\"]]\n",
    "home_odds = df[[\"B365H\", \"BSH\", \"BWH\", \"GBH\", \"IWH\", \"LBH\", \"PSH\", \"SOH\", \"SBH\", \"SJH\", \"SYH\", \"VCH\", \"WHH\"]]\n",
    "draw_odds = df[[\"B365D\", \"BSD\", \"BWD\", \"GBD\", \"IWD\", \"LBD\", \"PSD\", \"SOD\", \"SBD\", \"SJD\", \"SYD\", \"VCD\", \"WHD\"]]\n",
    "\n",
    "#Average of away/home/draw odds\n",
    "df[\"Avg_away_odds\"] = away_odds.mean(axis=1)\n",
    "df[\"Avg_home_odds\"] = home_odds.mean(axis=1)\n",
    "df[\"Avg_draw_odds\"] = draw_odds.mean(axis=1)\n",
    "\n",
    "#Predcition based on averages - Odds with smallest average have the highest probability -> returns A/H/D\n",
    "df[\"Avg_bookie_prediction\"] = df[[\"Avg_away_odds\", \"Avg_home_odds\", \"Avg_draw_odds\"]].idxmin(axis=1).fillna(\"\").astype(str).str[4]\n",
    "df[\"Avg_bookie_prediction\"] = df[\"Avg_bookie_prediction\"].str.upper()\n",
    "\n",
    "#Certainity of odds, the smaller variance implies, that bookies are more \"sure\"\n",
    "df[\"Var_away_odds\"] = away_odds.var(axis=1)\n",
    "df[\"Var_home_odds\"] = home_odds.var(axis=1)\n",
    "df[\"Var_draw_odds\"] = draw_odds.var(axis=1)\n",
    "\n",
    "print(df.loc[:, \"Avg_away_odds\":\"Var_draw_odds\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c81c2df5f635823"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Columns for predictions of all bookies\n",
    "bookies_predictions = pd.DataFrame(columns = [\"B365P\", \"BSP\", \"BWP\", \"GBP\", \"IWP\", \"LBP\", \"PSP\", \"SOP\", \"SBP\", \"SJP\", \"SYP\", \"VCP\", \"WHP\"])\n",
    "\n",
    "#dataframe with away/home/draw odds for each bookie\n",
    "df_bookies_accuracy = pd.concat([away_odds, home_odds, draw_odds, bookies_predictions], axis = 1).sort_index(axis = 1)\n",
    "df_bookies_accuracy[\"Outcome\"] = df[[\"FTR\"]]\n",
    "\n",
    "seq = list(range(3, 53, 4))\n",
    "#\"prediction\" of each bookie based on their odds\n",
    "for i in seq:\n",
    "    df_bookies_accuracy.iloc[:, i] = df_bookies_accuracy.iloc[:, i-3:i].idxmin(axis=1).fillna(\"\").astype(str).str[-1]\n",
    "\n",
    "print(df_bookies_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8d7c71eb410bfed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Accuracy of each bookie - all around 50% - accuracy of a bookie cannot be used as a weight for prediction\n",
    "for bookie in bookies_predictions:\n",
    "    filter_df = df_bookies_accuracy[df_bookies_accuracy[bookie].notna()]\n",
    "    matching_values = (filter_df[bookie] == filter_df['Outcome']).sum()\n",
    "    total_values = len(filter_df)\n",
    "    percent= (matching_values/total_values) *100\n",
    "    print(\"Percentage of matching values for \" + bookie[:-1] + f\": {percent:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b86b0aa3d9daa05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- - -"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a00d24cc9fb48e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aa907d44454efac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all completely empty columns and rows which there is a lot of, dropped 41 empty columns in total."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "234ba0e944b1f035"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(how='all', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb31e1bed329138"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d0695aa4b7f0b7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(\"final.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4604ac42b85042de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration\n",
    "\n",
    "Total overview of all variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b5e6047279e3e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99cb63c7675f6be0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Percentage of missing values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d3741cd471b158a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "na_vals = df.isna().sum()\n",
    "na_vals = na_vals/df.shape[0]\n",
    "na_vals.sort_values(ascending = False).head(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87bd3aef84019e54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)\n",
    "\n",
    "# Get first and last occurrences\n",
    "first_occurrences = df.apply(lambda x: x.first_valid_index())\n",
    "last_occurrences = df.apply(lambda x: x.last_valid_index())\n",
    "\n",
    "# Initialize a dictionary to store counts\n",
    "missing_counts = {}\n",
    "\n",
    "# Iterate through each column and calculate missing values counts between first and last occurrences\n",
    "for column in df.columns:\n",
    "    # Indexes of the first and last occurrences\n",
    "    first_idx = df[column].first_valid_index()\n",
    "    last_idx = df[column].last_valid_index()\n",
    "\n",
    "    # Select the range between first and last occurrence, count missing values\n",
    "    missing_count = df[column][first_idx:last_idx].isnull().sum()\n",
    "    missing_counts[column] = missing_count\n",
    "\n",
    "# Create a new DataFrame with the results\n",
    "result_df = pd.DataFrame({\n",
    "    'Variable':          df.columns,\n",
    "    'First Occurrence':  df[\"Date\"].to_numpy()[first_occurrences.values],\n",
    "    'Last Occurrence':   df[\"Date\"].to_numpy()[last_occurrences.values],\n",
    "    \"Missing within\": missing_counts.values()\n",
    "})\n",
    "\n",
    "result_df.sort_values(by=\"Missing within\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647e8ffc4fc172d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "List of the most missing values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a1f0edd1a978df0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "na_vals = df[df[\"season\"] > 18].isna().sum()\n",
    "\n",
    "na_vals = na_vals/df[df[\"season\"] > 18].shape[0]*100\n",
    "na_vals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84f84ee271f3527a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "na_vals = [df[df[\"season\"]==i].isna().sum().sum()/(df[df[\"season\"]==i].shape[0]*df[df[\"season\"]==i].shape[1]) for i in range(0,22)]\n",
    "plt.xticks(range(0,22))\n",
    "plt.ylim(0.3, 1)\n",
    "plt.locator_params(axis='y', nbins=14)\n",
    "plt.plot(na_vals)\n",
    "plt.gca().ticklabel_format(axis='y', style='plain', scilimits=(0, 0))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "787106119d5075a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering\n",
    "We decided to add several features to the dataset.\n",
    "These features are:\n",
    "- Result of the last match between the two contending teams\n",
    "- Goal score during the last match between the two contending teams\n",
    "- Average amount of goals scored in the current season\n",
    "- Average amount of goals received in the current season\n",
    "\n",
    "We believe that these features will prove useful in the training of our model as they can reveal things such as momentum and strenghts/weaknesses against certain teams."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dafab2b1568d265"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Result of the last match between the two contending teams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e02bcbf88623869e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a string of participating teams, append them alphabetically behind each other so it is easier to slice them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27d3db66a4fa4ef1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Index\"] = df.index\n",
    "df[\"MatchTeams\"] = df[[\"HomeTeam\",\"AwayTeam\"]].values.tolist()\n",
    "df[\"MatchTeams\"] = df[\"MatchTeams\"].sort_values().apply(lambda x: sorted(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f2106b16333bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.assign(MatchTeams=df[\"MatchTeams\"].apply(lambda l: \"_\".join(l)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1588a4c5793ed246"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values(['MatchTeams','Date'],ascending=True).groupby('MatchTeams').shift()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10bb6bf4e89d3b5a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "23e363b205240b57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use groupby to group by same matches, create [\"LastMatchIndex\",\"LastMatchAwayGoals\", \"LastMatchHomeGoals\"] columns with unsorted values.\n",
    "First match of two teams gets empty column index as LastMatchIndex"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1ac3e7f75c4edd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[[\"LastMatchIndex\",\"LastMatchAwayGoals\", \"LastMatchHomeGoals\"]] = df.sort_values(['MatchTeams','Date'],ascending=True).groupby('MatchTeams').shift()[[\"Index\",\"FTAG\", \"FTHG\"]]\n",
    "df.loc[np.isnan(df[\"LastMatchIndex\"]), \"LastMatchIndex\"] = len(df.index)-1\n",
    "df.loc[len(df.index)] = [np.nan for _ in range(df.shape[1])]\n",
    "df.loc[len(df.index)-1]\n",
    "df[\"LastMatchIndex\"] = df[\"LastMatchIndex\"].replace(np.nan, len(df.index)-1)\n",
    "\n",
    "df[\"LastMatchIndex\"].fillna(len(df.index)-1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab9f1f222745ff5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr = df[\"LastMatchIndex\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78964ed215e7e017"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Switch LastMatchHomeGoals and LastMatchAwayGoals if they do not correspond to the teams accordingly, calculate who won the match"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb2cdee9b48e7020"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"SameHomeTeam\"] = (df.iloc[arr][\"HomeTeam\"].values == df[\"HomeTeam\"].values)\n",
    "df.loc[df[\"SameHomeTeam\"],['LastMatchHomeGoals','LastMatchAwayGoals']] = df.loc[df[\"SameHomeTeam\"],['LastMatchHomeGoals','LastMatchAwayGoals']].values\n",
    "df[\"LastMatchAwayWin\"] = (df[\"LastMatchAwayGoals\"] > df[\"LastMatchHomeGoals\"]).astype(int)\n",
    "df[\"LastMatchHomeWin\"] = (df[\"LastMatchAwayGoals\"] < df[\"LastMatchHomeGoals\"]).astype(int)\n",
    "df[\"LastMatchDraw\"] = (df[\"LastMatchAwayGoals\"] == df[\"LastMatchHomeGoals\"]).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac199309ca36405d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df[\"MatchTeams\"] == \"Chelsea_Liverpool\"][[\"Date\",\"FTHG\", \"FTAG\",\"LastMatchHomeGoals\", \"LastMatchAwayGoals\", \"LastMatchHomeWin\",\"LastMatchAwayWin\", \"LastMatchDraw\" ]]\n",
    "df.drop([\"SameHomeTeam\", \"LastMatchIndex\", \"Index\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bee40cad7360d605"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO Average amount of goals scored/received in the current season\n",
    "\n",
    "We will add 4 columns - HomeTeamAvgScored, AwayTeamAvgScored, HomeTeamAvgReceived, AwayTeamAvgReceived\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "175537c6bf81b9de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
